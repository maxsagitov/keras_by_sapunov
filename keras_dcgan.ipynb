{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on DCGAN from here:\n",
    "\n",
    "https://github.com/roatienza/Deep-Learning-Experiments/blob/master/Experiments/Tensorflow/GAN/dcgan_mnist.py\n",
    "\n",
    "Other sources:\n",
    "\n",
    "https://github.com/jacobgil/keras-dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DCGAN on MNIST using Keras\n",
    "Author: Rowel Atienza\n",
    "Project: https://github.com/roatienza/Deep-Learning-Experiments\n",
    "Dependencies: tensorflow 1.0 and keras 2.0\n",
    "Usage: python3 dcgan_mnist.py\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    def elapsed(self,sec):\n",
    "        if sec < 60:\n",
    "            return str(sec) + \" sec\"\n",
    "        elif sec < (60 * 60):\n",
    "            return str(sec / 60) + \" min\"\n",
    "        else:\n",
    "            return str(sec / (60 * 60)) + \" hr\"\n",
    "    def elapsed_time(self):\n",
    "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "    def __init__(self, img_rows=28, img_cols=28, channel=1):\n",
    "\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        self.D = None   # discriminator\n",
    "        self.G = None   # generator\n",
    "        self.AM = None  # adversarial model\n",
    "        self.DM = None  # discriminator model\n",
    "\n",
    "    # (Wâˆ’F+2P)/S+1\n",
    "    def discriminator(self):\n",
    "        if self.D:\n",
    "            return self.D\n",
    "        self.D = Sequential()\n",
    "        depth = 64\n",
    "        dropout = 0.4\n",
    "        # In: 28 x 28 x 1, depth = 1\n",
    "        # Out: 14 x 14 x 1, depth=64\n",
    "        input_shape = (self.img_rows, self.img_cols, self.channel)\n",
    "        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\\\n",
    "            padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        # Out: 1-dim probability\n",
    "        self.D.add(Flatten())\n",
    "        self.D.add(Dense(1))\n",
    "        self.D.add(Activation('sigmoid'))\n",
    "        self.D.summary()\n",
    "        return self.D\n",
    "\n",
    "    def generator(self):\n",
    "        if self.G:\n",
    "            return self.G\n",
    "        self.G = Sequential()\n",
    "        dropout = 0.4\n",
    "        depth = 64+64+64+64\n",
    "        dim = 7\n",
    "        # In: 100\n",
    "        # Out: dim x dim x depth\n",
    "        self.G.add(Dense(dim*dim*depth, input_dim=100))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "        self.G.add(Reshape((dim, dim, depth)))\n",
    "        self.G.add(Dropout(dropout))\n",
    "\n",
    "        # In: dim x dim x depth\n",
    "        # Out: 2*dim x 2*dim x depth/2\n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n",
    "        self.G.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "        self.G.add(Activation('sigmoid'))\n",
    "        self.G.summary()\n",
    "        return self.G\n",
    "\n",
    "    def discriminator_model(self):\n",
    "        if self.DM:\n",
    "            return self.DM\n",
    "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "        self.DM = Sequential()\n",
    "        self.DM.add(self.discriminator())\n",
    "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        return self.DM\n",
    "\n",
    "    def adversarial_model(self):\n",
    "        if self.AM:\n",
    "            return self.AM\n",
    "        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "        self.AM = Sequential()\n",
    "        self.AM.add(self.generator())\n",
    "        self.AM.add(self.discriminator())\n",
    "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        return self.AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNIST_DCGAN(object):\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channel = 1\n",
    "\n",
    "        self.x_train = input_data.read_data_sets(\"mnist\",\\\n",
    "        \tone_hot=True).train.images\n",
    "        self.x_train = self.x_train.reshape(-1, self.img_rows,\\\n",
    "        \tself.img_cols, 1).astype(np.float32)\n",
    "\n",
    "        self.DCGAN = DCGAN()\n",
    "        self.discriminator =  self.DCGAN.discriminator_model()\n",
    "        self.adversarial = self.DCGAN.adversarial_model()\n",
    "        self.generator = self.DCGAN.generator()\n",
    "\n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
    "        noise_input = None\n",
    "        if save_interval>0:\n",
    "            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "        for i in range(train_steps):\n",
    "            images_train = self.x_train[np.random.randint(0,\n",
    "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            images_fake = self.generator.predict(noise)\n",
    "            x = np.concatenate((images_train, images_fake))\n",
    "            y = np.ones([2*batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            d_loss = self.discriminator.train_on_batch(x, y)\n",
    "\n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            print(log_mesg)\n",
    "            if save_interval>0:\n",
    "                if (i+1)%save_interval==0:\n",
    "                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
    "                        noise=noise_input, step=(i+1))\n",
    "\n",
    "    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n",
    "        filename = 'mnist.png'\n",
    "        if fake:\n",
    "            if noise is None:\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
    "            else:\n",
    "                filename = \"mnist_%d.png\" % step\n",
    "            images = self.generator.predict(noise)\n",
    "        else:\n",
    "            i = np.random.randint(0, self.x_train.shape[0], samples)\n",
    "            images = self.x_train[i, :, :, :]\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.img_rows, self.img_cols])\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 8193      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,311,553\n",
      "Trainable params: 4,311,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 2,394,241\n",
      "Trainable params: 2,368,705\n",
      "Non-trainable params: 25,536\n",
      "_________________________________________________________________\n",
      "0: [D loss: 0.692992, acc: 0.556641]  [A loss: 1.433622, acc: 0.000000]\n",
      "1: [D loss: 0.645771, acc: 0.998047]  [A loss: 1.332077, acc: 0.000000]\n",
      "2: [D loss: 0.534616, acc: 1.000000]  [A loss: 1.791429, acc: 0.000000]\n",
      "3: [D loss: 0.327098, acc: 1.000000]  [A loss: 2.139452, acc: 0.000000]\n",
      "4: [D loss: 0.124837, acc: 1.000000]  [A loss: 0.753021, acc: 0.453125]\n",
      "5: [D loss: 0.071036, acc: 1.000000]  [A loss: 1.873064, acc: 0.003906]\n",
      "6: [D loss: 0.083078, acc: 0.970703]  [A loss: 0.000232, acc: 1.000000]\n",
      "7: [D loss: 0.041007, acc: 0.998047]  [A loss: 0.001919, acc: 1.000000]\n",
      "8: [D loss: 0.017100, acc: 0.996094]  [A loss: 0.000730, acc: 1.000000]\n",
      "9: [D loss: 0.015570, acc: 0.998047]  [A loss: 0.000293, acc: 1.000000]\n",
      "10: [D loss: 0.009003, acc: 1.000000]  [A loss: 0.000498, acc: 1.000000]\n",
      "11: [D loss: 0.009514, acc: 1.000000]  [A loss: 0.000245, acc: 1.000000]\n",
      "12: [D loss: 0.007567, acc: 1.000000]  [A loss: 0.000208, acc: 1.000000]\n",
      "13: [D loss: 0.004956, acc: 1.000000]  [A loss: 0.000495, acc: 1.000000]\n",
      "14: [D loss: 0.005775, acc: 1.000000]  [A loss: 0.000217, acc: 1.000000]\n",
      "15: [D loss: 0.004469, acc: 1.000000]  [A loss: 0.000238, acc: 1.000000]\n",
      "16: [D loss: 0.005599, acc: 1.000000]  [A loss: 0.000093, acc: 1.000000]\n",
      "17: [D loss: 0.004474, acc: 1.000000]  [A loss: 0.000149, acc: 1.000000]\n",
      "18: [D loss: 0.003322, acc: 1.000000]  [A loss: 0.000786, acc: 1.000000]\n",
      "19: [D loss: 0.003620, acc: 1.000000]  [A loss: 0.000192, acc: 1.000000]\n",
      "20: [D loss: 0.002659, acc: 1.000000]  [A loss: 0.000545, acc: 1.000000]\n",
      "21: [D loss: 0.002096, acc: 1.000000]  [A loss: 0.000864, acc: 1.000000]\n",
      "22: [D loss: 0.003038, acc: 1.000000]  [A loss: 0.000322, acc: 1.000000]\n",
      "23: [D loss: 0.002304, acc: 1.000000]  [A loss: 0.000771, acc: 1.000000]\n",
      "24: [D loss: 0.001986, acc: 1.000000]  [A loss: 0.001040, acc: 1.000000]\n",
      "25: [D loss: 0.001639, acc: 1.000000]  [A loss: 0.003067, acc: 1.000000]\n",
      "26: [D loss: 0.001969, acc: 1.000000]  [A loss: 0.006033, acc: 1.000000]\n",
      "27: [D loss: 0.003584, acc: 1.000000]  [A loss: 0.076226, acc: 0.988281]\n",
      "28: [D loss: 0.185755, acc: 0.964844]  [A loss: 16.102674, acc: 0.000000]\n",
      "29: [D loss: 1.997133, acc: 0.500000]  [A loss: 0.000000, acc: 1.000000]\n",
      "30: [D loss: 0.091416, acc: 0.996094]  [A loss: 0.000001, acc: 1.000000]\n",
      "31: [D loss: 0.048186, acc: 1.000000]  [A loss: 0.000004, acc: 1.000000]\n",
      "32: [D loss: 0.040936, acc: 1.000000]  [A loss: 0.000011, acc: 1.000000]\n",
      "33: [D loss: 0.033768, acc: 1.000000]  [A loss: 0.000027, acc: 1.000000]\n",
      "34: [D loss: 0.031483, acc: 1.000000]  [A loss: 0.000075, acc: 1.000000]\n",
      "35: [D loss: 0.026614, acc: 1.000000]  [A loss: 0.000185, acc: 1.000000]\n",
      "36: [D loss: 0.022999, acc: 1.000000]  [A loss: 0.000356, acc: 1.000000]\n",
      "37: [D loss: 0.022642, acc: 0.998047]  [A loss: 0.000485, acc: 1.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38: [D loss: 0.024725, acc: 0.998047]  [A loss: 0.001441, acc: 1.000000]\n",
      "39: [D loss: 0.032824, acc: 0.998047]  [A loss: 0.003067, acc: 1.000000]\n",
      "40: [D loss: 0.025561, acc: 1.000000]  [A loss: 0.003965, acc: 1.000000]\n",
      "41: [D loss: 0.033712, acc: 0.998047]  [A loss: 0.004541, acc: 1.000000]\n",
      "42: [D loss: 0.043093, acc: 0.998047]  [A loss: 0.040548, acc: 0.988281]\n",
      "43: [D loss: 0.695135, acc: 0.658203]  [A loss: 6.502824, acc: 0.000000]\n",
      "44: [D loss: 2.143780, acc: 0.505859]  [A loss: 8.191023, acc: 0.000000]\n",
      "45: [D loss: 0.300820, acc: 0.923828]  [A loss: 2.088740, acc: 0.023438]\n",
      "46: [D loss: 0.855108, acc: 0.566406]  [A loss: 6.136967, acc: 0.000000]\n",
      "47: [D loss: 0.318919, acc: 0.931641]  [A loss: 3.441426, acc: 0.000000]\n",
      "48: [D loss: 0.690661, acc: 0.583984]  [A loss: 7.943220, acc: 0.000000]\n",
      "49: [D loss: 0.373503, acc: 0.826172]  [A loss: 1.176194, acc: 0.230469]\n",
      "50: [D loss: 1.061980, acc: 0.500000]  [A loss: 7.462814, acc: 0.000000]\n",
      "51: [D loss: 0.477730, acc: 0.705078]  [A loss: 1.904238, acc: 0.003906]\n",
      "52: [D loss: 0.611813, acc: 0.554688]  [A loss: 5.047221, acc: 0.000000]\n",
      "53: [D loss: 0.261132, acc: 0.937500]  [A loss: 2.366456, acc: 0.000000]\n",
      "54: [D loss: 0.475222, acc: 0.658203]  [A loss: 4.906759, acc: 0.000000]\n",
      "55: [D loss: 0.206973, acc: 0.978516]  [A loss: 2.667356, acc: 0.000000]\n",
      "56: [D loss: 0.438087, acc: 0.681641]  [A loss: 5.356464, acc: 0.000000]\n",
      "57: [D loss: 0.201462, acc: 0.957031]  [A loss: 2.539784, acc: 0.000000]\n",
      "58: [D loss: 0.443342, acc: 0.664062]  [A loss: 5.522981, acc: 0.000000]\n",
      "59: [D loss: 0.206738, acc: 0.949219]  [A loss: 2.568661, acc: 0.000000]\n",
      "60: [D loss: 0.363073, acc: 0.769531]  [A loss: 4.939378, acc: 0.000000]\n",
      "61: [D loss: 0.143553, acc: 0.988281]  [A loss: 2.798302, acc: 0.000000]\n",
      "62: [D loss: 0.272461, acc: 0.919922]  [A loss: 4.369342, acc: 0.000000]\n",
      "63: [D loss: 0.144188, acc: 0.990234]  [A loss: 3.070428, acc: 0.000000]\n",
      "64: [D loss: 0.244945, acc: 0.953125]  [A loss: 4.370011, acc: 0.000000]\n",
      "65: [D loss: 0.130424, acc: 0.994141]  [A loss: 3.086435, acc: 0.000000]\n",
      "66: [D loss: 0.232244, acc: 0.966797]  [A loss: 4.145480, acc: 0.000000]\n",
      "67: [D loss: 0.141932, acc: 0.998047]  [A loss: 3.091027, acc: 0.000000]\n",
      "68: [D loss: 0.218985, acc: 0.990234]  [A loss: 3.872322, acc: 0.000000]\n",
      "69: [D loss: 0.155641, acc: 0.996094]  [A loss: 2.966152, acc: 0.000000]\n",
      "70: [D loss: 0.224523, acc: 0.982422]  [A loss: 3.840089, acc: 0.000000]\n",
      "71: [D loss: 0.146057, acc: 0.996094]  [A loss: 2.810852, acc: 0.000000]\n",
      "72: [D loss: 0.233059, acc: 0.957031]  [A loss: 3.874252, acc: 0.000000]\n",
      "73: [D loss: 0.149540, acc: 0.994141]  [A loss: 2.512677, acc: 0.000000]\n",
      "74: [D loss: 0.302294, acc: 0.873047]  [A loss: 4.392513, acc: 0.000000]\n",
      "75: [D loss: 0.217299, acc: 0.947266]  [A loss: 1.528983, acc: 0.039062]\n",
      "76: [D loss: 0.717924, acc: 0.527344]  [A loss: 5.133339, acc: 0.000000]\n",
      "77: [D loss: 0.481376, acc: 0.753906]  [A loss: 1.439801, acc: 0.003906]\n",
      "78: [D loss: 0.395297, acc: 0.736328]  [A loss: 2.344806, acc: 0.000000]\n",
      "79: [D loss: 0.230112, acc: 0.970703]  [A loss: 2.155061, acc: 0.000000]\n",
      "80: [D loss: 0.257381, acc: 0.939453]  [A loss: 2.427405, acc: 0.000000]\n",
      "81: [D loss: 0.248734, acc: 0.947266]  [A loss: 2.569454, acc: 0.000000]\n",
      "82: [D loss: 0.232993, acc: 0.951172]  [A loss: 2.401025, acc: 0.000000]\n",
      "83: [D loss: 0.270310, acc: 0.906250]  [A loss: 2.625855, acc: 0.000000]\n",
      "84: [D loss: 0.245742, acc: 0.945312]  [A loss: 2.748055, acc: 0.000000]\n",
      "85: [D loss: 0.234546, acc: 0.937500]  [A loss: 2.515591, acc: 0.000000]\n",
      "86: [D loss: 0.272687, acc: 0.904297]  [A loss: 3.199759, acc: 0.000000]\n",
      "87: [D loss: 0.240998, acc: 0.957031]  [A loss: 1.549895, acc: 0.039062]\n",
      "88: [D loss: 0.726350, acc: 0.576172]  [A loss: 5.148015, acc: 0.000000]\n",
      "89: [D loss: 0.896675, acc: 0.578125]  [A loss: 0.970523, acc: 0.191406]\n",
      "90: [D loss: 0.558528, acc: 0.611328]  [A loss: 1.729356, acc: 0.000000]\n",
      "91: [D loss: 0.314071, acc: 0.943359]  [A loss: 1.502797, acc: 0.000000]\n",
      "92: [D loss: 0.337522, acc: 0.845703]  [A loss: 1.891010, acc: 0.000000]\n",
      "93: [D loss: 0.296410, acc: 0.941406]  [A loss: 1.720085, acc: 0.000000]\n",
      "94: [D loss: 0.341177, acc: 0.857422]  [A loss: 2.056763, acc: 0.000000]\n",
      "95: [D loss: 0.296719, acc: 0.937500]  [A loss: 1.750839, acc: 0.000000]\n",
      "96: [D loss: 0.348473, acc: 0.832031]  [A loss: 2.403427, acc: 0.000000]\n",
      "97: [D loss: 0.273889, acc: 0.970703]  [A loss: 1.557589, acc: 0.019531]\n",
      "98: [D loss: 0.471280, acc: 0.699219]  [A loss: 2.996756, acc: 0.000000]\n",
      "99: [D loss: 0.385341, acc: 0.855469]  [A loss: 0.916739, acc: 0.253906]\n",
      "100: [D loss: 0.690761, acc: 0.531250]  [A loss: 2.571218, acc: 0.000000]\n",
      "101: [D loss: 0.386636, acc: 0.871094]  [A loss: 0.967612, acc: 0.152344]\n",
      "102: [D loss: 0.530629, acc: 0.593750]  [A loss: 1.971066, acc: 0.000000]\n",
      "103: [D loss: 0.323299, acc: 0.960938]  [A loss: 1.354912, acc: 0.007812]\n",
      "104: [D loss: 0.415442, acc: 0.742188]  [A loss: 2.046798, acc: 0.000000]\n",
      "105: [D loss: 0.315364, acc: 0.949219]  [A loss: 1.467660, acc: 0.000000]\n",
      "106: [D loss: 0.399994, acc: 0.742188]  [A loss: 2.327607, acc: 0.000000]\n",
      "107: [D loss: 0.343691, acc: 0.929688]  [A loss: 1.047430, acc: 0.105469]\n",
      "108: [D loss: 0.644799, acc: 0.544922]  [A loss: 2.845304, acc: 0.000000]\n",
      "109: [D loss: 0.465839, acc: 0.808594]  [A loss: 0.783093, acc: 0.347656]\n",
      "110: [D loss: 0.628865, acc: 0.523438]  [A loss: 1.716015, acc: 0.000000]\n",
      "111: [D loss: 0.352696, acc: 0.939453]  [A loss: 1.360214, acc: 0.003906]\n",
      "112: [D loss: 0.385846, acc: 0.804688]  [A loss: 1.740580, acc: 0.000000]\n",
      "113: [D loss: 0.360405, acc: 0.890625]  [A loss: 1.571098, acc: 0.000000]\n",
      "114: [D loss: 0.410191, acc: 0.783203]  [A loss: 1.994673, acc: 0.000000]\n",
      "115: [D loss: 0.347463, acc: 0.921875]  [A loss: 1.327898, acc: 0.019531]\n",
      "116: [D loss: 0.500279, acc: 0.652344]  [A loss: 2.704653, acc: 0.000000]\n",
      "117: [D loss: 0.420625, acc: 0.863281]  [A loss: 0.651845, acc: 0.621094]\n",
      "118: [D loss: 0.832078, acc: 0.505859]  [A loss: 2.135977, acc: 0.000000]\n",
      "119: [D loss: 0.400276, acc: 0.908203]  [A loss: 0.976987, acc: 0.121094]\n",
      "120: [D loss: 0.508319, acc: 0.585938]  [A loss: 1.657124, acc: 0.000000]\n",
      "121: [D loss: 0.372848, acc: 0.904297]  [A loss: 1.360228, acc: 0.015625]\n",
      "122: [D loss: 0.437797, acc: 0.732422]  [A loss: 1.878414, acc: 0.000000]\n",
      "123: [D loss: 0.363626, acc: 0.894531]  [A loss: 1.373676, acc: 0.027344]\n",
      "124: [D loss: 0.474905, acc: 0.695312]  [A loss: 2.409544, acc: 0.000000]\n",
      "125: [D loss: 0.376964, acc: 0.904297]  [A loss: 0.789548, acc: 0.398438]\n",
      "126: [D loss: 0.762029, acc: 0.509766]  [A loss: 2.737151, acc: 0.000000]\n",
      "127: [D loss: 0.495111, acc: 0.806641]  [A loss: 0.685770, acc: 0.570312]\n",
      "128: [D loss: 0.649797, acc: 0.521484]  [A loss: 1.438822, acc: 0.000000]\n",
      "129: [D loss: 0.414156, acc: 0.863281]  [A loss: 1.205284, acc: 0.039062]\n",
      "130: [D loss: 0.461569, acc: 0.724609]  [A loss: 1.599104, acc: 0.000000]\n",
      "131: [D loss: 0.414688, acc: 0.824219]  [A loss: 1.432805, acc: 0.007812]\n",
      "132: [D loss: 0.442287, acc: 0.738281]  [A loss: 1.928473, acc: 0.000000]\n",
      "133: [D loss: 0.394775, acc: 0.906250]  [A loss: 1.057158, acc: 0.089844]\n",
      "134: [D loss: 0.597156, acc: 0.560547]  [A loss: 2.742967, acc: 0.000000]\n",
      "135: [D loss: 0.485193, acc: 0.814453]  [A loss: 0.563741, acc: 0.761719]\n",
      "136: [D loss: 0.762320, acc: 0.501953]  [A loss: 1.618585, acc: 0.000000]\n",
      "137: [D loss: 0.441585, acc: 0.902344]  [A loss: 1.014470, acc: 0.066406]\n",
      "138: [D loss: 0.510607, acc: 0.595703]  [A loss: 1.655508, acc: 0.000000]\n",
      "139: [D loss: 0.411185, acc: 0.876953]  [A loss: 1.195725, acc: 0.019531]\n",
      "140: [D loss: 0.494757, acc: 0.669922]  [A loss: 1.958111, acc: 0.000000]\n",
      "141: [D loss: 0.377102, acc: 0.917969]  [A loss: 1.034440, acc: 0.093750]\n",
      "142: [D loss: 0.585180, acc: 0.560547]  [A loss: 2.508621, acc: 0.000000]\n",
      "143: [D loss: 0.447590, acc: 0.853516]  [A loss: 0.645326, acc: 0.652344]\n",
      "144: [D loss: 0.741249, acc: 0.515625]  [A loss: 1.844052, acc: 0.000000]\n",
      "145: [D loss: 0.447307, acc: 0.898438]  [A loss: 0.848475, acc: 0.246094]\n",
      "146: [D loss: 0.559368, acc: 0.537109]  [A loss: 1.637326, acc: 0.007812]\n",
      "147: [D loss: 0.422504, acc: 0.859375]  [A loss: 1.168607, acc: 0.031250]\n",
      "148: [D loss: 0.490796, acc: 0.660156]  [A loss: 1.787745, acc: 0.000000]\n",
      "149: [D loss: 0.403725, acc: 0.892578]  [A loss: 1.114575, acc: 0.070312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150: [D loss: 0.561347, acc: 0.605469]  [A loss: 2.292832, acc: 0.000000]\n",
      "151: [D loss: 0.467412, acc: 0.867188]  [A loss: 0.672100, acc: 0.550781]\n",
      "152: [D loss: 0.750948, acc: 0.501953]  [A loss: 2.085491, acc: 0.000000]\n",
      "153: [D loss: 0.476391, acc: 0.859375]  [A loss: 0.775192, acc: 0.390625]\n",
      "154: [D loss: 0.599649, acc: 0.517578]  [A loss: 1.528679, acc: 0.000000]\n",
      "155: [D loss: 0.427156, acc: 0.912109]  [A loss: 1.104988, acc: 0.050781]\n",
      "156: [D loss: 0.498557, acc: 0.630859]  [A loss: 1.937962, acc: 0.000000]\n",
      "157: [D loss: 0.399610, acc: 0.908203]  [A loss: 1.156844, acc: 0.062500]\n",
      "158: [D loss: 0.539561, acc: 0.609375]  [A loss: 2.358469, acc: 0.000000]\n",
      "159: [D loss: 0.457586, acc: 0.851562]  [A loss: 0.685625, acc: 0.539062]\n",
      "160: [D loss: 0.757207, acc: 0.501953]  [A loss: 2.148816, acc: 0.000000]\n",
      "161: [D loss: 0.488889, acc: 0.837891]  [A loss: 0.714659, acc: 0.476562]\n",
      "162: [D loss: 0.650433, acc: 0.523438]  [A loss: 1.581339, acc: 0.000000]\n",
      "163: [D loss: 0.467863, acc: 0.845703]  [A loss: 1.119082, acc: 0.042969]\n",
      "164: [D loss: 0.540933, acc: 0.615234]  [A loss: 1.828085, acc: 0.000000]\n",
      "165: [D loss: 0.444367, acc: 0.830078]  [A loss: 1.079113, acc: 0.085938]\n",
      "166: [D loss: 0.576505, acc: 0.574219]  [A loss: 2.437112, acc: 0.000000]\n",
      "167: [D loss: 0.465301, acc: 0.835938]  [A loss: 0.607333, acc: 0.675781]\n",
      "168: [D loss: 0.794705, acc: 0.505859]  [A loss: 2.142062, acc: 0.000000]\n",
      "169: [D loss: 0.491563, acc: 0.832031]  [A loss: 0.768328, acc: 0.355469]\n",
      "170: [D loss: 0.656078, acc: 0.525391]  [A loss: 1.692116, acc: 0.003906]\n",
      "171: [D loss: 0.463042, acc: 0.847656]  [A loss: 1.063833, acc: 0.097656]\n",
      "172: [D loss: 0.545146, acc: 0.599609]  [A loss: 2.059070, acc: 0.000000]\n",
      "173: [D loss: 0.461847, acc: 0.869141]  [A loss: 0.949256, acc: 0.152344]\n",
      "174: [D loss: 0.646688, acc: 0.529297]  [A loss: 2.583117, acc: 0.000000]\n",
      "175: [D loss: 0.516256, acc: 0.769531]  [A loss: 0.577713, acc: 0.746094]\n",
      "176: [D loss: 0.805211, acc: 0.505859]  [A loss: 1.848163, acc: 0.000000]\n",
      "177: [D loss: 0.522711, acc: 0.798828]  [A loss: 0.830133, acc: 0.289062]\n",
      "178: [D loss: 0.645311, acc: 0.539062]  [A loss: 1.667669, acc: 0.000000]\n",
      "179: [D loss: 0.484024, acc: 0.839844]  [A loss: 1.097122, acc: 0.082031]\n",
      "180: [D loss: 0.588055, acc: 0.583984]  [A loss: 1.854369, acc: 0.000000]\n",
      "181: [D loss: 0.476054, acc: 0.845703]  [A loss: 0.933686, acc: 0.238281]\n",
      "182: [D loss: 0.714678, acc: 0.537109]  [A loss: 2.296450, acc: 0.000000]\n",
      "183: [D loss: 0.565060, acc: 0.730469]  [A loss: 0.532918, acc: 0.789062]\n",
      "184: [D loss: 0.799226, acc: 0.498047]  [A loss: 1.582503, acc: 0.000000]\n",
      "185: [D loss: 0.554222, acc: 0.771484]  [A loss: 0.862974, acc: 0.261719]\n",
      "186: [D loss: 0.655769, acc: 0.535156]  [A loss: 1.670052, acc: 0.000000]\n",
      "187: [D loss: 0.563152, acc: 0.714844]  [A loss: 1.049866, acc: 0.089844]\n",
      "188: [D loss: 0.629406, acc: 0.566406]  [A loss: 1.842372, acc: 0.000000]\n",
      "189: [D loss: 0.504827, acc: 0.839844]  [A loss: 0.845021, acc: 0.304688]\n",
      "190: [D loss: 0.697498, acc: 0.521484]  [A loss: 2.403951, acc: 0.000000]\n",
      "191: [D loss: 0.561755, acc: 0.744141]  [A loss: 0.562241, acc: 0.750000]\n",
      "192: [D loss: 0.790797, acc: 0.496094]  [A loss: 1.827395, acc: 0.000000]\n",
      "193: [D loss: 0.578938, acc: 0.726562]  [A loss: 0.818741, acc: 0.300781]\n",
      "194: [D loss: 0.685878, acc: 0.529297]  [A loss: 1.650284, acc: 0.000000]\n",
      "195: [D loss: 0.547819, acc: 0.757812]  [A loss: 0.981742, acc: 0.140625]\n",
      "196: [D loss: 0.640111, acc: 0.562500]  [A loss: 1.901858, acc: 0.000000]\n",
      "197: [D loss: 0.551520, acc: 0.792969]  [A loss: 0.785992, acc: 0.386719]\n",
      "198: [D loss: 0.720300, acc: 0.509766]  [A loss: 2.152150, acc: 0.000000]\n",
      "199: [D loss: 0.579463, acc: 0.738281]  [A loss: 0.624230, acc: 0.691406]\n",
      "200: [D loss: 0.757999, acc: 0.509766]  [A loss: 1.705861, acc: 0.000000]\n",
      "201: [D loss: 0.586728, acc: 0.736328]  [A loss: 0.798044, acc: 0.316406]\n",
      "202: [D loss: 0.679767, acc: 0.537109]  [A loss: 1.585959, acc: 0.000000]\n",
      "203: [D loss: 0.563604, acc: 0.742188]  [A loss: 0.840560, acc: 0.300781]\n",
      "204: [D loss: 0.680635, acc: 0.541016]  [A loss: 1.867960, acc: 0.000000]\n",
      "205: [D loss: 0.577171, acc: 0.742188]  [A loss: 0.685922, acc: 0.558594]\n",
      "206: [D loss: 0.735855, acc: 0.511719]  [A loss: 1.687259, acc: 0.000000]\n",
      "207: [D loss: 0.583531, acc: 0.746094]  [A loss: 0.792314, acc: 0.335938]\n",
      "208: [D loss: 0.677723, acc: 0.535156]  [A loss: 1.445539, acc: 0.000000]\n",
      "209: [D loss: 0.572476, acc: 0.761719]  [A loss: 0.884129, acc: 0.203125]\n",
      "210: [D loss: 0.641144, acc: 0.552734]  [A loss: 1.639962, acc: 0.000000]\n",
      "211: [D loss: 0.571482, acc: 0.748047]  [A loss: 0.732645, acc: 0.437500]\n",
      "212: [D loss: 0.725152, acc: 0.513672]  [A loss: 1.838087, acc: 0.000000]\n",
      "213: [D loss: 0.594795, acc: 0.724609]  [A loss: 0.622045, acc: 0.695312]\n",
      "214: [D loss: 0.715150, acc: 0.519531]  [A loss: 1.292651, acc: 0.011719]\n",
      "215: [D loss: 0.555361, acc: 0.748047]  [A loss: 0.986553, acc: 0.074219]\n",
      "216: [D loss: 0.609213, acc: 0.582031]  [A loss: 1.488996, acc: 0.003906]\n",
      "217: [D loss: 0.574982, acc: 0.742188]  [A loss: 0.886050, acc: 0.195312]\n",
      "218: [D loss: 0.655677, acc: 0.568359]  [A loss: 1.596363, acc: 0.000000]\n",
      "219: [D loss: 0.586744, acc: 0.755859]  [A loss: 0.731485, acc: 0.402344]\n",
      "220: [D loss: 0.686280, acc: 0.513672]  [A loss: 1.653532, acc: 0.000000]\n",
      "221: [D loss: 0.545108, acc: 0.791016]  [A loss: 0.778523, acc: 0.378906]\n",
      "222: [D loss: 0.720443, acc: 0.533203]  [A loss: 1.756973, acc: 0.000000]\n",
      "223: [D loss: 0.627220, acc: 0.666016]  [A loss: 0.658526, acc: 0.613281]\n",
      "224: [D loss: 0.807930, acc: 0.496094]  [A loss: 1.356274, acc: 0.000000]\n",
      "225: [D loss: 0.579241, acc: 0.724609]  [A loss: 0.936926, acc: 0.109375]\n",
      "226: [D loss: 0.616275, acc: 0.621094]  [A loss: 1.387366, acc: 0.000000]\n",
      "227: [D loss: 0.576562, acc: 0.763672]  [A loss: 0.777254, acc: 0.339844]\n",
      "228: [D loss: 0.656808, acc: 0.523438]  [A loss: 1.365492, acc: 0.000000]\n",
      "229: [D loss: 0.577607, acc: 0.781250]  [A loss: 0.810887, acc: 0.253906]\n",
      "230: [D loss: 0.653863, acc: 0.537109]  [A loss: 1.468371, acc: 0.000000]\n",
      "231: [D loss: 0.576373, acc: 0.763672]  [A loss: 0.754101, acc: 0.382812]\n",
      "232: [D loss: 0.676999, acc: 0.544922]  [A loss: 1.542572, acc: 0.000000]\n",
      "233: [D loss: 0.601149, acc: 0.740234]  [A loss: 0.708125, acc: 0.496094]\n",
      "234: [D loss: 0.687226, acc: 0.517578]  [A loss: 1.342944, acc: 0.000000]\n",
      "235: [D loss: 0.574270, acc: 0.742188]  [A loss: 0.944314, acc: 0.121094]\n",
      "236: [D loss: 0.618595, acc: 0.611328]  [A loss: 1.269283, acc: 0.007812]\n",
      "237: [D loss: 0.591426, acc: 0.722656]  [A loss: 0.761904, acc: 0.351562]\n",
      "238: [D loss: 0.681831, acc: 0.507812]  [A loss: 1.428257, acc: 0.000000]\n",
      "239: [D loss: 0.580048, acc: 0.759766]  [A loss: 0.759190, acc: 0.351562]\n",
      "240: [D loss: 0.701285, acc: 0.529297]  [A loss: 1.545229, acc: 0.000000]\n",
      "241: [D loss: 0.631486, acc: 0.648438]  [A loss: 0.658798, acc: 0.601562]\n",
      "242: [D loss: 0.722986, acc: 0.500000]  [A loss: 1.199277, acc: 0.003906]\n",
      "243: [D loss: 0.584347, acc: 0.695312]  [A loss: 0.868639, acc: 0.187500]\n",
      "244: [D loss: 0.629580, acc: 0.589844]  [A loss: 1.362386, acc: 0.003906]\n",
      "245: [D loss: 0.589931, acc: 0.761719]  [A loss: 0.706260, acc: 0.464844]\n",
      "246: [D loss: 0.684861, acc: 0.519531]  [A loss: 1.259625, acc: 0.000000]\n",
      "247: [D loss: 0.603112, acc: 0.724609]  [A loss: 0.827867, acc: 0.226562]\n",
      "248: [D loss: 0.651430, acc: 0.550781]  [A loss: 1.321236, acc: 0.000000]\n",
      "249: [D loss: 0.577145, acc: 0.753906]  [A loss: 0.758766, acc: 0.375000]\n",
      "250: [D loss: 0.685835, acc: 0.529297]  [A loss: 1.441781, acc: 0.003906]\n",
      "251: [D loss: 0.580938, acc: 0.765625]  [A loss: 0.656154, acc: 0.601562]\n",
      "252: [D loss: 0.719683, acc: 0.505859]  [A loss: 1.380469, acc: 0.003906]\n",
      "253: [D loss: 0.590368, acc: 0.750000]  [A loss: 0.691875, acc: 0.507812]\n",
      "254: [D loss: 0.725365, acc: 0.500000]  [A loss: 1.360502, acc: 0.007812]\n",
      "255: [D loss: 0.600930, acc: 0.712891]  [A loss: 1.000908, acc: 0.050781]\n",
      "256: [D loss: 0.596504, acc: 0.656250]  [A loss: 1.103033, acc: 0.042969]\n",
      "257: [D loss: 0.593239, acc: 0.701172]  [A loss: 0.974748, acc: 0.109375]\n",
      "258: [D loss: 0.640979, acc: 0.585938]  [A loss: 1.256505, acc: 0.015625]\n",
      "259: [D loss: 0.602098, acc: 0.707031]  [A loss: 0.983515, acc: 0.093750]\n",
      "260: [D loss: 0.637781, acc: 0.583984]  [A loss: 1.574715, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261: [D loss: 0.586083, acc: 0.767578]  [A loss: 0.646375, acc: 0.625000]\n",
      "262: [D loss: 0.750961, acc: 0.500000]  [A loss: 1.854499, acc: 0.000000]\n",
      "263: [D loss: 0.665489, acc: 0.558594]  [A loss: 0.616258, acc: 0.699219]\n",
      "264: [D loss: 0.819947, acc: 0.492188]  [A loss: 1.209861, acc: 0.027344]\n",
      "265: [D loss: 0.594486, acc: 0.681641]  [A loss: 1.058092, acc: 0.042969]\n",
      "266: [D loss: 0.627030, acc: 0.648438]  [A loss: 1.233855, acc: 0.007812]\n",
      "267: [D loss: 0.609148, acc: 0.691406]  [A loss: 0.955643, acc: 0.093750]\n",
      "268: [D loss: 0.628467, acc: 0.583984]  [A loss: 1.293141, acc: 0.000000]\n",
      "269: [D loss: 0.609744, acc: 0.675781]  [A loss: 1.012945, acc: 0.066406]\n",
      "270: [D loss: 0.645847, acc: 0.583984]  [A loss: 1.458077, acc: 0.000000]\n",
      "271: [D loss: 0.621887, acc: 0.695312]  [A loss: 0.710482, acc: 0.500000]\n",
      "272: [D loss: 0.721667, acc: 0.513672]  [A loss: 1.769747, acc: 0.000000]\n",
      "273: [D loss: 0.642980, acc: 0.574219]  [A loss: 0.596137, acc: 0.746094]\n",
      "274: [D loss: 0.736645, acc: 0.505859]  [A loss: 1.213762, acc: 0.003906]\n",
      "275: [D loss: 0.612094, acc: 0.712891]  [A loss: 0.817733, acc: 0.257812]\n",
      "276: [D loss: 0.668203, acc: 0.562500]  [A loss: 1.287214, acc: 0.007812]\n",
      "277: [D loss: 0.625440, acc: 0.669922]  [A loss: 0.798569, acc: 0.273438]\n",
      "278: [D loss: 0.664200, acc: 0.566406]  [A loss: 1.216982, acc: 0.000000]\n",
      "279: [D loss: 0.622098, acc: 0.691406]  [A loss: 0.808692, acc: 0.265625]\n",
      "280: [D loss: 0.665666, acc: 0.572266]  [A loss: 1.211016, acc: 0.003906]\n",
      "281: [D loss: 0.621811, acc: 0.707031]  [A loss: 0.874080, acc: 0.203125]\n",
      "282: [D loss: 0.670299, acc: 0.564453]  [A loss: 1.291996, acc: 0.000000]\n",
      "283: [D loss: 0.624931, acc: 0.716797]  [A loss: 0.711827, acc: 0.468750]\n",
      "284: [D loss: 0.705272, acc: 0.503906]  [A loss: 1.457523, acc: 0.000000]\n",
      "285: [D loss: 0.625430, acc: 0.673828]  [A loss: 0.731598, acc: 0.429688]\n",
      "286: [D loss: 0.694033, acc: 0.517578]  [A loss: 1.310341, acc: 0.000000]\n",
      "287: [D loss: 0.637812, acc: 0.679688]  [A loss: 0.768762, acc: 0.316406]\n",
      "288: [D loss: 0.708578, acc: 0.509766]  [A loss: 1.216447, acc: 0.000000]\n",
      "289: [D loss: 0.628054, acc: 0.664062]  [A loss: 0.851713, acc: 0.152344]\n",
      "290: [D loss: 0.662017, acc: 0.576172]  [A loss: 1.234223, acc: 0.003906]\n",
      "291: [D loss: 0.631082, acc: 0.685547]  [A loss: 0.792767, acc: 0.296875]\n",
      "292: [D loss: 0.698759, acc: 0.515625]  [A loss: 1.235615, acc: 0.007812]\n",
      "293: [D loss: 0.619613, acc: 0.689453]  [A loss: 0.860659, acc: 0.167969]\n",
      "294: [D loss: 0.670034, acc: 0.548828]  [A loss: 1.379829, acc: 0.000000]\n",
      "295: [D loss: 0.631679, acc: 0.677734]  [A loss: 0.693700, acc: 0.523438]\n",
      "296: [D loss: 0.703356, acc: 0.515625]  [A loss: 1.228705, acc: 0.000000]\n",
      "297: [D loss: 0.633959, acc: 0.675781]  [A loss: 0.818929, acc: 0.257812]\n",
      "298: [D loss: 0.676734, acc: 0.531250]  [A loss: 1.325882, acc: 0.000000]\n",
      "299: [D loss: 0.642974, acc: 0.634766]  [A loss: 0.712344, acc: 0.476562]\n",
      "300: [D loss: 0.719171, acc: 0.521484]  [A loss: 1.282647, acc: 0.000000]\n",
      "301: [D loss: 0.630222, acc: 0.679688]  [A loss: 0.767116, acc: 0.335938]\n",
      "302: [D loss: 0.687249, acc: 0.531250]  [A loss: 1.354542, acc: 0.000000]\n",
      "303: [D loss: 0.659961, acc: 0.585938]  [A loss: 0.659135, acc: 0.597656]\n",
      "304: [D loss: 0.710911, acc: 0.507812]  [A loss: 1.003346, acc: 0.015625]\n",
      "305: [D loss: 0.624380, acc: 0.679688]  [A loss: 0.860955, acc: 0.183594]\n",
      "306: [D loss: 0.660082, acc: 0.597656]  [A loss: 1.138002, acc: 0.003906]\n",
      "307: [D loss: 0.628752, acc: 0.701172]  [A loss: 0.734437, acc: 0.417969]\n",
      "308: [D loss: 0.685416, acc: 0.501953]  [A loss: 1.139331, acc: 0.003906]\n",
      "309: [D loss: 0.631157, acc: 0.693359]  [A loss: 0.742004, acc: 0.398438]\n",
      "310: [D loss: 0.680867, acc: 0.544922]  [A loss: 1.226955, acc: 0.003906]\n",
      "311: [D loss: 0.627265, acc: 0.691406]  [A loss: 0.688366, acc: 0.546875]\n",
      "312: [D loss: 0.707498, acc: 0.515625]  [A loss: 1.252511, acc: 0.000000]\n",
      "313: [D loss: 0.634662, acc: 0.693359]  [A loss: 0.716993, acc: 0.460938]\n",
      "314: [D loss: 0.695994, acc: 0.523438]  [A loss: 1.248114, acc: 0.000000]\n",
      "315: [D loss: 0.657026, acc: 0.636719]  [A loss: 0.759670, acc: 0.359375]\n",
      "316: [D loss: 0.721522, acc: 0.501953]  [A loss: 1.163273, acc: 0.000000]\n",
      "317: [D loss: 0.633757, acc: 0.667969]  [A loss: 0.917359, acc: 0.093750]\n",
      "318: [D loss: 0.661910, acc: 0.576172]  [A loss: 1.201749, acc: 0.000000]\n",
      "319: [D loss: 0.636901, acc: 0.650391]  [A loss: 0.754758, acc: 0.339844]\n",
      "320: [D loss: 0.689389, acc: 0.529297]  [A loss: 1.261454, acc: 0.000000]\n",
      "321: [D loss: 0.630408, acc: 0.712891]  [A loss: 0.717973, acc: 0.453125]\n",
      "322: [D loss: 0.704758, acc: 0.515625]  [A loss: 1.317257, acc: 0.000000]\n",
      "323: [D loss: 0.637586, acc: 0.669922]  [A loss: 0.716453, acc: 0.468750]\n",
      "324: [D loss: 0.700088, acc: 0.517578]  [A loss: 1.239871, acc: 0.000000]\n",
      "325: [D loss: 0.636346, acc: 0.667969]  [A loss: 0.720348, acc: 0.472656]\n",
      "326: [D loss: 0.716087, acc: 0.519531]  [A loss: 1.275262, acc: 0.000000]\n",
      "327: [D loss: 0.650059, acc: 0.628906]  [A loss: 0.695715, acc: 0.527344]\n",
      "328: [D loss: 0.745298, acc: 0.501953]  [A loss: 1.158541, acc: 0.007812]\n",
      "329: [D loss: 0.640458, acc: 0.669922]  [A loss: 0.793130, acc: 0.257812]\n",
      "330: [D loss: 0.687362, acc: 0.558594]  [A loss: 1.090473, acc: 0.003906]\n",
      "331: [D loss: 0.654065, acc: 0.658203]  [A loss: 0.760146, acc: 0.339844]\n",
      "332: [D loss: 0.692221, acc: 0.523438]  [A loss: 1.038834, acc: 0.011719]\n",
      "333: [D loss: 0.661451, acc: 0.625000]  [A loss: 0.849239, acc: 0.148438]\n",
      "334: [D loss: 0.659016, acc: 0.574219]  [A loss: 1.029552, acc: 0.027344]\n",
      "335: [D loss: 0.650630, acc: 0.648438]  [A loss: 0.771659, acc: 0.316406]\n",
      "336: [D loss: 0.672321, acc: 0.541016]  [A loss: 1.150392, acc: 0.003906]\n",
      "337: [D loss: 0.659034, acc: 0.632812]  [A loss: 0.719236, acc: 0.429688]\n",
      "338: [D loss: 0.716271, acc: 0.509766]  [A loss: 1.246849, acc: 0.000000]\n",
      "339: [D loss: 0.644271, acc: 0.640625]  [A loss: 0.669882, acc: 0.589844]\n",
      "340: [D loss: 0.707219, acc: 0.511719]  [A loss: 1.177592, acc: 0.003906]\n",
      "341: [D loss: 0.641899, acc: 0.660156]  [A loss: 0.685410, acc: 0.531250]\n",
      "342: [D loss: 0.696744, acc: 0.531250]  [A loss: 1.021724, acc: 0.023438]\n",
      "343: [D loss: 0.645572, acc: 0.673828]  [A loss: 0.784799, acc: 0.269531]\n",
      "344: [D loss: 0.671557, acc: 0.550781]  [A loss: 1.015474, acc: 0.035156]\n",
      "345: [D loss: 0.651452, acc: 0.638672]  [A loss: 0.870315, acc: 0.140625]\n",
      "346: [D loss: 0.674644, acc: 0.548828]  [A loss: 1.002660, acc: 0.039062]\n",
      "347: [D loss: 0.657210, acc: 0.634766]  [A loss: 0.926510, acc: 0.054688]\n",
      "348: [D loss: 0.662415, acc: 0.597656]  [A loss: 1.004165, acc: 0.027344]\n",
      "349: [D loss: 0.651431, acc: 0.597656]  [A loss: 1.094573, acc: 0.003906]\n",
      "350: [D loss: 0.646856, acc: 0.648438]  [A loss: 0.870683, acc: 0.121094]\n",
      "351: [D loss: 0.686688, acc: 0.560547]  [A loss: 1.237981, acc: 0.000000]\n",
      "352: [D loss: 0.650740, acc: 0.646484]  [A loss: 0.713127, acc: 0.464844]\n",
      "353: [D loss: 0.704983, acc: 0.513672]  [A loss: 1.325241, acc: 0.000000]\n",
      "354: [D loss: 0.649395, acc: 0.642578]  [A loss: 0.616302, acc: 0.718750]\n",
      "355: [D loss: 0.745315, acc: 0.503906]  [A loss: 1.332576, acc: 0.003906]\n",
      "356: [D loss: 0.667048, acc: 0.556641]  [A loss: 0.657805, acc: 0.617188]\n",
      "357: [D loss: 0.765624, acc: 0.498047]  [A loss: 1.114955, acc: 0.015625]\n",
      "358: [D loss: 0.649783, acc: 0.630859]  [A loss: 0.812075, acc: 0.234375]\n",
      "359: [D loss: 0.669813, acc: 0.580078]  [A loss: 1.072862, acc: 0.003906]\n",
      "360: [D loss: 0.655570, acc: 0.656250]  [A loss: 0.767336, acc: 0.285156]\n",
      "361: [D loss: 0.671595, acc: 0.546875]  [A loss: 0.998286, acc: 0.031250]\n",
      "362: [D loss: 0.653414, acc: 0.623047]  [A loss: 0.827876, acc: 0.167969]\n",
      "363: [D loss: 0.676011, acc: 0.550781]  [A loss: 0.994085, acc: 0.046875]\n",
      "364: [D loss: 0.638090, acc: 0.673828]  [A loss: 0.855243, acc: 0.144531]\n",
      "365: [D loss: 0.667480, acc: 0.562500]  [A loss: 1.168854, acc: 0.007812]\n",
      "366: [D loss: 0.649666, acc: 0.646484]  [A loss: 0.696214, acc: 0.503906]\n",
      "367: [D loss: 0.703216, acc: 0.515625]  [A loss: 1.328347, acc: 0.000000]\n",
      "368: [D loss: 0.668528, acc: 0.576172]  [A loss: 0.653108, acc: 0.597656]\n",
      "369: [D loss: 0.718351, acc: 0.501953]  [A loss: 1.093522, acc: 0.000000]\n",
      "370: [D loss: 0.658309, acc: 0.640625]  [A loss: 0.766381, acc: 0.316406]\n",
      "371: [D loss: 0.667845, acc: 0.556641]  [A loss: 1.001051, acc: 0.031250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372: [D loss: 0.645465, acc: 0.646484]  [A loss: 0.870910, acc: 0.121094]\n",
      "373: [D loss: 0.670071, acc: 0.562500]  [A loss: 0.981300, acc: 0.050781]\n",
      "374: [D loss: 0.664055, acc: 0.619141]  [A loss: 0.914420, acc: 0.074219]\n",
      "375: [D loss: 0.661405, acc: 0.578125]  [A loss: 0.936241, acc: 0.058594]\n",
      "376: [D loss: 0.650994, acc: 0.599609]  [A loss: 0.993941, acc: 0.042969]\n",
      "377: [D loss: 0.663548, acc: 0.611328]  [A loss: 0.982531, acc: 0.054688]\n",
      "378: [D loss: 0.671103, acc: 0.611328]  [A loss: 0.968796, acc: 0.074219]\n",
      "379: [D loss: 0.657306, acc: 0.599609]  [A loss: 1.130643, acc: 0.000000]\n",
      "380: [D loss: 0.651839, acc: 0.628906]  [A loss: 0.745779, acc: 0.394531]\n",
      "381: [D loss: 0.699119, acc: 0.509766]  [A loss: 1.320012, acc: 0.000000]\n",
      "382: [D loss: 0.664011, acc: 0.599609]  [A loss: 0.585926, acc: 0.828125]\n",
      "383: [D loss: 0.756465, acc: 0.500000]  [A loss: 1.222411, acc: 0.000000]\n",
      "384: [D loss: 0.690725, acc: 0.527344]  [A loss: 0.742004, acc: 0.367188]\n",
      "385: [D loss: 0.687756, acc: 0.527344]  [A loss: 0.959299, acc: 0.066406]\n",
      "386: [D loss: 0.687837, acc: 0.558594]  [A loss: 0.871681, acc: 0.093750]\n",
      "387: [D loss: 0.665791, acc: 0.593750]  [A loss: 0.896919, acc: 0.093750]\n",
      "388: [D loss: 0.671181, acc: 0.560547]  [A loss: 0.880828, acc: 0.128906]\n",
      "389: [D loss: 0.663661, acc: 0.576172]  [A loss: 0.953964, acc: 0.058594]\n",
      "390: [D loss: 0.665142, acc: 0.623047]  [A loss: 0.865255, acc: 0.128906]\n",
      "391: [D loss: 0.666592, acc: 0.568359]  [A loss: 1.032236, acc: 0.023438]\n",
      "392: [D loss: 0.663554, acc: 0.601562]  [A loss: 0.830341, acc: 0.203125]\n",
      "393: [D loss: 0.685501, acc: 0.558594]  [A loss: 1.067313, acc: 0.031250]\n",
      "394: [D loss: 0.671489, acc: 0.585938]  [A loss: 0.820257, acc: 0.214844]\n",
      "395: [D loss: 0.674824, acc: 0.539062]  [A loss: 1.241084, acc: 0.003906]\n",
      "396: [D loss: 0.678391, acc: 0.578125]  [A loss: 0.640653, acc: 0.683594]\n",
      "397: [D loss: 0.731054, acc: 0.505859]  [A loss: 1.256537, acc: 0.000000]\n",
      "398: [D loss: 0.659449, acc: 0.595703]  [A loss: 0.621239, acc: 0.687500]\n",
      "399: [D loss: 0.741015, acc: 0.498047]  [A loss: 1.095859, acc: 0.007812]\n",
      "400: [D loss: 0.683136, acc: 0.537109]  [A loss: 0.750886, acc: 0.339844]\n",
      "401: [D loss: 0.734648, acc: 0.484375]  [A loss: 1.104997, acc: 0.015625]\n",
      "402: [D loss: 0.680999, acc: 0.593750]  [A loss: 0.779467, acc: 0.242188]\n",
      "403: [D loss: 0.685928, acc: 0.556641]  [A loss: 0.906231, acc: 0.062500]\n",
      "404: [D loss: 0.672284, acc: 0.568359]  [A loss: 0.835876, acc: 0.164062]\n",
      "405: [D loss: 0.670112, acc: 0.595703]  [A loss: 0.880569, acc: 0.093750]\n",
      "406: [D loss: 0.665106, acc: 0.603516]  [A loss: 0.903030, acc: 0.058594]\n",
      "407: [D loss: 0.680329, acc: 0.564453]  [A loss: 0.972754, acc: 0.035156]\n",
      "408: [D loss: 0.679170, acc: 0.554688]  [A loss: 0.906514, acc: 0.082031]\n",
      "409: [D loss: 0.683777, acc: 0.560547]  [A loss: 0.982594, acc: 0.039062]\n",
      "410: [D loss: 0.667414, acc: 0.583984]  [A loss: 0.840240, acc: 0.175781]\n",
      "411: [D loss: 0.676312, acc: 0.550781]  [A loss: 1.074258, acc: 0.000000]\n",
      "412: [D loss: 0.670872, acc: 0.576172]  [A loss: 0.747060, acc: 0.402344]\n",
      "413: [D loss: 0.698529, acc: 0.527344]  [A loss: 1.167276, acc: 0.003906]\n",
      "414: [D loss: 0.664185, acc: 0.587891]  [A loss: 0.674477, acc: 0.585938]\n",
      "415: [D loss: 0.724243, acc: 0.529297]  [A loss: 1.242047, acc: 0.000000]\n",
      "416: [D loss: 0.681632, acc: 0.554688]  [A loss: 0.642119, acc: 0.683594]\n",
      "417: [D loss: 0.760243, acc: 0.507812]  [A loss: 1.132546, acc: 0.011719]\n",
      "418: [D loss: 0.664684, acc: 0.601562]  [A loss: 0.725762, acc: 0.398438]\n",
      "419: [D loss: 0.691744, acc: 0.531250]  [A loss: 1.013077, acc: 0.011719]\n",
      "420: [D loss: 0.660063, acc: 0.615234]  [A loss: 0.744571, acc: 0.367188]\n",
      "421: [D loss: 0.684656, acc: 0.525391]  [A loss: 0.942374, acc: 0.054688]\n",
      "422: [D loss: 0.673981, acc: 0.558594]  [A loss: 0.829938, acc: 0.179688]\n",
      "423: [D loss: 0.671400, acc: 0.564453]  [A loss: 0.913133, acc: 0.101562]\n",
      "424: [D loss: 0.665792, acc: 0.601562]  [A loss: 0.858852, acc: 0.144531]\n",
      "425: [D loss: 0.664405, acc: 0.587891]  [A loss: 0.953806, acc: 0.042969]\n",
      "426: [D loss: 0.664712, acc: 0.603516]  [A loss: 0.838324, acc: 0.179688]\n",
      "427: [D loss: 0.680823, acc: 0.544922]  [A loss: 1.057141, acc: 0.046875]\n",
      "428: [D loss: 0.665235, acc: 0.599609]  [A loss: 0.868178, acc: 0.195312]\n",
      "429: [D loss: 0.674566, acc: 0.601562]  [A loss: 0.985808, acc: 0.027344]\n",
      "430: [D loss: 0.684104, acc: 0.562500]  [A loss: 0.942002, acc: 0.082031]\n",
      "431: [D loss: 0.682998, acc: 0.550781]  [A loss: 0.954755, acc: 0.058594]\n",
      "432: [D loss: 0.658300, acc: 0.591797]  [A loss: 0.955836, acc: 0.046875]\n",
      "433: [D loss: 0.686940, acc: 0.558594]  [A loss: 0.929853, acc: 0.085938]\n",
      "434: [D loss: 0.680143, acc: 0.562500]  [A loss: 0.910541, acc: 0.113281]\n",
      "435: [D loss: 0.683152, acc: 0.556641]  [A loss: 1.042910, acc: 0.007812]\n",
      "436: [D loss: 0.654881, acc: 0.636719]  [A loss: 0.801683, acc: 0.273438]\n",
      "437: [D loss: 0.680002, acc: 0.587891]  [A loss: 1.155903, acc: 0.023438]\n",
      "438: [D loss: 0.670217, acc: 0.607422]  [A loss: 0.678430, acc: 0.582031]\n",
      "439: [D loss: 0.725540, acc: 0.517578]  [A loss: 1.343348, acc: 0.000000]\n",
      "440: [D loss: 0.683916, acc: 0.535156]  [A loss: 0.562925, acc: 0.835938]\n",
      "441: [D loss: 0.753921, acc: 0.501953]  [A loss: 1.068363, acc: 0.015625]\n",
      "442: [D loss: 0.674373, acc: 0.582031]  [A loss: 0.755225, acc: 0.359375]\n",
      "443: [D loss: 0.687348, acc: 0.537109]  [A loss: 1.049233, acc: 0.019531]\n",
      "444: [D loss: 0.663347, acc: 0.583984]  [A loss: 0.720682, acc: 0.437500]\n",
      "445: [D loss: 0.699866, acc: 0.515625]  [A loss: 0.965058, acc: 0.046875]\n",
      "446: [D loss: 0.664320, acc: 0.589844]  [A loss: 0.788171, acc: 0.257812]\n",
      "447: [D loss: 0.677736, acc: 0.560547]  [A loss: 0.924234, acc: 0.082031]\n",
      "448: [D loss: 0.675999, acc: 0.578125]  [A loss: 0.856532, acc: 0.144531]\n",
      "449: [D loss: 0.668902, acc: 0.576172]  [A loss: 0.887792, acc: 0.109375]\n",
      "450: [D loss: 0.657909, acc: 0.628906]  [A loss: 0.837311, acc: 0.160156]\n",
      "451: [D loss: 0.669723, acc: 0.580078]  [A loss: 0.926697, acc: 0.089844]\n",
      "452: [D loss: 0.672369, acc: 0.591797]  [A loss: 0.931320, acc: 0.062500]\n",
      "453: [D loss: 0.670764, acc: 0.605469]  [A loss: 0.921716, acc: 0.089844]\n",
      "454: [D loss: 0.676045, acc: 0.587891]  [A loss: 0.928297, acc: 0.066406]\n",
      "455: [D loss: 0.676952, acc: 0.564453]  [A loss: 0.956355, acc: 0.054688]\n",
      "456: [D loss: 0.656788, acc: 0.619141]  [A loss: 0.843309, acc: 0.203125]\n",
      "457: [D loss: 0.681600, acc: 0.570312]  [A loss: 1.017908, acc: 0.042969]\n",
      "458: [D loss: 0.671730, acc: 0.578125]  [A loss: 0.821150, acc: 0.253906]\n",
      "459: [D loss: 0.684346, acc: 0.560547]  [A loss: 1.087552, acc: 0.019531]\n",
      "460: [D loss: 0.661835, acc: 0.601562]  [A loss: 0.733560, acc: 0.410156]\n",
      "461: [D loss: 0.691200, acc: 0.558594]  [A loss: 1.322726, acc: 0.003906]\n",
      "462: [D loss: 0.683736, acc: 0.558594]  [A loss: 0.547249, acc: 0.839844]\n",
      "463: [D loss: 0.788418, acc: 0.500000]  [A loss: 1.079562, acc: 0.015625]\n",
      "464: [D loss: 0.665693, acc: 0.593750]  [A loss: 0.748247, acc: 0.367188]\n",
      "465: [D loss: 0.683758, acc: 0.552734]  [A loss: 0.948087, acc: 0.054688]\n",
      "466: [D loss: 0.662038, acc: 0.617188]  [A loss: 0.780085, acc: 0.292969]\n",
      "467: [D loss: 0.694611, acc: 0.527344]  [A loss: 0.959514, acc: 0.054688]\n",
      "468: [D loss: 0.658601, acc: 0.625000]  [A loss: 0.781633, acc: 0.308594]\n",
      "469: [D loss: 0.693666, acc: 0.556641]  [A loss: 0.993880, acc: 0.035156]\n",
      "470: [D loss: 0.665654, acc: 0.601562]  [A loss: 0.779221, acc: 0.324219]\n",
      "471: [D loss: 0.684646, acc: 0.552734]  [A loss: 0.997976, acc: 0.035156]\n",
      "472: [D loss: 0.678208, acc: 0.617188]  [A loss: 0.773202, acc: 0.316406]\n",
      "473: [D loss: 0.688585, acc: 0.539062]  [A loss: 1.020852, acc: 0.058594]\n",
      "474: [D loss: 0.669626, acc: 0.582031]  [A loss: 0.726142, acc: 0.429688]\n",
      "475: [D loss: 0.697929, acc: 0.535156]  [A loss: 0.950222, acc: 0.035156]\n",
      "476: [D loss: 0.674501, acc: 0.558594]  [A loss: 0.769751, acc: 0.335938]\n",
      "477: [D loss: 0.685524, acc: 0.550781]  [A loss: 1.035246, acc: 0.015625]\n",
      "478: [D loss: 0.666847, acc: 0.599609]  [A loss: 0.780541, acc: 0.328125]\n",
      "479: [D loss: 0.681045, acc: 0.537109]  [A loss: 1.005014, acc: 0.046875]\n",
      "480: [D loss: 0.665436, acc: 0.595703]  [A loss: 0.798829, acc: 0.292969]\n",
      "481: [D loss: 0.699566, acc: 0.537109]  [A loss: 1.066529, acc: 0.023438]\n",
      "482: [D loss: 0.676101, acc: 0.576172]  [A loss: 0.720969, acc: 0.460938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483: [D loss: 0.693694, acc: 0.541016]  [A loss: 1.076158, acc: 0.011719]\n",
      "484: [D loss: 0.671190, acc: 0.599609]  [A loss: 0.716680, acc: 0.445312]\n",
      "485: [D loss: 0.706909, acc: 0.521484]  [A loss: 1.075254, acc: 0.019531]\n",
      "486: [D loss: 0.663455, acc: 0.574219]  [A loss: 0.731239, acc: 0.429688]\n",
      "487: [D loss: 0.703284, acc: 0.541016]  [A loss: 1.020084, acc: 0.027344]\n",
      "488: [D loss: 0.681932, acc: 0.566406]  [A loss: 0.782495, acc: 0.296875]\n",
      "489: [D loss: 0.703195, acc: 0.525391]  [A loss: 1.065393, acc: 0.027344]\n",
      "490: [D loss: 0.677402, acc: 0.570312]  [A loss: 0.781900, acc: 0.316406]\n",
      "491: [D loss: 0.687179, acc: 0.542969]  [A loss: 1.006993, acc: 0.031250]\n",
      "492: [D loss: 0.672355, acc: 0.562500]  [A loss: 0.769474, acc: 0.359375]\n",
      "493: [D loss: 0.681294, acc: 0.539062]  [A loss: 0.959120, acc: 0.031250]\n",
      "494: [D loss: 0.673038, acc: 0.593750]  [A loss: 0.776806, acc: 0.281250]\n",
      "495: [D loss: 0.687491, acc: 0.544922]  [A loss: 0.997865, acc: 0.054688]\n",
      "496: [D loss: 0.665964, acc: 0.625000]  [A loss: 0.717952, acc: 0.460938]\n",
      "497: [D loss: 0.704655, acc: 0.507812]  [A loss: 1.038095, acc: 0.023438]\n",
      "498: [D loss: 0.673109, acc: 0.576172]  [A loss: 0.766269, acc: 0.347656]\n",
      "499: [D loss: 0.693354, acc: 0.531250]  [A loss: 1.022734, acc: 0.007812]\n",
      "500: [D loss: 0.669670, acc: 0.595703]  [A loss: 0.747251, acc: 0.394531]\n",
      "501: [D loss: 0.693901, acc: 0.541016]  [A loss: 1.013028, acc: 0.023438]\n",
      "502: [D loss: 0.663063, acc: 0.621094]  [A loss: 0.765111, acc: 0.339844]\n",
      "503: [D loss: 0.699578, acc: 0.525391]  [A loss: 1.009595, acc: 0.031250]\n",
      "504: [D loss: 0.665445, acc: 0.605469]  [A loss: 0.777125, acc: 0.335938]\n",
      "505: [D loss: 0.698291, acc: 0.542969]  [A loss: 0.991534, acc: 0.039062]\n",
      "506: [D loss: 0.658642, acc: 0.601562]  [A loss: 0.815538, acc: 0.253906]\n",
      "507: [D loss: 0.679719, acc: 0.583984]  [A loss: 1.016452, acc: 0.027344]\n",
      "508: [D loss: 0.671959, acc: 0.611328]  [A loss: 0.748148, acc: 0.398438]\n",
      "509: [D loss: 0.702293, acc: 0.527344]  [A loss: 1.069621, acc: 0.003906]\n",
      "510: [D loss: 0.677964, acc: 0.570312]  [A loss: 0.728856, acc: 0.457031]\n",
      "511: [D loss: 0.695306, acc: 0.533203]  [A loss: 1.000598, acc: 0.050781]\n",
      "512: [D loss: 0.672949, acc: 0.583984]  [A loss: 0.782450, acc: 0.324219]\n",
      "513: [D loss: 0.674228, acc: 0.556641]  [A loss: 0.915192, acc: 0.085938]\n",
      "514: [D loss: 0.670773, acc: 0.591797]  [A loss: 0.779995, acc: 0.328125]\n",
      "515: [D loss: 0.691958, acc: 0.539062]  [A loss: 1.056116, acc: 0.046875]\n",
      "516: [D loss: 0.674045, acc: 0.580078]  [A loss: 0.798999, acc: 0.234375]\n",
      "517: [D loss: 0.687116, acc: 0.548828]  [A loss: 0.955669, acc: 0.042969]\n",
      "518: [D loss: 0.662964, acc: 0.621094]  [A loss: 0.801093, acc: 0.273438]\n",
      "519: [D loss: 0.682753, acc: 0.568359]  [A loss: 0.993112, acc: 0.046875]\n",
      "520: [D loss: 0.673168, acc: 0.585938]  [A loss: 0.803782, acc: 0.277344]\n",
      "521: [D loss: 0.685939, acc: 0.548828]  [A loss: 0.993642, acc: 0.027344]\n",
      "522: [D loss: 0.663501, acc: 0.595703]  [A loss: 0.801962, acc: 0.242188]\n",
      "523: [D loss: 0.683282, acc: 0.533203]  [A loss: 1.051131, acc: 0.046875]\n",
      "524: [D loss: 0.665828, acc: 0.578125]  [A loss: 0.732935, acc: 0.437500]\n",
      "525: [D loss: 0.684586, acc: 0.535156]  [A loss: 1.046217, acc: 0.015625]\n",
      "526: [D loss: 0.674730, acc: 0.580078]  [A loss: 0.713923, acc: 0.468750]\n",
      "527: [D loss: 0.693460, acc: 0.527344]  [A loss: 1.051175, acc: 0.031250]\n",
      "528: [D loss: 0.662024, acc: 0.605469]  [A loss: 0.720410, acc: 0.468750]\n",
      "529: [D loss: 0.712925, acc: 0.537109]  [A loss: 1.058169, acc: 0.027344]\n",
      "530: [D loss: 0.672527, acc: 0.556641]  [A loss: 0.730793, acc: 0.417969]\n",
      "531: [D loss: 0.689645, acc: 0.548828]  [A loss: 0.991242, acc: 0.062500]\n",
      "532: [D loss: 0.680383, acc: 0.560547]  [A loss: 0.820252, acc: 0.191406]\n",
      "533: [D loss: 0.693987, acc: 0.544922]  [A loss: 0.923917, acc: 0.089844]\n",
      "534: [D loss: 0.672818, acc: 0.597656]  [A loss: 0.845264, acc: 0.183594]\n",
      "535: [D loss: 0.673217, acc: 0.583984]  [A loss: 0.959157, acc: 0.062500]\n",
      "536: [D loss: 0.674668, acc: 0.560547]  [A loss: 0.822107, acc: 0.210938]\n",
      "537: [D loss: 0.680000, acc: 0.562500]  [A loss: 0.885586, acc: 0.140625]\n",
      "538: [D loss: 0.666497, acc: 0.603516]  [A loss: 0.882697, acc: 0.109375]\n",
      "539: [D loss: 0.672614, acc: 0.570312]  [A loss: 0.901847, acc: 0.109375]\n",
      "540: [D loss: 0.677160, acc: 0.564453]  [A loss: 0.935238, acc: 0.085938]\n",
      "541: [D loss: 0.682606, acc: 0.593750]  [A loss: 0.910376, acc: 0.144531]\n",
      "542: [D loss: 0.676452, acc: 0.570312]  [A loss: 0.897050, acc: 0.121094]\n",
      "543: [D loss: 0.677386, acc: 0.560547]  [A loss: 0.942784, acc: 0.085938]\n",
      "544: [D loss: 0.665621, acc: 0.583984]  [A loss: 0.837204, acc: 0.187500]\n",
      "545: [D loss: 0.667222, acc: 0.597656]  [A loss: 1.019588, acc: 0.031250]\n",
      "546: [D loss: 0.664976, acc: 0.613281]  [A loss: 0.801578, acc: 0.292969]\n",
      "547: [D loss: 0.681372, acc: 0.527344]  [A loss: 1.139604, acc: 0.019531]\n",
      "548: [D loss: 0.663590, acc: 0.605469]  [A loss: 0.685810, acc: 0.546875]\n",
      "549: [D loss: 0.717625, acc: 0.507812]  [A loss: 1.216421, acc: 0.000000]\n",
      "550: [D loss: 0.674796, acc: 0.580078]  [A loss: 0.644381, acc: 0.656250]\n",
      "551: [D loss: 0.723440, acc: 0.509766]  [A loss: 1.090217, acc: 0.011719]\n",
      "552: [D loss: 0.665620, acc: 0.625000]  [A loss: 0.690572, acc: 0.546875]\n",
      "553: [D loss: 0.698576, acc: 0.531250]  [A loss: 0.935701, acc: 0.062500]\n",
      "554: [D loss: 0.679371, acc: 0.544922]  [A loss: 0.865397, acc: 0.164062]\n",
      "555: [D loss: 0.666059, acc: 0.576172]  [A loss: 0.841762, acc: 0.191406]\n",
      "556: [D loss: 0.673737, acc: 0.568359]  [A loss: 0.918320, acc: 0.105469]\n",
      "557: [D loss: 0.670477, acc: 0.636719]  [A loss: 0.857137, acc: 0.148438]\n",
      "558: [D loss: 0.683546, acc: 0.568359]  [A loss: 0.838142, acc: 0.222656]\n",
      "559: [D loss: 0.686639, acc: 0.546875]  [A loss: 0.945321, acc: 0.097656]\n",
      "560: [D loss: 0.666656, acc: 0.591797]  [A loss: 0.840941, acc: 0.218750]\n",
      "561: [D loss: 0.660120, acc: 0.611328]  [A loss: 0.924040, acc: 0.097656]\n",
      "562: [D loss: 0.666101, acc: 0.619141]  [A loss: 0.756312, acc: 0.367188]\n",
      "563: [D loss: 0.693472, acc: 0.527344]  [A loss: 1.003400, acc: 0.062500]\n",
      "564: [D loss: 0.673977, acc: 0.587891]  [A loss: 0.819721, acc: 0.203125]\n",
      "565: [D loss: 0.669010, acc: 0.587891]  [A loss: 1.016045, acc: 0.031250]\n",
      "566: [D loss: 0.660723, acc: 0.621094]  [A loss: 0.823631, acc: 0.210938]\n",
      "567: [D loss: 0.672337, acc: 0.576172]  [A loss: 0.916952, acc: 0.093750]\n",
      "568: [D loss: 0.670480, acc: 0.601562]  [A loss: 0.876504, acc: 0.152344]\n",
      "569: [D loss: 0.675660, acc: 0.550781]  [A loss: 0.961939, acc: 0.078125]\n",
      "570: [D loss: 0.664864, acc: 0.580078]  [A loss: 0.887207, acc: 0.152344]\n",
      "571: [D loss: 0.681090, acc: 0.533203]  [A loss: 1.052140, acc: 0.015625]\n",
      "572: [D loss: 0.655691, acc: 0.652344]  [A loss: 0.780558, acc: 0.316406]\n",
      "573: [D loss: 0.677631, acc: 0.544922]  [A loss: 1.044385, acc: 0.031250]\n",
      "574: [D loss: 0.653058, acc: 0.609375]  [A loss: 0.809226, acc: 0.289062]\n",
      "575: [D loss: 0.682909, acc: 0.578125]  [A loss: 1.116177, acc: 0.027344]\n",
      "576: [D loss: 0.668555, acc: 0.593750]  [A loss: 0.694544, acc: 0.562500]\n",
      "577: [D loss: 0.712179, acc: 0.509766]  [A loss: 1.167024, acc: 0.015625]\n",
      "578: [D loss: 0.669208, acc: 0.574219]  [A loss: 0.700923, acc: 0.500000]\n",
      "579: [D loss: 0.697950, acc: 0.531250]  [A loss: 1.015395, acc: 0.070312]\n",
      "580: [D loss: 0.673322, acc: 0.583984]  [A loss: 0.797694, acc: 0.273438]\n",
      "581: [D loss: 0.694039, acc: 0.580078]  [A loss: 0.964328, acc: 0.050781]\n",
      "582: [D loss: 0.675824, acc: 0.572266]  [A loss: 0.812365, acc: 0.269531]\n",
      "583: [D loss: 0.685770, acc: 0.564453]  [A loss: 0.941243, acc: 0.097656]\n",
      "584: [D loss: 0.673861, acc: 0.583984]  [A loss: 0.889048, acc: 0.136719]\n",
      "585: [D loss: 0.666487, acc: 0.609375]  [A loss: 0.900612, acc: 0.136719]\n",
      "586: [D loss: 0.677031, acc: 0.552734]  [A loss: 0.925611, acc: 0.066406]\n",
      "587: [D loss: 0.653542, acc: 0.617188]  [A loss: 0.863917, acc: 0.175781]\n",
      "588: [D loss: 0.673566, acc: 0.572266]  [A loss: 1.009187, acc: 0.042969]\n",
      "589: [D loss: 0.674558, acc: 0.578125]  [A loss: 0.771536, acc: 0.347656]\n",
      "590: [D loss: 0.680249, acc: 0.544922]  [A loss: 1.067256, acc: 0.027344]\n",
      "591: [D loss: 0.662008, acc: 0.605469]  [A loss: 0.752761, acc: 0.378906]\n",
      "592: [D loss: 0.683141, acc: 0.552734]  [A loss: 0.991290, acc: 0.082031]\n",
      "593: [D loss: 0.671140, acc: 0.560547]  [A loss: 0.903434, acc: 0.128906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594: [D loss: 0.676077, acc: 0.570312]  [A loss: 0.872827, acc: 0.156250]\n",
      "595: [D loss: 0.671490, acc: 0.582031]  [A loss: 0.952405, acc: 0.089844]\n",
      "596: [D loss: 0.663111, acc: 0.595703]  [A loss: 0.882231, acc: 0.191406]\n",
      "597: [D loss: 0.673196, acc: 0.591797]  [A loss: 0.924565, acc: 0.128906]\n",
      "598: [D loss: 0.659428, acc: 0.623047]  [A loss: 0.928148, acc: 0.121094]\n",
      "599: [D loss: 0.664989, acc: 0.599609]  [A loss: 0.809996, acc: 0.261719]\n",
      "600: [D loss: 0.676105, acc: 0.580078]  [A loss: 1.144431, acc: 0.019531]\n",
      "601: [D loss: 0.668078, acc: 0.583984]  [A loss: 0.668424, acc: 0.613281]\n",
      "602: [D loss: 0.716808, acc: 0.539062]  [A loss: 1.219359, acc: 0.015625]\n",
      "603: [D loss: 0.668738, acc: 0.609375]  [A loss: 0.680252, acc: 0.531250]\n",
      "604: [D loss: 0.721461, acc: 0.519531]  [A loss: 1.033678, acc: 0.046875]\n",
      "605: [D loss: 0.679294, acc: 0.572266]  [A loss: 0.785514, acc: 0.296875]\n",
      "606: [D loss: 0.694822, acc: 0.550781]  [A loss: 0.983625, acc: 0.058594]\n",
      "607: [D loss: 0.659287, acc: 0.599609]  [A loss: 0.870771, acc: 0.187500]\n",
      "608: [D loss: 0.662211, acc: 0.611328]  [A loss: 0.938953, acc: 0.101562]\n",
      "609: [D loss: 0.669698, acc: 0.572266]  [A loss: 0.871683, acc: 0.164062]\n",
      "610: [D loss: 0.675622, acc: 0.562500]  [A loss: 0.929255, acc: 0.093750]\n",
      "611: [D loss: 0.657371, acc: 0.603516]  [A loss: 0.860427, acc: 0.179688]\n",
      "612: [D loss: 0.666110, acc: 0.587891]  [A loss: 0.933395, acc: 0.125000]\n",
      "613: [D loss: 0.667332, acc: 0.580078]  [A loss: 0.961939, acc: 0.070312]\n",
      "614: [D loss: 0.648119, acc: 0.658203]  [A loss: 0.829066, acc: 0.246094]\n",
      "615: [D loss: 0.694887, acc: 0.546875]  [A loss: 1.041449, acc: 0.046875]\n",
      "616: [D loss: 0.668729, acc: 0.580078]  [A loss: 0.739093, acc: 0.433594]\n",
      "617: [D loss: 0.696024, acc: 0.546875]  [A loss: 1.100418, acc: 0.023438]\n",
      "618: [D loss: 0.659436, acc: 0.630859]  [A loss: 0.771639, acc: 0.324219]\n",
      "619: [D loss: 0.717280, acc: 0.525391]  [A loss: 1.085439, acc: 0.027344]\n",
      "620: [D loss: 0.651009, acc: 0.625000]  [A loss: 0.766465, acc: 0.328125]\n",
      "621: [D loss: 0.686981, acc: 0.552734]  [A loss: 1.037078, acc: 0.046875]\n",
      "622: [D loss: 0.665262, acc: 0.597656]  [A loss: 0.756359, acc: 0.402344]\n",
      "623: [D loss: 0.701687, acc: 0.537109]  [A loss: 1.066052, acc: 0.050781]\n",
      "624: [D loss: 0.668062, acc: 0.595703]  [A loss: 0.775406, acc: 0.347656]\n",
      "625: [D loss: 0.696386, acc: 0.533203]  [A loss: 1.062045, acc: 0.046875]\n",
      "626: [D loss: 0.665904, acc: 0.609375]  [A loss: 0.761618, acc: 0.367188]\n",
      "627: [D loss: 0.666194, acc: 0.597656]  [A loss: 0.979501, acc: 0.066406]\n",
      "628: [D loss: 0.656632, acc: 0.611328]  [A loss: 0.804567, acc: 0.281250]\n",
      "629: [D loss: 0.689219, acc: 0.542969]  [A loss: 1.032330, acc: 0.058594]\n",
      "630: [D loss: 0.674092, acc: 0.578125]  [A loss: 0.797375, acc: 0.277344]\n",
      "631: [D loss: 0.676516, acc: 0.576172]  [A loss: 0.983089, acc: 0.109375]\n",
      "632: [D loss: 0.665675, acc: 0.589844]  [A loss: 0.793885, acc: 0.285156]\n",
      "633: [D loss: 0.670724, acc: 0.591797]  [A loss: 0.940780, acc: 0.109375]\n",
      "634: [D loss: 0.663471, acc: 0.615234]  [A loss: 0.833245, acc: 0.242188]\n",
      "635: [D loss: 0.686846, acc: 0.554688]  [A loss: 1.010130, acc: 0.066406]\n",
      "636: [D loss: 0.660096, acc: 0.593750]  [A loss: 0.808559, acc: 0.269531]\n",
      "637: [D loss: 0.678624, acc: 0.564453]  [A loss: 0.999376, acc: 0.058594]\n",
      "638: [D loss: 0.658653, acc: 0.607422]  [A loss: 0.800503, acc: 0.343750]\n",
      "639: [D loss: 0.676760, acc: 0.591797]  [A loss: 1.083844, acc: 0.023438]\n",
      "640: [D loss: 0.665220, acc: 0.599609]  [A loss: 0.745922, acc: 0.421875]\n",
      "641: [D loss: 0.701316, acc: 0.513672]  [A loss: 1.079668, acc: 0.027344]\n",
      "642: [D loss: 0.662865, acc: 0.597656]  [A loss: 0.742971, acc: 0.421875]\n",
      "643: [D loss: 0.692175, acc: 0.525391]  [A loss: 1.054084, acc: 0.070312]\n",
      "644: [D loss: 0.676487, acc: 0.576172]  [A loss: 0.892237, acc: 0.175781]\n",
      "645: [D loss: 0.674800, acc: 0.582031]  [A loss: 0.922383, acc: 0.113281]\n",
      "646: [D loss: 0.673561, acc: 0.580078]  [A loss: 0.943589, acc: 0.078125]\n",
      "647: [D loss: 0.659572, acc: 0.591797]  [A loss: 0.798476, acc: 0.285156]\n",
      "648: [D loss: 0.693799, acc: 0.539062]  [A loss: 1.037867, acc: 0.050781]\n",
      "649: [D loss: 0.651373, acc: 0.611328]  [A loss: 0.898160, acc: 0.156250]\n",
      "650: [D loss: 0.677676, acc: 0.595703]  [A loss: 0.995928, acc: 0.066406]\n",
      "651: [D loss: 0.669208, acc: 0.609375]  [A loss: 0.817223, acc: 0.265625]\n",
      "652: [D loss: 0.682915, acc: 0.574219]  [A loss: 0.971348, acc: 0.105469]\n",
      "653: [D loss: 0.669686, acc: 0.591797]  [A loss: 0.778384, acc: 0.316406]\n",
      "654: [D loss: 0.727552, acc: 0.505859]  [A loss: 1.186932, acc: 0.015625]\n",
      "655: [D loss: 0.679741, acc: 0.550781]  [A loss: 0.639633, acc: 0.687500]\n",
      "656: [D loss: 0.701609, acc: 0.537109]  [A loss: 1.133143, acc: 0.027344]\n",
      "657: [D loss: 0.672456, acc: 0.574219]  [A loss: 0.738069, acc: 0.410156]\n",
      "658: [D loss: 0.693388, acc: 0.544922]  [A loss: 1.040884, acc: 0.062500]\n",
      "659: [D loss: 0.658918, acc: 0.617188]  [A loss: 0.798740, acc: 0.296875]\n",
      "660: [D loss: 0.673563, acc: 0.589844]  [A loss: 0.936518, acc: 0.105469]\n",
      "661: [D loss: 0.668944, acc: 0.591797]  [A loss: 0.895865, acc: 0.175781]\n",
      "662: [D loss: 0.698134, acc: 0.554688]  [A loss: 0.999330, acc: 0.050781]\n",
      "663: [D loss: 0.670586, acc: 0.585938]  [A loss: 0.821854, acc: 0.273438]\n",
      "664: [D loss: 0.666039, acc: 0.576172]  [A loss: 0.951212, acc: 0.093750]\n",
      "665: [D loss: 0.671726, acc: 0.595703]  [A loss: 0.871134, acc: 0.195312]\n",
      "666: [D loss: 0.664428, acc: 0.603516]  [A loss: 0.940510, acc: 0.121094]\n",
      "667: [D loss: 0.671828, acc: 0.580078]  [A loss: 0.922530, acc: 0.132812]\n",
      "668: [D loss: 0.680841, acc: 0.578125]  [A loss: 0.856252, acc: 0.203125]\n",
      "669: [D loss: 0.675319, acc: 0.583984]  [A loss: 0.971352, acc: 0.097656]\n",
      "670: [D loss: 0.670164, acc: 0.589844]  [A loss: 0.831975, acc: 0.246094]\n",
      "671: [D loss: 0.675240, acc: 0.556641]  [A loss: 1.002728, acc: 0.105469]\n",
      "672: [D loss: 0.666316, acc: 0.576172]  [A loss: 0.853097, acc: 0.238281]\n",
      "673: [D loss: 0.677690, acc: 0.558594]  [A loss: 1.083186, acc: 0.054688]\n",
      "674: [D loss: 0.668354, acc: 0.587891]  [A loss: 0.724753, acc: 0.457031]\n",
      "675: [D loss: 0.707985, acc: 0.542969]  [A loss: 1.167121, acc: 0.035156]\n",
      "676: [D loss: 0.679508, acc: 0.582031]  [A loss: 0.691377, acc: 0.539062]\n",
      "677: [D loss: 0.719120, acc: 0.490234]  [A loss: 1.015790, acc: 0.066406]\n",
      "678: [D loss: 0.675790, acc: 0.560547]  [A loss: 0.816360, acc: 0.273438]\n",
      "679: [D loss: 0.690843, acc: 0.554688]  [A loss: 0.980633, acc: 0.070312]\n",
      "680: [D loss: 0.671600, acc: 0.570312]  [A loss: 0.815514, acc: 0.242188]\n",
      "681: [D loss: 0.669692, acc: 0.589844]  [A loss: 0.943877, acc: 0.101562]\n",
      "682: [D loss: 0.667817, acc: 0.601562]  [A loss: 0.860128, acc: 0.203125]\n",
      "683: [D loss: 0.670504, acc: 0.576172]  [A loss: 0.952633, acc: 0.148438]\n",
      "684: [D loss: 0.690796, acc: 0.539062]  [A loss: 0.911918, acc: 0.117188]\n",
      "685: [D loss: 0.675265, acc: 0.582031]  [A loss: 0.943616, acc: 0.074219]\n",
      "686: [D loss: 0.664247, acc: 0.599609]  [A loss: 0.902856, acc: 0.144531]\n",
      "687: [D loss: 0.680737, acc: 0.591797]  [A loss: 0.959828, acc: 0.136719]\n",
      "688: [D loss: 0.664929, acc: 0.599609]  [A loss: 0.859667, acc: 0.210938]\n",
      "689: [D loss: 0.683081, acc: 0.580078]  [A loss: 1.017043, acc: 0.054688]\n",
      "690: [D loss: 0.671098, acc: 0.574219]  [A loss: 0.850030, acc: 0.234375]\n",
      "691: [D loss: 0.665405, acc: 0.605469]  [A loss: 1.028752, acc: 0.074219]\n",
      "692: [D loss: 0.674986, acc: 0.580078]  [A loss: 0.814806, acc: 0.273438]\n",
      "693: [D loss: 0.704847, acc: 0.546875]  [A loss: 1.188323, acc: 0.007812]\n",
      "694: [D loss: 0.667949, acc: 0.601562]  [A loss: 0.666794, acc: 0.613281]\n",
      "695: [D loss: 0.705709, acc: 0.517578]  [A loss: 1.081084, acc: 0.046875]\n",
      "696: [D loss: 0.670864, acc: 0.558594]  [A loss: 0.778783, acc: 0.386719]\n",
      "697: [D loss: 0.703331, acc: 0.546875]  [A loss: 1.073261, acc: 0.050781]\n",
      "698: [D loss: 0.667753, acc: 0.591797]  [A loss: 0.720785, acc: 0.429688]\n",
      "699: [D loss: 0.693993, acc: 0.525391]  [A loss: 1.026930, acc: 0.046875]\n",
      "700: [D loss: 0.666353, acc: 0.591797]  [A loss: 0.763724, acc: 0.367188]\n",
      "701: [D loss: 0.694095, acc: 0.544922]  [A loss: 1.044886, acc: 0.062500]\n",
      "702: [D loss: 0.654140, acc: 0.611328]  [A loss: 0.769320, acc: 0.378906]\n",
      "703: [D loss: 0.704220, acc: 0.556641]  [A loss: 1.039588, acc: 0.078125]\n",
      "704: [D loss: 0.678264, acc: 0.568359]  [A loss: 0.778662, acc: 0.324219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705: [D loss: 0.683855, acc: 0.556641]  [A loss: 0.996829, acc: 0.062500]\n",
      "706: [D loss: 0.673024, acc: 0.593750]  [A loss: 0.779714, acc: 0.371094]\n",
      "707: [D loss: 0.695169, acc: 0.560547]  [A loss: 1.024828, acc: 0.035156]\n",
      "708: [D loss: 0.655932, acc: 0.625000]  [A loss: 0.834918, acc: 0.253906]\n",
      "709: [D loss: 0.679093, acc: 0.546875]  [A loss: 0.999627, acc: 0.070312]\n",
      "710: [D loss: 0.665629, acc: 0.572266]  [A loss: 0.814311, acc: 0.285156]\n",
      "711: [D loss: 0.680205, acc: 0.580078]  [A loss: 0.986161, acc: 0.109375]\n",
      "712: [D loss: 0.668340, acc: 0.601562]  [A loss: 0.876526, acc: 0.238281]\n",
      "713: [D loss: 0.674560, acc: 0.562500]  [A loss: 1.028588, acc: 0.066406]\n",
      "714: [D loss: 0.664305, acc: 0.605469]  [A loss: 0.838766, acc: 0.246094]\n",
      "715: [D loss: 0.653806, acc: 0.580078]  [A loss: 1.003376, acc: 0.085938]\n",
      "716: [D loss: 0.683510, acc: 0.550781]  [A loss: 0.900239, acc: 0.167969]\n",
      "717: [D loss: 0.693369, acc: 0.546875]  [A loss: 1.066222, acc: 0.046875]\n",
      "718: [D loss: 0.653538, acc: 0.626953]  [A loss: 0.821777, acc: 0.234375]\n",
      "719: [D loss: 0.695675, acc: 0.531250]  [A loss: 1.128834, acc: 0.031250]\n",
      "720: [D loss: 0.674506, acc: 0.560547]  [A loss: 0.732451, acc: 0.437500]\n",
      "721: [D loss: 0.687783, acc: 0.542969]  [A loss: 1.134566, acc: 0.042969]\n",
      "722: [D loss: 0.694412, acc: 0.541016]  [A loss: 0.693683, acc: 0.527344]\n",
      "723: [D loss: 0.696990, acc: 0.542969]  [A loss: 1.043804, acc: 0.062500]\n",
      "724: [D loss: 0.673146, acc: 0.560547]  [A loss: 0.733644, acc: 0.441406]\n",
      "725: [D loss: 0.701754, acc: 0.535156]  [A loss: 1.055954, acc: 0.058594]\n",
      "726: [D loss: 0.676024, acc: 0.558594]  [A loss: 0.740278, acc: 0.414062]\n",
      "727: [D loss: 0.697532, acc: 0.546875]  [A loss: 1.054164, acc: 0.062500]\n",
      "728: [D loss: 0.671337, acc: 0.560547]  [A loss: 0.799400, acc: 0.335938]\n",
      "729: [D loss: 0.703868, acc: 0.539062]  [A loss: 1.021889, acc: 0.074219]\n",
      "730: [D loss: 0.660605, acc: 0.597656]  [A loss: 0.829578, acc: 0.242188]\n",
      "731: [D loss: 0.678108, acc: 0.564453]  [A loss: 0.924527, acc: 0.140625]\n",
      "732: [D loss: 0.669647, acc: 0.601562]  [A loss: 0.823387, acc: 0.269531]\n",
      "733: [D loss: 0.681328, acc: 0.546875]  [A loss: 1.001891, acc: 0.093750]\n",
      "734: [D loss: 0.683269, acc: 0.572266]  [A loss: 0.883682, acc: 0.156250]\n",
      "735: [D loss: 0.690000, acc: 0.556641]  [A loss: 0.970313, acc: 0.109375]\n",
      "736: [D loss: 0.679052, acc: 0.574219]  [A loss: 0.835611, acc: 0.210938]\n",
      "737: [D loss: 0.681925, acc: 0.572266]  [A loss: 0.997546, acc: 0.093750]\n",
      "738: [D loss: 0.661436, acc: 0.617188]  [A loss: 0.896267, acc: 0.164062]\n",
      "739: [D loss: 0.681927, acc: 0.570312]  [A loss: 0.947125, acc: 0.093750]\n",
      "740: [D loss: 0.663429, acc: 0.599609]  [A loss: 0.777617, acc: 0.347656]\n",
      "741: [D loss: 0.681957, acc: 0.570312]  [A loss: 1.080580, acc: 0.046875]\n",
      "742: [D loss: 0.664669, acc: 0.589844]  [A loss: 0.795481, acc: 0.316406]\n",
      "743: [D loss: 0.692992, acc: 0.560547]  [A loss: 0.990651, acc: 0.070312]\n",
      "744: [D loss: 0.662320, acc: 0.611328]  [A loss: 0.798824, acc: 0.308594]\n",
      "745: [D loss: 0.679171, acc: 0.578125]  [A loss: 1.037427, acc: 0.054688]\n",
      "746: [D loss: 0.670389, acc: 0.603516]  [A loss: 0.823612, acc: 0.308594]\n",
      "747: [D loss: 0.690238, acc: 0.564453]  [A loss: 1.084473, acc: 0.019531]\n",
      "748: [D loss: 0.656534, acc: 0.621094]  [A loss: 0.783229, acc: 0.335938]\n",
      "749: [D loss: 0.692004, acc: 0.554688]  [A loss: 1.078808, acc: 0.031250]\n",
      "750: [D loss: 0.671102, acc: 0.585938]  [A loss: 0.792217, acc: 0.335938]\n",
      "751: [D loss: 0.696866, acc: 0.558594]  [A loss: 1.072104, acc: 0.070312]\n",
      "752: [D loss: 0.671250, acc: 0.589844]  [A loss: 0.746564, acc: 0.410156]\n",
      "753: [D loss: 0.686246, acc: 0.558594]  [A loss: 1.063692, acc: 0.078125]\n",
      "754: [D loss: 0.677822, acc: 0.570312]  [A loss: 0.797095, acc: 0.351562]\n",
      "755: [D loss: 0.706276, acc: 0.531250]  [A loss: 1.038442, acc: 0.078125]\n",
      "756: [D loss: 0.687737, acc: 0.542969]  [A loss: 0.790812, acc: 0.335938]\n",
      "757: [D loss: 0.693735, acc: 0.541016]  [A loss: 1.015960, acc: 0.085938]\n",
      "758: [D loss: 0.672967, acc: 0.578125]  [A loss: 0.761003, acc: 0.402344]\n",
      "759: [D loss: 0.695129, acc: 0.548828]  [A loss: 1.079455, acc: 0.042969]\n",
      "760: [D loss: 0.665841, acc: 0.603516]  [A loss: 0.800018, acc: 0.304688]\n",
      "761: [D loss: 0.694198, acc: 0.535156]  [A loss: 1.086047, acc: 0.039062]\n",
      "762: [D loss: 0.677452, acc: 0.568359]  [A loss: 0.829735, acc: 0.238281]\n",
      "763: [D loss: 0.672595, acc: 0.572266]  [A loss: 0.947008, acc: 0.128906]\n",
      "764: [D loss: 0.666666, acc: 0.593750]  [A loss: 0.814718, acc: 0.269531]\n",
      "765: [D loss: 0.691573, acc: 0.527344]  [A loss: 1.061101, acc: 0.070312]\n",
      "766: [D loss: 0.673072, acc: 0.572266]  [A loss: 0.800735, acc: 0.292969]\n",
      "767: [D loss: 0.685389, acc: 0.560547]  [A loss: 1.016785, acc: 0.078125]\n",
      "768: [D loss: 0.663690, acc: 0.605469]  [A loss: 0.810155, acc: 0.289062]\n",
      "769: [D loss: 0.684056, acc: 0.558594]  [A loss: 0.977782, acc: 0.066406]\n",
      "770: [D loss: 0.666539, acc: 0.593750]  [A loss: 0.860685, acc: 0.238281]\n",
      "771: [D loss: 0.682000, acc: 0.554688]  [A loss: 0.995227, acc: 0.082031]\n",
      "772: [D loss: 0.670201, acc: 0.560547]  [A loss: 0.853725, acc: 0.238281]\n",
      "773: [D loss: 0.674577, acc: 0.562500]  [A loss: 1.030535, acc: 0.046875]\n",
      "774: [D loss: 0.664793, acc: 0.587891]  [A loss: 0.780506, acc: 0.347656]\n",
      "775: [D loss: 0.693377, acc: 0.527344]  [A loss: 1.137317, acc: 0.023438]\n",
      "776: [D loss: 0.671562, acc: 0.582031]  [A loss: 0.703515, acc: 0.539062]\n",
      "777: [D loss: 0.700623, acc: 0.542969]  [A loss: 1.162703, acc: 0.011719]\n",
      "778: [D loss: 0.679522, acc: 0.566406]  [A loss: 0.672751, acc: 0.550781]\n",
      "779: [D loss: 0.690218, acc: 0.541016]  [A loss: 1.086482, acc: 0.046875]\n",
      "780: [D loss: 0.657262, acc: 0.603516]  [A loss: 0.856003, acc: 0.226562]\n",
      "781: [D loss: 0.687838, acc: 0.556641]  [A loss: 0.989334, acc: 0.085938]\n",
      "782: [D loss: 0.683850, acc: 0.539062]  [A loss: 0.796295, acc: 0.308594]\n",
      "783: [D loss: 0.701867, acc: 0.550781]  [A loss: 1.051156, acc: 0.039062]\n",
      "784: [D loss: 0.669273, acc: 0.589844]  [A loss: 0.819967, acc: 0.296875]\n",
      "785: [D loss: 0.688943, acc: 0.556641]  [A loss: 1.034460, acc: 0.074219]\n",
      "786: [D loss: 0.696423, acc: 0.529297]  [A loss: 0.794817, acc: 0.324219]\n",
      "787: [D loss: 0.679391, acc: 0.578125]  [A loss: 0.991226, acc: 0.082031]\n",
      "788: [D loss: 0.668464, acc: 0.593750]  [A loss: 0.822614, acc: 0.273438]\n",
      "789: [D loss: 0.677154, acc: 0.583984]  [A loss: 0.966338, acc: 0.113281]\n",
      "790: [D loss: 0.673283, acc: 0.556641]  [A loss: 0.979703, acc: 0.074219]\n",
      "791: [D loss: 0.668078, acc: 0.591797]  [A loss: 0.838099, acc: 0.226562]\n",
      "792: [D loss: 0.682701, acc: 0.572266]  [A loss: 1.005796, acc: 0.074219]\n",
      "793: [D loss: 0.680802, acc: 0.566406]  [A loss: 0.800919, acc: 0.324219]\n",
      "794: [D loss: 0.682877, acc: 0.566406]  [A loss: 1.044576, acc: 0.089844]\n",
      "795: [D loss: 0.672656, acc: 0.580078]  [A loss: 0.855412, acc: 0.222656]\n",
      "796: [D loss: 0.699980, acc: 0.537109]  [A loss: 1.043531, acc: 0.050781]\n",
      "797: [D loss: 0.668552, acc: 0.578125]  [A loss: 0.746524, acc: 0.402344]\n",
      "798: [D loss: 0.702008, acc: 0.550781]  [A loss: 1.107746, acc: 0.039062]\n",
      "799: [D loss: 0.659841, acc: 0.623047]  [A loss: 0.708319, acc: 0.523438]\n",
      "800: [D loss: 0.730644, acc: 0.521484]  [A loss: 1.246550, acc: 0.007812]\n",
      "801: [D loss: 0.680869, acc: 0.554688]  [A loss: 0.650831, acc: 0.648438]\n",
      "802: [D loss: 0.740056, acc: 0.521484]  [A loss: 1.122620, acc: 0.031250]\n",
      "803: [D loss: 0.660143, acc: 0.605469]  [A loss: 0.764451, acc: 0.394531]\n",
      "804: [D loss: 0.702906, acc: 0.535156]  [A loss: 0.992173, acc: 0.132812]\n",
      "805: [D loss: 0.668709, acc: 0.607422]  [A loss: 0.845920, acc: 0.242188]\n",
      "806: [D loss: 0.678773, acc: 0.562500]  [A loss: 0.902744, acc: 0.175781]\n",
      "807: [D loss: 0.669623, acc: 0.576172]  [A loss: 0.908333, acc: 0.132812]\n",
      "808: [D loss: 0.671470, acc: 0.580078]  [A loss: 0.970063, acc: 0.109375]\n",
      "809: [D loss: 0.667603, acc: 0.595703]  [A loss: 0.866173, acc: 0.218750]\n",
      "810: [D loss: 0.671750, acc: 0.585938]  [A loss: 0.999808, acc: 0.085938]\n",
      "811: [D loss: 0.672184, acc: 0.583984]  [A loss: 0.840480, acc: 0.242188]\n",
      "812: [D loss: 0.669544, acc: 0.597656]  [A loss: 1.051782, acc: 0.066406]\n",
      "813: [D loss: 0.670072, acc: 0.593750]  [A loss: 0.757697, acc: 0.402344]\n",
      "814: [D loss: 0.716509, acc: 0.542969]  [A loss: 1.213234, acc: 0.019531]\n",
      "815: [D loss: 0.675129, acc: 0.578125]  [A loss: 0.741749, acc: 0.406250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816: [D loss: 0.740391, acc: 0.507812]  [A loss: 1.061402, acc: 0.070312]\n",
      "817: [D loss: 0.657374, acc: 0.623047]  [A loss: 0.786305, acc: 0.355469]\n",
      "818: [D loss: 0.691979, acc: 0.580078]  [A loss: 1.020228, acc: 0.082031]\n",
      "819: [D loss: 0.664477, acc: 0.595703]  [A loss: 0.795064, acc: 0.343750]\n",
      "820: [D loss: 0.669936, acc: 0.572266]  [A loss: 0.967495, acc: 0.117188]\n",
      "821: [D loss: 0.679036, acc: 0.570312]  [A loss: 0.829616, acc: 0.269531]\n",
      "822: [D loss: 0.685999, acc: 0.570312]  [A loss: 1.013623, acc: 0.105469]\n",
      "823: [D loss: 0.673011, acc: 0.570312]  [A loss: 0.812314, acc: 0.320312]\n",
      "824: [D loss: 0.686628, acc: 0.541016]  [A loss: 1.014737, acc: 0.074219]\n",
      "825: [D loss: 0.671047, acc: 0.583984]  [A loss: 0.795027, acc: 0.312500]\n",
      "826: [D loss: 0.694211, acc: 0.564453]  [A loss: 1.064171, acc: 0.074219]\n",
      "827: [D loss: 0.666046, acc: 0.599609]  [A loss: 0.789217, acc: 0.332031]\n",
      "828: [D loss: 0.706021, acc: 0.548828]  [A loss: 1.008620, acc: 0.089844]\n",
      "829: [D loss: 0.687357, acc: 0.548828]  [A loss: 0.850182, acc: 0.250000]\n",
      "830: [D loss: 0.675431, acc: 0.556641]  [A loss: 1.008325, acc: 0.117188]\n",
      "831: [D loss: 0.682393, acc: 0.546875]  [A loss: 0.776363, acc: 0.367188]\n",
      "832: [D loss: 0.695048, acc: 0.533203]  [A loss: 1.131991, acc: 0.039062]\n",
      "833: [D loss: 0.668319, acc: 0.589844]  [A loss: 0.733800, acc: 0.445312]\n",
      "834: [D loss: 0.673886, acc: 0.558594]  [A loss: 1.060434, acc: 0.082031]\n",
      "835: [D loss: 0.695413, acc: 0.556641]  [A loss: 0.798122, acc: 0.355469]\n",
      "836: [D loss: 0.688311, acc: 0.566406]  [A loss: 1.050397, acc: 0.074219]\n",
      "837: [D loss: 0.667173, acc: 0.587891]  [A loss: 0.767453, acc: 0.378906]\n",
      "838: [D loss: 0.681395, acc: 0.574219]  [A loss: 1.068774, acc: 0.039062]\n",
      "839: [D loss: 0.650311, acc: 0.632812]  [A loss: 0.768681, acc: 0.363281]\n",
      "840: [D loss: 0.667634, acc: 0.585938]  [A loss: 0.991160, acc: 0.121094]\n",
      "841: [D loss: 0.683313, acc: 0.568359]  [A loss: 0.905784, acc: 0.156250]\n",
      "842: [D loss: 0.689685, acc: 0.544922]  [A loss: 0.934415, acc: 0.144531]\n",
      "843: [D loss: 0.678112, acc: 0.564453]  [A loss: 0.806421, acc: 0.332031]\n",
      "844: [D loss: 0.691229, acc: 0.560547]  [A loss: 1.137148, acc: 0.042969]\n",
      "845: [D loss: 0.670782, acc: 0.589844]  [A loss: 0.782431, acc: 0.332031]\n",
      "846: [D loss: 0.685044, acc: 0.562500]  [A loss: 1.121966, acc: 0.023438]\n",
      "847: [D loss: 0.694922, acc: 0.541016]  [A loss: 0.688612, acc: 0.546875]\n",
      "848: [D loss: 0.713497, acc: 0.535156]  [A loss: 1.136205, acc: 0.035156]\n",
      "849: [D loss: 0.676956, acc: 0.580078]  [A loss: 0.751566, acc: 0.398438]\n",
      "850: [D loss: 0.699273, acc: 0.554688]  [A loss: 1.006999, acc: 0.101562]\n",
      "851: [D loss: 0.665777, acc: 0.578125]  [A loss: 0.806140, acc: 0.320312]\n",
      "852: [D loss: 0.691295, acc: 0.556641]  [A loss: 0.991245, acc: 0.089844]\n",
      "853: [D loss: 0.658712, acc: 0.580078]  [A loss: 0.831900, acc: 0.250000]\n",
      "854: [D loss: 0.694773, acc: 0.583984]  [A loss: 0.970848, acc: 0.109375]\n",
      "855: [D loss: 0.687193, acc: 0.541016]  [A loss: 0.888904, acc: 0.179688]\n",
      "856: [D loss: 0.692364, acc: 0.552734]  [A loss: 0.917998, acc: 0.132812]\n",
      "857: [D loss: 0.666272, acc: 0.599609]  [A loss: 0.906600, acc: 0.207031]\n",
      "858: [D loss: 0.660194, acc: 0.589844]  [A loss: 0.899714, acc: 0.164062]\n",
      "859: [D loss: 0.677171, acc: 0.570312]  [A loss: 0.992989, acc: 0.085938]\n",
      "860: [D loss: 0.679036, acc: 0.582031]  [A loss: 0.930567, acc: 0.187500]\n",
      "861: [D loss: 0.675491, acc: 0.570312]  [A loss: 0.950292, acc: 0.136719]\n",
      "862: [D loss: 0.679883, acc: 0.552734]  [A loss: 0.831998, acc: 0.273438]\n",
      "863: [D loss: 0.668732, acc: 0.595703]  [A loss: 1.089851, acc: 0.082031]\n",
      "864: [D loss: 0.678914, acc: 0.570312]  [A loss: 0.787710, acc: 0.324219]\n",
      "865: [D loss: 0.683464, acc: 0.560547]  [A loss: 1.083181, acc: 0.062500]\n",
      "866: [D loss: 0.660269, acc: 0.601562]  [A loss: 0.725550, acc: 0.480469]\n",
      "867: [D loss: 0.705818, acc: 0.527344]  [A loss: 1.191149, acc: 0.039062]\n",
      "868: [D loss: 0.670602, acc: 0.595703]  [A loss: 0.698400, acc: 0.511719]\n",
      "869: [D loss: 0.724906, acc: 0.517578]  [A loss: 1.104034, acc: 0.050781]\n",
      "870: [D loss: 0.673594, acc: 0.597656]  [A loss: 0.729375, acc: 0.429688]\n",
      "871: [D loss: 0.691153, acc: 0.546875]  [A loss: 0.978786, acc: 0.121094]\n",
      "872: [D loss: 0.677239, acc: 0.578125]  [A loss: 0.800608, acc: 0.328125]\n",
      "873: [D loss: 0.704698, acc: 0.531250]  [A loss: 1.025914, acc: 0.070312]\n",
      "874: [D loss: 0.666053, acc: 0.560547]  [A loss: 0.826021, acc: 0.277344]\n",
      "875: [D loss: 0.688006, acc: 0.554688]  [A loss: 1.016841, acc: 0.062500]\n",
      "876: [D loss: 0.679728, acc: 0.560547]  [A loss: 0.846040, acc: 0.250000]\n",
      "877: [D loss: 0.688646, acc: 0.572266]  [A loss: 0.962201, acc: 0.105469]\n",
      "878: [D loss: 0.689809, acc: 0.537109]  [A loss: 0.844927, acc: 0.257812]\n",
      "879: [D loss: 0.684406, acc: 0.582031]  [A loss: 0.955763, acc: 0.105469]\n",
      "880: [D loss: 0.673373, acc: 0.582031]  [A loss: 0.792438, acc: 0.324219]\n",
      "881: [D loss: 0.715387, acc: 0.515625]  [A loss: 1.164905, acc: 0.046875]\n",
      "882: [D loss: 0.673956, acc: 0.605469]  [A loss: 0.762145, acc: 0.402344]\n",
      "883: [D loss: 0.690484, acc: 0.562500]  [A loss: 1.034674, acc: 0.066406]\n",
      "884: [D loss: 0.656363, acc: 0.613281]  [A loss: 0.813091, acc: 0.273438]\n",
      "885: [D loss: 0.686041, acc: 0.582031]  [A loss: 1.004256, acc: 0.097656]\n",
      "886: [D loss: 0.674444, acc: 0.576172]  [A loss: 0.793933, acc: 0.304688]\n",
      "887: [D loss: 0.682880, acc: 0.548828]  [A loss: 0.959019, acc: 0.121094]\n",
      "888: [D loss: 0.672721, acc: 0.568359]  [A loss: 0.898642, acc: 0.156250]\n",
      "889: [D loss: 0.674891, acc: 0.560547]  [A loss: 0.968290, acc: 0.136719]\n",
      "890: [D loss: 0.672412, acc: 0.554688]  [A loss: 0.868252, acc: 0.218750]\n",
      "891: [D loss: 0.679404, acc: 0.564453]  [A loss: 0.941211, acc: 0.144531]\n",
      "892: [D loss: 0.694718, acc: 0.537109]  [A loss: 0.930590, acc: 0.117188]\n",
      "893: [D loss: 0.671097, acc: 0.552734]  [A loss: 0.938764, acc: 0.125000]\n",
      "894: [D loss: 0.679144, acc: 0.562500]  [A loss: 0.951779, acc: 0.109375]\n",
      "895: [D loss: 0.667853, acc: 0.583984]  [A loss: 0.845498, acc: 0.265625]\n",
      "896: [D loss: 0.689979, acc: 0.564453]  [A loss: 1.092488, acc: 0.046875]\n",
      "897: [D loss: 0.663642, acc: 0.617188]  [A loss: 0.679957, acc: 0.542969]\n",
      "898: [D loss: 0.733338, acc: 0.529297]  [A loss: 1.263801, acc: 0.011719]\n",
      "899: [D loss: 0.673594, acc: 0.568359]  [A loss: 0.688976, acc: 0.558594]\n",
      "900: [D loss: 0.721508, acc: 0.513672]  [A loss: 1.051619, acc: 0.039062]\n",
      "901: [D loss: 0.681580, acc: 0.556641]  [A loss: 0.828644, acc: 0.230469]\n",
      "902: [D loss: 0.675545, acc: 0.585938]  [A loss: 0.933658, acc: 0.136719]\n",
      "903: [D loss: 0.671835, acc: 0.587891]  [A loss: 0.854220, acc: 0.214844]\n",
      "904: [D loss: 0.689794, acc: 0.583984]  [A loss: 0.955521, acc: 0.125000]\n",
      "905: [D loss: 0.676686, acc: 0.558594]  [A loss: 0.849759, acc: 0.214844]\n",
      "906: [D loss: 0.685812, acc: 0.552734]  [A loss: 0.967167, acc: 0.089844]\n",
      "907: [D loss: 0.680454, acc: 0.564453]  [A loss: 0.883868, acc: 0.203125]\n",
      "908: [D loss: 0.703598, acc: 0.521484]  [A loss: 1.033614, acc: 0.093750]\n",
      "909: [D loss: 0.670805, acc: 0.587891]  [A loss: 0.807596, acc: 0.328125]\n",
      "910: [D loss: 0.677656, acc: 0.558594]  [A loss: 1.033320, acc: 0.085938]\n",
      "911: [D loss: 0.676871, acc: 0.574219]  [A loss: 0.803556, acc: 0.312500]\n",
      "912: [D loss: 0.683925, acc: 0.562500]  [A loss: 1.041644, acc: 0.085938]\n",
      "913: [D loss: 0.709076, acc: 0.496094]  [A loss: 0.976043, acc: 0.109375]\n",
      "914: [D loss: 0.669597, acc: 0.589844]  [A loss: 0.937980, acc: 0.128906]\n",
      "915: [D loss: 0.669555, acc: 0.601562]  [A loss: 0.863052, acc: 0.207031]\n",
      "916: [D loss: 0.676132, acc: 0.591797]  [A loss: 1.139166, acc: 0.050781]\n",
      "917: [D loss: 0.668949, acc: 0.583984]  [A loss: 0.774100, acc: 0.402344]\n",
      "918: [D loss: 0.722193, acc: 0.537109]  [A loss: 1.225733, acc: 0.015625]\n",
      "919: [D loss: 0.669589, acc: 0.568359]  [A loss: 0.643173, acc: 0.621094]\n",
      "920: [D loss: 0.753668, acc: 0.533203]  [A loss: 1.209282, acc: 0.042969]\n",
      "921: [D loss: 0.687492, acc: 0.542969]  [A loss: 0.795944, acc: 0.335938]\n",
      "922: [D loss: 0.688295, acc: 0.546875]  [A loss: 0.979975, acc: 0.085938]\n",
      "923: [D loss: 0.659335, acc: 0.611328]  [A loss: 0.888855, acc: 0.207031]\n",
      "924: [D loss: 0.705120, acc: 0.533203]  [A loss: 0.978276, acc: 0.140625]\n",
      "925: [D loss: 0.681663, acc: 0.578125]  [A loss: 0.856787, acc: 0.218750]\n",
      "926: [D loss: 0.684386, acc: 0.552734]  [A loss: 1.004080, acc: 0.136719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927: [D loss: 0.669370, acc: 0.601562]  [A loss: 0.859352, acc: 0.250000]\n",
      "928: [D loss: 0.702153, acc: 0.531250]  [A loss: 0.904128, acc: 0.167969]\n",
      "929: [D loss: 0.703481, acc: 0.527344]  [A loss: 1.089527, acc: 0.046875]\n",
      "930: [D loss: 0.680891, acc: 0.603516]  [A loss: 0.836686, acc: 0.273438]\n",
      "931: [D loss: 0.678651, acc: 0.570312]  [A loss: 0.983004, acc: 0.125000]\n",
      "932: [D loss: 0.674582, acc: 0.568359]  [A loss: 0.807902, acc: 0.281250]\n",
      "933: [D loss: 0.687346, acc: 0.562500]  [A loss: 1.068451, acc: 0.074219]\n",
      "934: [D loss: 0.666273, acc: 0.578125]  [A loss: 0.850911, acc: 0.238281]\n",
      "935: [D loss: 0.691301, acc: 0.541016]  [A loss: 1.062079, acc: 0.093750]\n",
      "936: [D loss: 0.682022, acc: 0.574219]  [A loss: 0.819558, acc: 0.292969]\n",
      "937: [D loss: 0.698240, acc: 0.578125]  [A loss: 1.067098, acc: 0.058594]\n",
      "938: [D loss: 0.660089, acc: 0.566406]  [A loss: 0.846394, acc: 0.273438]\n",
      "939: [D loss: 0.686761, acc: 0.558594]  [A loss: 1.035888, acc: 0.070312]\n",
      "940: [D loss: 0.687922, acc: 0.566406]  [A loss: 0.832427, acc: 0.281250]\n",
      "941: [D loss: 0.697961, acc: 0.552734]  [A loss: 1.167313, acc: 0.058594]\n",
      "942: [D loss: 0.689363, acc: 0.554688]  [A loss: 0.726911, acc: 0.457031]\n",
      "943: [D loss: 0.720949, acc: 0.542969]  [A loss: 1.160852, acc: 0.031250]\n",
      "944: [D loss: 0.675882, acc: 0.595703]  [A loss: 0.658408, acc: 0.609375]\n",
      "945: [D loss: 0.740666, acc: 0.496094]  [A loss: 1.228328, acc: 0.031250]\n",
      "946: [D loss: 0.682268, acc: 0.529297]  [A loss: 0.679426, acc: 0.593750]\n",
      "947: [D loss: 0.706344, acc: 0.525391]  [A loss: 1.047098, acc: 0.070312]\n",
      "948: [D loss: 0.680335, acc: 0.570312]  [A loss: 0.802623, acc: 0.281250]\n",
      "949: [D loss: 0.692481, acc: 0.544922]  [A loss: 0.948280, acc: 0.125000]\n",
      "950: [D loss: 0.681903, acc: 0.582031]  [A loss: 0.811476, acc: 0.234375]\n",
      "951: [D loss: 0.680065, acc: 0.560547]  [A loss: 0.962715, acc: 0.078125]\n",
      "952: [D loss: 0.682061, acc: 0.548828]  [A loss: 0.802100, acc: 0.328125]\n",
      "953: [D loss: 0.692156, acc: 0.527344]  [A loss: 0.941834, acc: 0.125000]\n",
      "954: [D loss: 0.682254, acc: 0.564453]  [A loss: 0.930411, acc: 0.128906]\n",
      "955: [D loss: 0.657484, acc: 0.597656]  [A loss: 0.950437, acc: 0.140625]\n",
      "956: [D loss: 0.688089, acc: 0.546875]  [A loss: 0.866916, acc: 0.183594]\n",
      "957: [D loss: 0.689066, acc: 0.556641]  [A loss: 0.900370, acc: 0.171875]\n",
      "958: [D loss: 0.691324, acc: 0.531250]  [A loss: 1.011107, acc: 0.089844]\n",
      "959: [D loss: 0.684105, acc: 0.558594]  [A loss: 0.841858, acc: 0.269531]\n",
      "960: [D loss: 0.682141, acc: 0.585938]  [A loss: 1.012398, acc: 0.089844]\n",
      "961: [D loss: 0.671543, acc: 0.572266]  [A loss: 0.777250, acc: 0.363281]\n",
      "962: [D loss: 0.684666, acc: 0.562500]  [A loss: 1.081381, acc: 0.042969]\n",
      "963: [D loss: 0.670630, acc: 0.591797]  [A loss: 0.709433, acc: 0.464844]\n",
      "964: [D loss: 0.699038, acc: 0.544922]  [A loss: 1.098757, acc: 0.027344]\n",
      "965: [D loss: 0.673971, acc: 0.580078]  [A loss: 0.664746, acc: 0.609375]\n",
      "966: [D loss: 0.730512, acc: 0.529297]  [A loss: 1.155852, acc: 0.019531]\n",
      "967: [D loss: 0.670938, acc: 0.603516]  [A loss: 0.727921, acc: 0.480469]\n",
      "968: [D loss: 0.698390, acc: 0.537109]  [A loss: 1.038894, acc: 0.058594]\n",
      "969: [D loss: 0.673202, acc: 0.574219]  [A loss: 0.821480, acc: 0.277344]\n",
      "970: [D loss: 0.692647, acc: 0.535156]  [A loss: 0.984896, acc: 0.113281]\n",
      "971: [D loss: 0.664228, acc: 0.615234]  [A loss: 0.838065, acc: 0.230469]\n",
      "972: [D loss: 0.690925, acc: 0.554688]  [A loss: 1.022450, acc: 0.066406]\n",
      "973: [D loss: 0.684019, acc: 0.582031]  [A loss: 0.816682, acc: 0.253906]\n",
      "974: [D loss: 0.699849, acc: 0.535156]  [A loss: 0.944136, acc: 0.148438]\n",
      "975: [D loss: 0.669971, acc: 0.582031]  [A loss: 0.854975, acc: 0.218750]\n",
      "976: [D loss: 0.688320, acc: 0.552734]  [A loss: 0.992075, acc: 0.113281]\n",
      "977: [D loss: 0.659010, acc: 0.607422]  [A loss: 0.833525, acc: 0.285156]\n",
      "978: [D loss: 0.682287, acc: 0.548828]  [A loss: 0.981804, acc: 0.101562]\n",
      "979: [D loss: 0.676362, acc: 0.566406]  [A loss: 0.811186, acc: 0.273438]\n",
      "980: [D loss: 0.680121, acc: 0.582031]  [A loss: 1.058256, acc: 0.093750]\n",
      "981: [D loss: 0.669556, acc: 0.585938]  [A loss: 0.769818, acc: 0.390625]\n",
      "982: [D loss: 0.709387, acc: 0.541016]  [A loss: 1.153726, acc: 0.035156]\n",
      "983: [D loss: 0.687607, acc: 0.548828]  [A loss: 0.796023, acc: 0.363281]\n",
      "984: [D loss: 0.689349, acc: 0.542969]  [A loss: 1.015291, acc: 0.140625]\n",
      "985: [D loss: 0.682988, acc: 0.560547]  [A loss: 0.835261, acc: 0.289062]\n",
      "986: [D loss: 0.713708, acc: 0.513672]  [A loss: 1.088986, acc: 0.054688]\n",
      "987: [D loss: 0.694144, acc: 0.560547]  [A loss: 0.820726, acc: 0.277344]\n",
      "988: [D loss: 0.710772, acc: 0.523438]  [A loss: 1.050794, acc: 0.070312]\n",
      "989: [D loss: 0.675331, acc: 0.580078]  [A loss: 0.804640, acc: 0.281250]\n",
      "990: [D loss: 0.708563, acc: 0.521484]  [A loss: 1.070606, acc: 0.054688]\n",
      "991: [D loss: 0.687134, acc: 0.546875]  [A loss: 0.735089, acc: 0.417969]\n",
      "992: [D loss: 0.680934, acc: 0.574219]  [A loss: 1.016207, acc: 0.078125]\n",
      "993: [D loss: 0.677009, acc: 0.599609]  [A loss: 0.843764, acc: 0.222656]\n",
      "994: [D loss: 0.689732, acc: 0.550781]  [A loss: 0.991417, acc: 0.078125]\n",
      "995: [D loss: 0.668590, acc: 0.591797]  [A loss: 0.869522, acc: 0.210938]\n",
      "996: [D loss: 0.684482, acc: 0.564453]  [A loss: 0.930738, acc: 0.132812]\n",
      "997: [D loss: 0.679050, acc: 0.552734]  [A loss: 0.901981, acc: 0.187500]\n",
      "998: [D loss: 0.690938, acc: 0.525391]  [A loss: 0.982836, acc: 0.082031]\n",
      "999: [D loss: 0.677311, acc: 0.539062]  [A loss: 0.785353, acc: 0.332031]\n",
      "1000: [D loss: 0.692228, acc: 0.556641]  [A loss: 1.214222, acc: 0.011719]\n",
      "1001: [D loss: 0.666569, acc: 0.605469]  [A loss: 0.674619, acc: 0.535156]\n",
      "1002: [D loss: 0.743234, acc: 0.509766]  [A loss: 1.219118, acc: 0.035156]\n",
      "1003: [D loss: 0.704581, acc: 0.548828]  [A loss: 0.670738, acc: 0.574219]\n",
      "1004: [D loss: 0.738095, acc: 0.511719]  [A loss: 1.035041, acc: 0.027344]\n",
      "1005: [D loss: 0.679237, acc: 0.552734]  [A loss: 0.741384, acc: 0.417969]\n",
      "1006: [D loss: 0.717238, acc: 0.519531]  [A loss: 0.986879, acc: 0.070312]\n",
      "1007: [D loss: 0.666708, acc: 0.582031]  [A loss: 0.757801, acc: 0.359375]\n",
      "1008: [D loss: 0.691456, acc: 0.556641]  [A loss: 0.958498, acc: 0.082031]\n",
      "1009: [D loss: 0.670065, acc: 0.595703]  [A loss: 0.868715, acc: 0.183594]\n",
      "1010: [D loss: 0.687566, acc: 0.550781]  [A loss: 0.913318, acc: 0.117188]\n",
      "1011: [D loss: 0.686484, acc: 0.537109]  [A loss: 0.875929, acc: 0.160156]\n",
      "1012: [D loss: 0.680638, acc: 0.558594]  [A loss: 0.898820, acc: 0.125000]\n",
      "1013: [D loss: 0.667026, acc: 0.591797]  [A loss: 0.889599, acc: 0.152344]\n",
      "1014: [D loss: 0.684924, acc: 0.558594]  [A loss: 0.933773, acc: 0.117188]\n",
      "1015: [D loss: 0.689265, acc: 0.558594]  [A loss: 0.907816, acc: 0.152344]\n",
      "1016: [D loss: 0.683041, acc: 0.552734]  [A loss: 0.919193, acc: 0.125000]\n",
      "1017: [D loss: 0.687842, acc: 0.521484]  [A loss: 0.958372, acc: 0.117188]\n",
      "1018: [D loss: 0.672345, acc: 0.599609]  [A loss: 0.893153, acc: 0.128906]\n",
      "1019: [D loss: 0.693990, acc: 0.558594]  [A loss: 1.024993, acc: 0.078125]\n",
      "1020: [D loss: 0.683519, acc: 0.552734]  [A loss: 0.796013, acc: 0.324219]\n",
      "1021: [D loss: 0.686010, acc: 0.548828]  [A loss: 1.095284, acc: 0.042969]\n",
      "1022: [D loss: 0.679738, acc: 0.544922]  [A loss: 0.763103, acc: 0.406250]\n",
      "1023: [D loss: 0.720555, acc: 0.521484]  [A loss: 1.205667, acc: 0.023438]\n",
      "1024: [D loss: 0.683553, acc: 0.572266]  [A loss: 0.612734, acc: 0.699219]\n",
      "1025: [D loss: 0.725856, acc: 0.517578]  [A loss: 1.201970, acc: 0.011719]\n",
      "1026: [D loss: 0.687237, acc: 0.541016]  [A loss: 0.686733, acc: 0.535156]\n",
      "1027: [D loss: 0.707245, acc: 0.507812]  [A loss: 1.030457, acc: 0.050781]\n",
      "1028: [D loss: 0.667146, acc: 0.591797]  [A loss: 0.753368, acc: 0.398438]\n",
      "1029: [D loss: 0.703109, acc: 0.523438]  [A loss: 1.005694, acc: 0.109375]\n",
      "1030: [D loss: 0.682912, acc: 0.564453]  [A loss: 0.801501, acc: 0.292969]\n",
      "1031: [D loss: 0.679261, acc: 0.568359]  [A loss: 0.919208, acc: 0.125000]\n",
      "1032: [D loss: 0.671473, acc: 0.582031]  [A loss: 0.907339, acc: 0.167969]\n",
      "1033: [D loss: 0.673290, acc: 0.568359]  [A loss: 0.896835, acc: 0.156250]\n",
      "1034: [D loss: 0.682932, acc: 0.566406]  [A loss: 0.936338, acc: 0.105469]\n",
      "1035: [D loss: 0.689074, acc: 0.564453]  [A loss: 0.896743, acc: 0.187500]\n",
      "1036: [D loss: 0.672880, acc: 0.562500]  [A loss: 0.855228, acc: 0.214844]\n",
      "1037: [D loss: 0.684517, acc: 0.550781]  [A loss: 0.885066, acc: 0.195312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038: [D loss: 0.676614, acc: 0.564453]  [A loss: 0.955220, acc: 0.156250]\n",
      "1039: [D loss: 0.671021, acc: 0.572266]  [A loss: 0.904746, acc: 0.167969]\n",
      "1040: [D loss: 0.695731, acc: 0.517578]  [A loss: 0.968335, acc: 0.082031]\n",
      "1041: [D loss: 0.681086, acc: 0.578125]  [A loss: 0.884601, acc: 0.199219]\n",
      "1042: [D loss: 0.700613, acc: 0.515625]  [A loss: 1.076197, acc: 0.046875]\n",
      "1043: [D loss: 0.683782, acc: 0.550781]  [A loss: 0.735478, acc: 0.437500]\n",
      "1044: [D loss: 0.708177, acc: 0.523438]  [A loss: 1.145485, acc: 0.031250]\n",
      "1045: [D loss: 0.688289, acc: 0.533203]  [A loss: 0.702346, acc: 0.515625]\n",
      "1046: [D loss: 0.727922, acc: 0.513672]  [A loss: 1.177520, acc: 0.023438]\n",
      "1047: [D loss: 0.680673, acc: 0.564453]  [A loss: 0.725469, acc: 0.468750]\n",
      "1048: [D loss: 0.722256, acc: 0.519531]  [A loss: 1.045531, acc: 0.046875]\n",
      "1049: [D loss: 0.661938, acc: 0.599609]  [A loss: 0.735828, acc: 0.429688]\n",
      "1050: [D loss: 0.713643, acc: 0.503906]  [A loss: 0.975585, acc: 0.078125]\n",
      "1051: [D loss: 0.687819, acc: 0.541016]  [A loss: 0.735235, acc: 0.445312]\n",
      "1052: [D loss: 0.700891, acc: 0.552734]  [A loss: 0.956669, acc: 0.097656]\n",
      "1053: [D loss: 0.690584, acc: 0.546875]  [A loss: 0.770750, acc: 0.351562]\n",
      "1054: [D loss: 0.695457, acc: 0.560547]  [A loss: 0.969007, acc: 0.097656]\n",
      "1055: [D loss: 0.677289, acc: 0.589844]  [A loss: 0.807570, acc: 0.324219]\n",
      "1056: [D loss: 0.693415, acc: 0.548828]  [A loss: 0.936866, acc: 0.101562]\n",
      "1057: [D loss: 0.676911, acc: 0.603516]  [A loss: 0.843847, acc: 0.230469]\n",
      "1058: [D loss: 0.686288, acc: 0.558594]  [A loss: 0.895963, acc: 0.167969]\n",
      "1059: [D loss: 0.679919, acc: 0.570312]  [A loss: 0.909294, acc: 0.152344]\n",
      "1060: [D loss: 0.683460, acc: 0.572266]  [A loss: 0.944563, acc: 0.140625]\n",
      "1061: [D loss: 0.681984, acc: 0.580078]  [A loss: 0.857032, acc: 0.246094]\n",
      "1062: [D loss: 0.689524, acc: 0.533203]  [A loss: 1.055842, acc: 0.042969]\n",
      "1063: [D loss: 0.669682, acc: 0.591797]  [A loss: 0.818369, acc: 0.289062]\n",
      "1064: [D loss: 0.681151, acc: 0.554688]  [A loss: 1.009338, acc: 0.066406]\n",
      "1065: [D loss: 0.677017, acc: 0.566406]  [A loss: 0.876547, acc: 0.199219]\n",
      "1066: [D loss: 0.677819, acc: 0.585938]  [A loss: 0.934240, acc: 0.101562]\n",
      "1067: [D loss: 0.673714, acc: 0.564453]  [A loss: 0.982926, acc: 0.117188]\n",
      "1068: [D loss: 0.688250, acc: 0.550781]  [A loss: 0.880821, acc: 0.210938]\n",
      "1069: [D loss: 0.682636, acc: 0.564453]  [A loss: 0.931493, acc: 0.109375]\n",
      "1070: [D loss: 0.669648, acc: 0.580078]  [A loss: 0.869551, acc: 0.234375]\n",
      "1071: [D loss: 0.682467, acc: 0.566406]  [A loss: 1.108238, acc: 0.046875]\n",
      "1072: [D loss: 0.669891, acc: 0.613281]  [A loss: 0.681107, acc: 0.531250]\n",
      "1073: [D loss: 0.761449, acc: 0.507812]  [A loss: 1.337267, acc: 0.007812]\n",
      "1074: [D loss: 0.702653, acc: 0.537109]  [A loss: 0.614061, acc: 0.695312]\n",
      "1075: [D loss: 0.733878, acc: 0.523438]  [A loss: 1.116392, acc: 0.031250]\n",
      "1076: [D loss: 0.663501, acc: 0.572266]  [A loss: 0.747734, acc: 0.414062]\n",
      "1077: [D loss: 0.717371, acc: 0.525391]  [A loss: 1.082099, acc: 0.089844]\n",
      "1078: [D loss: 0.681126, acc: 0.550781]  [A loss: 0.778387, acc: 0.367188]\n",
      "1079: [D loss: 0.707535, acc: 0.554688]  [A loss: 0.978632, acc: 0.093750]\n",
      "1080: [D loss: 0.680586, acc: 0.533203]  [A loss: 0.818410, acc: 0.269531]\n",
      "1081: [D loss: 0.688141, acc: 0.558594]  [A loss: 0.988590, acc: 0.089844]\n",
      "1082: [D loss: 0.675516, acc: 0.558594]  [A loss: 0.781597, acc: 0.367188]\n",
      "1083: [D loss: 0.682045, acc: 0.556641]  [A loss: 0.974553, acc: 0.097656]\n",
      "1084: [D loss: 0.670827, acc: 0.593750]  [A loss: 0.832003, acc: 0.273438]\n",
      "1085: [D loss: 0.688598, acc: 0.564453]  [A loss: 0.944406, acc: 0.128906]\n",
      "1086: [D loss: 0.668339, acc: 0.582031]  [A loss: 0.828846, acc: 0.281250]\n",
      "1087: [D loss: 0.681611, acc: 0.556641]  [A loss: 0.981563, acc: 0.128906]\n",
      "1088: [D loss: 0.672724, acc: 0.607422]  [A loss: 0.848251, acc: 0.214844]\n",
      "1089: [D loss: 0.695051, acc: 0.560547]  [A loss: 1.019368, acc: 0.097656]\n",
      "1090: [D loss: 0.696919, acc: 0.505859]  [A loss: 0.814317, acc: 0.253906]\n",
      "1091: [D loss: 0.687514, acc: 0.578125]  [A loss: 1.017503, acc: 0.117188]\n",
      "1092: [D loss: 0.669145, acc: 0.580078]  [A loss: 0.732605, acc: 0.464844]\n",
      "1093: [D loss: 0.707976, acc: 0.539062]  [A loss: 1.118936, acc: 0.035156]\n",
      "1094: [D loss: 0.669386, acc: 0.585938]  [A loss: 0.673214, acc: 0.582031]\n",
      "1095: [D loss: 0.752262, acc: 0.517578]  [A loss: 1.214750, acc: 0.035156]\n",
      "1096: [D loss: 0.680094, acc: 0.554688]  [A loss: 0.675440, acc: 0.574219]\n",
      "1097: [D loss: 0.728595, acc: 0.539062]  [A loss: 1.057572, acc: 0.058594]\n",
      "1098: [D loss: 0.670409, acc: 0.587891]  [A loss: 0.761422, acc: 0.394531]\n",
      "1099: [D loss: 0.697461, acc: 0.517578]  [A loss: 0.886164, acc: 0.187500]\n",
      "1100: [D loss: 0.689590, acc: 0.535156]  [A loss: 0.844091, acc: 0.246094]\n",
      "1101: [D loss: 0.684391, acc: 0.578125]  [A loss: 0.937285, acc: 0.136719]\n",
      "1102: [D loss: 0.688453, acc: 0.546875]  [A loss: 0.867106, acc: 0.207031]\n",
      "1103: [D loss: 0.700415, acc: 0.537109]  [A loss: 0.947413, acc: 0.117188]\n",
      "1104: [D loss: 0.707704, acc: 0.513672]  [A loss: 0.841568, acc: 0.273438]\n",
      "1105: [D loss: 0.691647, acc: 0.572266]  [A loss: 0.968923, acc: 0.097656]\n",
      "1106: [D loss: 0.708312, acc: 0.505859]  [A loss: 0.902152, acc: 0.148438]\n",
      "1107: [D loss: 0.679929, acc: 0.572266]  [A loss: 0.885860, acc: 0.242188]\n",
      "1108: [D loss: 0.693389, acc: 0.560547]  [A loss: 0.934891, acc: 0.160156]\n",
      "1109: [D loss: 0.686066, acc: 0.562500]  [A loss: 0.942487, acc: 0.117188]\n",
      "1110: [D loss: 0.699431, acc: 0.535156]  [A loss: 0.930631, acc: 0.128906]\n",
      "1111: [D loss: 0.676061, acc: 0.564453]  [A loss: 0.915715, acc: 0.132812]\n",
      "1112: [D loss: 0.675436, acc: 0.589844]  [A loss: 0.984986, acc: 0.101562]\n",
      "1113: [D loss: 0.668677, acc: 0.568359]  [A loss: 0.812144, acc: 0.281250]\n",
      "1114: [D loss: 0.722381, acc: 0.525391]  [A loss: 1.118783, acc: 0.046875]\n",
      "1115: [D loss: 0.676381, acc: 0.568359]  [A loss: 0.717591, acc: 0.464844]\n",
      "1116: [D loss: 0.725748, acc: 0.525391]  [A loss: 1.216959, acc: 0.011719]\n",
      "1117: [D loss: 0.682286, acc: 0.574219]  [A loss: 0.635247, acc: 0.652344]\n",
      "1118: [D loss: 0.722821, acc: 0.529297]  [A loss: 1.106067, acc: 0.046875]\n",
      "1119: [D loss: 0.677851, acc: 0.574219]  [A loss: 0.698429, acc: 0.566406]\n",
      "1120: [D loss: 0.699005, acc: 0.542969]  [A loss: 1.017775, acc: 0.085938]\n",
      "1121: [D loss: 0.662694, acc: 0.613281]  [A loss: 0.760678, acc: 0.421875]\n",
      "1122: [D loss: 0.688877, acc: 0.535156]  [A loss: 0.990642, acc: 0.085938]\n",
      "1123: [D loss: 0.678337, acc: 0.576172]  [A loss: 0.820164, acc: 0.265625]\n",
      "1124: [D loss: 0.696175, acc: 0.560547]  [A loss: 1.055996, acc: 0.046875]\n",
      "1125: [D loss: 0.693635, acc: 0.533203]  [A loss: 0.799116, acc: 0.296875]\n",
      "1126: [D loss: 0.695164, acc: 0.558594]  [A loss: 0.983041, acc: 0.089844]\n",
      "1127: [D loss: 0.679863, acc: 0.554688]  [A loss: 0.815774, acc: 0.281250]\n",
      "1128: [D loss: 0.697231, acc: 0.539062]  [A loss: 1.032084, acc: 0.074219]\n",
      "1129: [D loss: 0.681520, acc: 0.552734]  [A loss: 0.788771, acc: 0.324219]\n",
      "1130: [D loss: 0.696375, acc: 0.531250]  [A loss: 1.011620, acc: 0.066406]\n",
      "1131: [D loss: 0.686276, acc: 0.560547]  [A loss: 0.826944, acc: 0.296875]\n",
      "1132: [D loss: 0.685385, acc: 0.572266]  [A loss: 1.043134, acc: 0.066406]\n",
      "1133: [D loss: 0.679085, acc: 0.554688]  [A loss: 0.741280, acc: 0.441406]\n",
      "1134: [D loss: 0.708742, acc: 0.550781]  [A loss: 1.079008, acc: 0.054688]\n",
      "1135: [D loss: 0.680728, acc: 0.542969]  [A loss: 0.722629, acc: 0.429688]\n",
      "1136: [D loss: 0.703222, acc: 0.542969]  [A loss: 1.073151, acc: 0.046875]\n",
      "1137: [D loss: 0.695094, acc: 0.507812]  [A loss: 0.707337, acc: 0.480469]\n",
      "1138: [D loss: 0.737054, acc: 0.509766]  [A loss: 1.084617, acc: 0.050781]\n",
      "1139: [D loss: 0.673609, acc: 0.576172]  [A loss: 0.759181, acc: 0.347656]\n",
      "1140: [D loss: 0.705614, acc: 0.552734]  [A loss: 0.976603, acc: 0.097656]\n",
      "1141: [D loss: 0.692385, acc: 0.521484]  [A loss: 0.843827, acc: 0.246094]\n",
      "1142: [D loss: 0.695399, acc: 0.529297]  [A loss: 0.943716, acc: 0.128906]\n",
      "1143: [D loss: 0.679853, acc: 0.580078]  [A loss: 0.854865, acc: 0.207031]\n",
      "1144: [D loss: 0.707324, acc: 0.527344]  [A loss: 0.964078, acc: 0.117188]\n",
      "1145: [D loss: 0.693147, acc: 0.546875]  [A loss: 0.859413, acc: 0.214844]\n",
      "1146: [D loss: 0.684993, acc: 0.556641]  [A loss: 0.928829, acc: 0.109375]\n",
      "1147: [D loss: 0.667570, acc: 0.587891]  [A loss: 0.934421, acc: 0.140625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148: [D loss: 0.686777, acc: 0.529297]  [A loss: 0.808104, acc: 0.292969]\n",
      "1149: [D loss: 0.684808, acc: 0.556641]  [A loss: 0.932945, acc: 0.117188]\n",
      "1150: [D loss: 0.681208, acc: 0.562500]  [A loss: 0.875628, acc: 0.207031]\n",
      "1151: [D loss: 0.684973, acc: 0.554688]  [A loss: 0.984477, acc: 0.109375]\n",
      "1152: [D loss: 0.671505, acc: 0.585938]  [A loss: 0.866021, acc: 0.210938]\n",
      "1153: [D loss: 0.684826, acc: 0.550781]  [A loss: 0.913923, acc: 0.152344]\n",
      "1154: [D loss: 0.693469, acc: 0.576172]  [A loss: 1.079605, acc: 0.070312]\n",
      "1155: [D loss: 0.682248, acc: 0.554688]  [A loss: 0.741972, acc: 0.445312]\n",
      "1156: [D loss: 0.708522, acc: 0.521484]  [A loss: 1.200958, acc: 0.019531]\n",
      "1157: [D loss: 0.680660, acc: 0.562500]  [A loss: 0.598962, acc: 0.742188]\n",
      "1158: [D loss: 0.769993, acc: 0.515625]  [A loss: 1.141375, acc: 0.058594]\n",
      "1159: [D loss: 0.676686, acc: 0.613281]  [A loss: 0.722949, acc: 0.445312]\n",
      "1160: [D loss: 0.725450, acc: 0.509766]  [A loss: 1.067092, acc: 0.054688]\n",
      "1161: [D loss: 0.678111, acc: 0.554688]  [A loss: 0.733526, acc: 0.445312]\n",
      "1162: [D loss: 0.697194, acc: 0.558594]  [A loss: 1.027148, acc: 0.074219]\n",
      "1163: [D loss: 0.672735, acc: 0.578125]  [A loss: 0.784775, acc: 0.339844]\n",
      "1164: [D loss: 0.696200, acc: 0.562500]  [A loss: 1.007811, acc: 0.089844]\n",
      "1165: [D loss: 0.699907, acc: 0.552734]  [A loss: 0.767120, acc: 0.382812]\n",
      "1166: [D loss: 0.711952, acc: 0.541016]  [A loss: 1.002344, acc: 0.074219]\n",
      "1167: [D loss: 0.678810, acc: 0.566406]  [A loss: 0.770944, acc: 0.359375]\n",
      "1168: [D loss: 0.700168, acc: 0.542969]  [A loss: 0.997346, acc: 0.078125]\n",
      "1169: [D loss: 0.682722, acc: 0.521484]  [A loss: 0.777946, acc: 0.347656]\n",
      "1170: [D loss: 0.685362, acc: 0.564453]  [A loss: 0.922700, acc: 0.175781]\n",
      "1171: [D loss: 0.685857, acc: 0.576172]  [A loss: 0.854128, acc: 0.234375]\n",
      "1172: [D loss: 0.690308, acc: 0.558594]  [A loss: 0.964261, acc: 0.109375]\n",
      "1173: [D loss: 0.668594, acc: 0.587891]  [A loss: 0.838563, acc: 0.242188]\n",
      "1174: [D loss: 0.684350, acc: 0.582031]  [A loss: 1.050811, acc: 0.082031]\n",
      "1175: [D loss: 0.677855, acc: 0.548828]  [A loss: 0.742805, acc: 0.445312]\n",
      "1176: [D loss: 0.693247, acc: 0.560547]  [A loss: 1.083232, acc: 0.050781]\n",
      "1177: [D loss: 0.684042, acc: 0.554688]  [A loss: 0.792226, acc: 0.335938]\n",
      "1178: [D loss: 0.686140, acc: 0.539062]  [A loss: 1.040864, acc: 0.101562]\n",
      "1179: [D loss: 0.678813, acc: 0.582031]  [A loss: 0.787912, acc: 0.371094]\n",
      "1180: [D loss: 0.702173, acc: 0.550781]  [A loss: 0.994933, acc: 0.085938]\n",
      "1181: [D loss: 0.666090, acc: 0.603516]  [A loss: 0.774732, acc: 0.343750]\n",
      "1182: [D loss: 0.711614, acc: 0.521484]  [A loss: 1.089062, acc: 0.070312]\n",
      "1183: [D loss: 0.672673, acc: 0.599609]  [A loss: 0.667275, acc: 0.574219]\n",
      "1184: [D loss: 0.746274, acc: 0.515625]  [A loss: 1.123990, acc: 0.058594]\n",
      "1185: [D loss: 0.692724, acc: 0.541016]  [A loss: 0.779283, acc: 0.351562]\n",
      "1186: [D loss: 0.688861, acc: 0.574219]  [A loss: 0.950153, acc: 0.117188]\n",
      "1187: [D loss: 0.681544, acc: 0.554688]  [A loss: 0.890096, acc: 0.203125]\n",
      "1188: [D loss: 0.677604, acc: 0.568359]  [A loss: 0.857647, acc: 0.250000]\n",
      "1189: [D loss: 0.673353, acc: 0.560547]  [A loss: 0.964080, acc: 0.136719]\n",
      "1190: [D loss: 0.676417, acc: 0.570312]  [A loss: 0.811589, acc: 0.277344]\n",
      "1191: [D loss: 0.678828, acc: 0.580078]  [A loss: 1.054977, acc: 0.062500]\n",
      "1192: [D loss: 0.677434, acc: 0.562500]  [A loss: 0.740631, acc: 0.453125]\n",
      "1193: [D loss: 0.703569, acc: 0.539062]  [A loss: 1.103274, acc: 0.070312]\n",
      "1194: [D loss: 0.714583, acc: 0.513672]  [A loss: 0.763223, acc: 0.398438]\n",
      "1195: [D loss: 0.700378, acc: 0.548828]  [A loss: 1.078117, acc: 0.066406]\n",
      "1196: [D loss: 0.695292, acc: 0.539062]  [A loss: 0.723758, acc: 0.437500]\n",
      "1197: [D loss: 0.722534, acc: 0.523438]  [A loss: 1.071200, acc: 0.062500]\n",
      "1198: [D loss: 0.677593, acc: 0.572266]  [A loss: 0.765624, acc: 0.394531]\n",
      "1199: [D loss: 0.713215, acc: 0.513672]  [A loss: 1.050079, acc: 0.039062]\n",
      "1200: [D loss: 0.675642, acc: 0.552734]  [A loss: 0.765563, acc: 0.378906]\n",
      "1201: [D loss: 0.684434, acc: 0.568359]  [A loss: 0.964756, acc: 0.128906]\n",
      "1202: [D loss: 0.675033, acc: 0.583984]  [A loss: 0.816934, acc: 0.289062]\n",
      "1203: [D loss: 0.690826, acc: 0.546875]  [A loss: 0.964242, acc: 0.109375]\n",
      "1204: [D loss: 0.676565, acc: 0.597656]  [A loss: 0.863910, acc: 0.199219]\n",
      "1205: [D loss: 0.699629, acc: 0.554688]  [A loss: 0.950603, acc: 0.128906]\n",
      "1206: [D loss: 0.691205, acc: 0.552734]  [A loss: 0.917706, acc: 0.171875]\n",
      "1207: [D loss: 0.688151, acc: 0.558594]  [A loss: 1.026249, acc: 0.085938]\n",
      "1208: [D loss: 0.687022, acc: 0.539062]  [A loss: 0.774407, acc: 0.367188]\n",
      "1209: [D loss: 0.702745, acc: 0.533203]  [A loss: 1.090117, acc: 0.054688]\n",
      "1210: [D loss: 0.683680, acc: 0.556641]  [A loss: 0.718001, acc: 0.492188]\n",
      "1211: [D loss: 0.719222, acc: 0.548828]  [A loss: 1.159945, acc: 0.015625]\n",
      "1212: [D loss: 0.689508, acc: 0.558594]  [A loss: 0.666913, acc: 0.589844]\n",
      "1213: [D loss: 0.734633, acc: 0.511719]  [A loss: 1.114278, acc: 0.039062]\n",
      "1214: [D loss: 0.684705, acc: 0.560547]  [A loss: 0.711573, acc: 0.511719]\n",
      "1215: [D loss: 0.722514, acc: 0.523438]  [A loss: 0.955208, acc: 0.101562]\n",
      "1216: [D loss: 0.679621, acc: 0.554688]  [A loss: 0.784024, acc: 0.335938]\n",
      "1217: [D loss: 0.698584, acc: 0.517578]  [A loss: 0.942050, acc: 0.136719]\n",
      "1218: [D loss: 0.692878, acc: 0.539062]  [A loss: 0.817610, acc: 0.277344]\n",
      "1219: [D loss: 0.702284, acc: 0.533203]  [A loss: 0.951028, acc: 0.125000]\n",
      "1220: [D loss: 0.679340, acc: 0.552734]  [A loss: 0.842849, acc: 0.253906]\n",
      "1221: [D loss: 0.684656, acc: 0.552734]  [A loss: 0.988864, acc: 0.097656]\n",
      "1222: [D loss: 0.685167, acc: 0.550781]  [A loss: 0.848538, acc: 0.246094]\n",
      "1223: [D loss: 0.695454, acc: 0.541016]  [A loss: 0.880778, acc: 0.199219]\n",
      "1224: [D loss: 0.686614, acc: 0.570312]  [A loss: 0.999325, acc: 0.101562]\n",
      "1225: [D loss: 0.681373, acc: 0.566406]  [A loss: 0.784558, acc: 0.343750]\n",
      "1226: [D loss: 0.701518, acc: 0.539062]  [A loss: 1.068256, acc: 0.035156]\n",
      "1227: [D loss: 0.684058, acc: 0.562500]  [A loss: 0.744545, acc: 0.394531]\n",
      "1228: [D loss: 0.692895, acc: 0.550781]  [A loss: 1.085982, acc: 0.039062]\n",
      "1229: [D loss: 0.670231, acc: 0.576172]  [A loss: 0.742384, acc: 0.421875]\n",
      "1230: [D loss: 0.710676, acc: 0.529297]  [A loss: 1.118647, acc: 0.019531]\n",
      "1231: [D loss: 0.682186, acc: 0.554688]  [A loss: 0.716133, acc: 0.488281]\n",
      "1232: [D loss: 0.715677, acc: 0.535156]  [A loss: 1.088330, acc: 0.062500]\n",
      "1233: [D loss: 0.687014, acc: 0.550781]  [A loss: 0.756311, acc: 0.410156]\n",
      "1234: [D loss: 0.676670, acc: 0.591797]  [A loss: 1.002759, acc: 0.074219]\n",
      "1235: [D loss: 0.693117, acc: 0.550781]  [A loss: 0.827614, acc: 0.285156]\n",
      "1236: [D loss: 0.674620, acc: 0.578125]  [A loss: 0.933155, acc: 0.121094]\n",
      "1237: [D loss: 0.695646, acc: 0.542969]  [A loss: 0.822778, acc: 0.265625]\n",
      "1238: [D loss: 0.690326, acc: 0.556641]  [A loss: 0.882082, acc: 0.203125]\n",
      "1239: [D loss: 0.691083, acc: 0.548828]  [A loss: 0.877108, acc: 0.167969]\n",
      "1240: [D loss: 0.716399, acc: 0.537109]  [A loss: 1.059493, acc: 0.078125]\n",
      "1241: [D loss: 0.695658, acc: 0.560547]  [A loss: 0.837080, acc: 0.261719]\n",
      "1242: [D loss: 0.704414, acc: 0.529297]  [A loss: 0.966537, acc: 0.089844]\n",
      "1243: [D loss: 0.689592, acc: 0.533203]  [A loss: 0.820701, acc: 0.281250]\n",
      "1244: [D loss: 0.712170, acc: 0.531250]  [A loss: 1.048737, acc: 0.058594]\n",
      "1245: [D loss: 0.660512, acc: 0.599609]  [A loss: 0.758242, acc: 0.382812]\n",
      "1246: [D loss: 0.713347, acc: 0.548828]  [A loss: 1.100700, acc: 0.042969]\n",
      "1247: [D loss: 0.676042, acc: 0.566406]  [A loss: 0.678740, acc: 0.562500]\n",
      "1248: [D loss: 0.727422, acc: 0.535156]  [A loss: 1.137062, acc: 0.027344]\n",
      "1249: [D loss: 0.664909, acc: 0.611328]  [A loss: 0.720259, acc: 0.496094]\n",
      "1250: [D loss: 0.706469, acc: 0.519531]  [A loss: 1.046699, acc: 0.082031]\n",
      "1251: [D loss: 0.678562, acc: 0.568359]  [A loss: 0.753672, acc: 0.406250]\n",
      "1252: [D loss: 0.699943, acc: 0.552734]  [A loss: 0.987568, acc: 0.078125]\n",
      "1253: [D loss: 0.664185, acc: 0.568359]  [A loss: 0.813474, acc: 0.296875]\n",
      "1254: [D loss: 0.691543, acc: 0.574219]  [A loss: 1.030664, acc: 0.074219]\n",
      "1255: [D loss: 0.676512, acc: 0.568359]  [A loss: 0.757927, acc: 0.386719]\n",
      "1256: [D loss: 0.704325, acc: 0.533203]  [A loss: 1.049826, acc: 0.078125]\n",
      "1257: [D loss: 0.677501, acc: 0.576172]  [A loss: 0.749208, acc: 0.417969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258: [D loss: 0.696339, acc: 0.558594]  [A loss: 1.051828, acc: 0.082031]\n",
      "1259: [D loss: 0.670378, acc: 0.591797]  [A loss: 0.805656, acc: 0.308594]\n",
      "1260: [D loss: 0.704420, acc: 0.552734]  [A loss: 1.025272, acc: 0.078125]\n",
      "1261: [D loss: 0.683312, acc: 0.560547]  [A loss: 0.795581, acc: 0.292969]\n",
      "1262: [D loss: 0.678573, acc: 0.566406]  [A loss: 1.022176, acc: 0.089844]\n",
      "1263: [D loss: 0.686035, acc: 0.564453]  [A loss: 0.717912, acc: 0.488281]\n",
      "1264: [D loss: 0.724187, acc: 0.515625]  [A loss: 1.070572, acc: 0.066406]\n",
      "1265: [D loss: 0.689856, acc: 0.546875]  [A loss: 0.730227, acc: 0.433594]\n",
      "1266: [D loss: 0.703213, acc: 0.550781]  [A loss: 1.102106, acc: 0.054688]\n",
      "1267: [D loss: 0.683092, acc: 0.556641]  [A loss: 0.731018, acc: 0.476562]\n",
      "1268: [D loss: 0.702938, acc: 0.537109]  [A loss: 1.062323, acc: 0.085938]\n",
      "1269: [D loss: 0.675441, acc: 0.585938]  [A loss: 0.713512, acc: 0.453125]\n",
      "1270: [D loss: 0.702433, acc: 0.531250]  [A loss: 1.095619, acc: 0.027344]\n",
      "1271: [D loss: 0.683382, acc: 0.560547]  [A loss: 0.796814, acc: 0.304688]\n",
      "1272: [D loss: 0.711250, acc: 0.542969]  [A loss: 0.975039, acc: 0.121094]\n",
      "1273: [D loss: 0.669480, acc: 0.585938]  [A loss: 0.801994, acc: 0.316406]\n",
      "1274: [D loss: 0.694440, acc: 0.564453]  [A loss: 1.005442, acc: 0.074219]\n",
      "1275: [D loss: 0.686527, acc: 0.562500]  [A loss: 0.815815, acc: 0.269531]\n",
      "1276: [D loss: 0.676552, acc: 0.585938]  [A loss: 0.995965, acc: 0.078125]\n",
      "1277: [D loss: 0.666536, acc: 0.585938]  [A loss: 0.770873, acc: 0.351562]\n",
      "1278: [D loss: 0.717370, acc: 0.509766]  [A loss: 1.115629, acc: 0.031250]\n",
      "1279: [D loss: 0.696852, acc: 0.515625]  [A loss: 0.737671, acc: 0.460938]\n",
      "1280: [D loss: 0.701205, acc: 0.546875]  [A loss: 1.082662, acc: 0.058594]\n",
      "1281: [D loss: 0.671029, acc: 0.589844]  [A loss: 0.745170, acc: 0.402344]\n",
      "1282: [D loss: 0.706733, acc: 0.517578]  [A loss: 1.163282, acc: 0.015625]\n",
      "1283: [D loss: 0.679177, acc: 0.574219]  [A loss: 0.697713, acc: 0.503906]\n",
      "1284: [D loss: 0.725508, acc: 0.529297]  [A loss: 1.106133, acc: 0.042969]\n",
      "1285: [D loss: 0.677947, acc: 0.552734]  [A loss: 0.703515, acc: 0.496094]\n",
      "1286: [D loss: 0.697297, acc: 0.558594]  [A loss: 1.063384, acc: 0.054688]\n",
      "1287: [D loss: 0.677588, acc: 0.582031]  [A loss: 0.717022, acc: 0.496094]\n",
      "1288: [D loss: 0.692703, acc: 0.544922]  [A loss: 0.983554, acc: 0.093750]\n",
      "1289: [D loss: 0.706932, acc: 0.507812]  [A loss: 0.794622, acc: 0.316406]\n",
      "1290: [D loss: 0.682243, acc: 0.576172]  [A loss: 0.927663, acc: 0.140625]\n",
      "1291: [D loss: 0.702544, acc: 0.541016]  [A loss: 0.916582, acc: 0.167969]\n",
      "1292: [D loss: 0.677617, acc: 0.568359]  [A loss: 0.827340, acc: 0.273438]\n",
      "1293: [D loss: 0.702483, acc: 0.535156]  [A loss: 0.984022, acc: 0.125000]\n",
      "1294: [D loss: 0.703544, acc: 0.521484]  [A loss: 0.855420, acc: 0.261719]\n",
      "1295: [D loss: 0.708527, acc: 0.511719]  [A loss: 0.983679, acc: 0.101562]\n",
      "1296: [D loss: 0.683183, acc: 0.533203]  [A loss: 0.796791, acc: 0.316406]\n",
      "1297: [D loss: 0.699959, acc: 0.548828]  [A loss: 1.034023, acc: 0.042969]\n",
      "1298: [D loss: 0.675499, acc: 0.568359]  [A loss: 0.791069, acc: 0.312500]\n",
      "1299: [D loss: 0.687240, acc: 0.572266]  [A loss: 1.087886, acc: 0.066406]\n",
      "1300: [D loss: 0.689503, acc: 0.529297]  [A loss: 0.718360, acc: 0.468750]\n",
      "1301: [D loss: 0.716486, acc: 0.521484]  [A loss: 1.119437, acc: 0.050781]\n",
      "1302: [D loss: 0.689864, acc: 0.515625]  [A loss: 0.680868, acc: 0.531250]\n",
      "1303: [D loss: 0.751570, acc: 0.513672]  [A loss: 1.099865, acc: 0.058594]\n",
      "1304: [D loss: 0.683138, acc: 0.570312]  [A loss: 0.689630, acc: 0.519531]\n",
      "1305: [D loss: 0.709694, acc: 0.517578]  [A loss: 1.022674, acc: 0.082031]\n",
      "1306: [D loss: 0.677584, acc: 0.582031]  [A loss: 0.762666, acc: 0.375000]\n",
      "1307: [D loss: 0.693291, acc: 0.529297]  [A loss: 0.979963, acc: 0.117188]\n",
      "1308: [D loss: 0.668347, acc: 0.609375]  [A loss: 0.768602, acc: 0.390625]\n",
      "1309: [D loss: 0.707723, acc: 0.505859]  [A loss: 0.988821, acc: 0.082031]\n",
      "1310: [D loss: 0.684204, acc: 0.568359]  [A loss: 0.824878, acc: 0.281250]\n",
      "1311: [D loss: 0.681761, acc: 0.544922]  [A loss: 1.018076, acc: 0.089844]\n",
      "1312: [D loss: 0.673495, acc: 0.591797]  [A loss: 0.806752, acc: 0.324219]\n",
      "1313: [D loss: 0.717330, acc: 0.525391]  [A loss: 1.055034, acc: 0.097656]\n",
      "1314: [D loss: 0.690656, acc: 0.525391]  [A loss: 0.786635, acc: 0.328125]\n",
      "1315: [D loss: 0.699376, acc: 0.541016]  [A loss: 1.116681, acc: 0.042969]\n",
      "1316: [D loss: 0.671538, acc: 0.587891]  [A loss: 0.745940, acc: 0.406250]\n",
      "1317: [D loss: 0.716443, acc: 0.500000]  [A loss: 1.246216, acc: 0.015625]\n",
      "1318: [D loss: 0.688528, acc: 0.562500]  [A loss: 0.605103, acc: 0.707031]\n",
      "1319: [D loss: 0.769282, acc: 0.513672]  [A loss: 1.199986, acc: 0.007812]\n",
      "1320: [D loss: 0.678501, acc: 0.570312]  [A loss: 0.685846, acc: 0.558594]\n",
      "1321: [D loss: 0.724398, acc: 0.529297]  [A loss: 0.936535, acc: 0.144531]\n",
      "1322: [D loss: 0.683976, acc: 0.566406]  [A loss: 0.859869, acc: 0.214844]\n",
      "1323: [D loss: 0.691115, acc: 0.580078]  [A loss: 0.930765, acc: 0.128906]\n",
      "1324: [D loss: 0.700808, acc: 0.533203]  [A loss: 0.845715, acc: 0.222656]\n",
      "1325: [D loss: 0.696611, acc: 0.542969]  [A loss: 0.918541, acc: 0.144531]\n",
      "1326: [D loss: 0.687899, acc: 0.564453]  [A loss: 0.854693, acc: 0.246094]\n",
      "1327: [D loss: 0.698138, acc: 0.511719]  [A loss: 0.910135, acc: 0.144531]\n",
      "1328: [D loss: 0.674328, acc: 0.589844]  [A loss: 0.856652, acc: 0.214844]\n",
      "1329: [D loss: 0.690718, acc: 0.564453]  [A loss: 0.951439, acc: 0.128906]\n",
      "1330: [D loss: 0.688227, acc: 0.548828]  [A loss: 0.814719, acc: 0.289062]\n",
      "1331: [D loss: 0.694627, acc: 0.539062]  [A loss: 0.953439, acc: 0.136719]\n",
      "1332: [D loss: 0.696723, acc: 0.541016]  [A loss: 0.916320, acc: 0.175781]\n",
      "1333: [D loss: 0.684523, acc: 0.552734]  [A loss: 0.906380, acc: 0.164062]\n",
      "1334: [D loss: 0.693331, acc: 0.554688]  [A loss: 0.955698, acc: 0.132812]\n",
      "1335: [D loss: 0.671916, acc: 0.574219]  [A loss: 0.839985, acc: 0.253906]\n",
      "1336: [D loss: 0.688127, acc: 0.556641]  [A loss: 1.071122, acc: 0.070312]\n",
      "1337: [D loss: 0.688646, acc: 0.521484]  [A loss: 0.787434, acc: 0.343750]\n",
      "1338: [D loss: 0.695481, acc: 0.537109]  [A loss: 1.132843, acc: 0.046875]\n",
      "1339: [D loss: 0.680810, acc: 0.564453]  [A loss: 0.646199, acc: 0.613281]\n",
      "1340: [D loss: 0.717844, acc: 0.550781]  [A loss: 1.253648, acc: 0.011719]\n",
      "1341: [D loss: 0.680322, acc: 0.574219]  [A loss: 0.598153, acc: 0.742188]\n",
      "1342: [D loss: 0.748652, acc: 0.515625]  [A loss: 1.158010, acc: 0.035156]\n",
      "1343: [D loss: 0.685870, acc: 0.535156]  [A loss: 0.704140, acc: 0.464844]\n",
      "1344: [D loss: 0.707352, acc: 0.523438]  [A loss: 1.012580, acc: 0.054688]\n",
      "1345: [D loss: 0.694790, acc: 0.548828]  [A loss: 0.764170, acc: 0.355469]\n",
      "1346: [D loss: 0.702568, acc: 0.552734]  [A loss: 1.003673, acc: 0.085938]\n",
      "1347: [D loss: 0.685320, acc: 0.566406]  [A loss: 0.772263, acc: 0.359375]\n",
      "1348: [D loss: 0.705626, acc: 0.541016]  [A loss: 1.026911, acc: 0.085938]\n",
      "1349: [D loss: 0.673475, acc: 0.572266]  [A loss: 0.817100, acc: 0.308594]\n",
      "1350: [D loss: 0.708742, acc: 0.517578]  [A loss: 0.974724, acc: 0.082031]\n",
      "1351: [D loss: 0.676699, acc: 0.566406]  [A loss: 0.819557, acc: 0.308594]\n",
      "1352: [D loss: 0.688115, acc: 0.546875]  [A loss: 1.044065, acc: 0.058594]\n",
      "1353: [D loss: 0.686021, acc: 0.529297]  [A loss: 0.772028, acc: 0.351562]\n",
      "1354: [D loss: 0.684630, acc: 0.568359]  [A loss: 0.995967, acc: 0.117188]\n",
      "1355: [D loss: 0.682544, acc: 0.568359]  [A loss: 0.722683, acc: 0.496094]\n",
      "1356: [D loss: 0.719705, acc: 0.511719]  [A loss: 1.166507, acc: 0.031250]\n",
      "1357: [D loss: 0.682285, acc: 0.572266]  [A loss: 0.684735, acc: 0.542969]\n",
      "1358: [D loss: 0.715428, acc: 0.525391]  [A loss: 1.150143, acc: 0.046875]\n",
      "1359: [D loss: 0.681705, acc: 0.591797]  [A loss: 0.647533, acc: 0.609375]\n",
      "1360: [D loss: 0.709148, acc: 0.535156]  [A loss: 1.170709, acc: 0.039062]\n",
      "1361: [D loss: 0.669057, acc: 0.580078]  [A loss: 0.744544, acc: 0.425781]\n",
      "1362: [D loss: 0.720622, acc: 0.537109]  [A loss: 0.997708, acc: 0.074219]\n",
      "1363: [D loss: 0.678309, acc: 0.578125]  [A loss: 0.850052, acc: 0.250000]\n",
      "1364: [D loss: 0.691979, acc: 0.554688]  [A loss: 0.922755, acc: 0.175781]\n",
      "1365: [D loss: 0.693521, acc: 0.539062]  [A loss: 0.783370, acc: 0.375000]\n",
      "1366: [D loss: 0.693456, acc: 0.558594]  [A loss: 0.970492, acc: 0.109375]\n",
      "1367: [D loss: 0.669935, acc: 0.585938]  [A loss: 0.843774, acc: 0.261719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1368: [D loss: 0.683887, acc: 0.525391]  [A loss: 0.958077, acc: 0.144531]\n",
      "1369: [D loss: 0.677140, acc: 0.582031]  [A loss: 0.819269, acc: 0.273438]\n",
      "1370: [D loss: 0.702655, acc: 0.529297]  [A loss: 0.982483, acc: 0.113281]\n",
      "1371: [D loss: 0.699091, acc: 0.539062]  [A loss: 0.767733, acc: 0.386719]\n",
      "1372: [D loss: 0.698519, acc: 0.552734]  [A loss: 1.092860, acc: 0.054688]\n",
      "1373: [D loss: 0.664843, acc: 0.599609]  [A loss: 0.720220, acc: 0.488281]\n",
      "1374: [D loss: 0.722171, acc: 0.531250]  [A loss: 1.209031, acc: 0.035156]\n",
      "1375: [D loss: 0.696527, acc: 0.548828]  [A loss: 0.695381, acc: 0.546875]\n",
      "1376: [D loss: 0.719614, acc: 0.500000]  [A loss: 1.136732, acc: 0.050781]\n",
      "1377: [D loss: 0.695469, acc: 0.550781]  [A loss: 0.746906, acc: 0.390625]\n",
      "1378: [D loss: 0.703341, acc: 0.548828]  [A loss: 1.057173, acc: 0.070312]\n",
      "1379: [D loss: 0.691700, acc: 0.539062]  [A loss: 0.753869, acc: 0.406250]\n",
      "1380: [D loss: 0.693621, acc: 0.564453]  [A loss: 0.956858, acc: 0.093750]\n",
      "1381: [D loss: 0.670938, acc: 0.583984]  [A loss: 0.887297, acc: 0.187500]\n",
      "1382: [D loss: 0.682335, acc: 0.560547]  [A loss: 0.960644, acc: 0.117188]\n",
      "1383: [D loss: 0.683779, acc: 0.562500]  [A loss: 0.923314, acc: 0.156250]\n",
      "1384: [D loss: 0.707876, acc: 0.507812]  [A loss: 0.936067, acc: 0.117188]\n",
      "1385: [D loss: 0.696090, acc: 0.542969]  [A loss: 0.820292, acc: 0.300781]\n",
      "1386: [D loss: 0.696654, acc: 0.533203]  [A loss: 1.078134, acc: 0.046875]\n",
      "1387: [D loss: 0.675898, acc: 0.558594]  [A loss: 0.798585, acc: 0.378906]\n",
      "1388: [D loss: 0.713812, acc: 0.535156]  [A loss: 1.176824, acc: 0.007812]\n",
      "1389: [D loss: 0.687029, acc: 0.560547]  [A loss: 0.631451, acc: 0.675781]\n",
      "1390: [D loss: 0.751663, acc: 0.511719]  [A loss: 1.230555, acc: 0.011719]\n",
      "1391: [D loss: 0.698283, acc: 0.501953]  [A loss: 0.708351, acc: 0.511719]\n",
      "1392: [D loss: 0.704834, acc: 0.527344]  [A loss: 0.988867, acc: 0.085938]\n",
      "1393: [D loss: 0.676766, acc: 0.587891]  [A loss: 0.819365, acc: 0.250000]\n",
      "1394: [D loss: 0.696568, acc: 0.531250]  [A loss: 0.988230, acc: 0.097656]\n",
      "1395: [D loss: 0.677001, acc: 0.542969]  [A loss: 0.801518, acc: 0.351562]\n",
      "1396: [D loss: 0.712068, acc: 0.533203]  [A loss: 0.981412, acc: 0.121094]\n",
      "1397: [D loss: 0.671531, acc: 0.574219]  [A loss: 0.778896, acc: 0.351562]\n",
      "1398: [D loss: 0.696870, acc: 0.542969]  [A loss: 1.007972, acc: 0.082031]\n",
      "1399: [D loss: 0.672598, acc: 0.572266]  [A loss: 0.745763, acc: 0.414062]\n",
      "1400: [D loss: 0.698752, acc: 0.533203]  [A loss: 1.034328, acc: 0.070312]\n",
      "1401: [D loss: 0.664754, acc: 0.587891]  [A loss: 0.750071, acc: 0.406250]\n",
      "1402: [D loss: 0.697543, acc: 0.531250]  [A loss: 1.079049, acc: 0.070312]\n",
      "1403: [D loss: 0.679281, acc: 0.570312]  [A loss: 0.698541, acc: 0.511719]\n",
      "1404: [D loss: 0.711732, acc: 0.523438]  [A loss: 1.083329, acc: 0.070312]\n",
      "1405: [D loss: 0.692433, acc: 0.556641]  [A loss: 0.658132, acc: 0.605469]\n",
      "1406: [D loss: 0.713268, acc: 0.525391]  [A loss: 1.027242, acc: 0.078125]\n",
      "1407: [D loss: 0.691015, acc: 0.544922]  [A loss: 0.722940, acc: 0.457031]\n",
      "1408: [D loss: 0.708676, acc: 0.517578]  [A loss: 0.986693, acc: 0.101562]\n",
      "1409: [D loss: 0.676946, acc: 0.574219]  [A loss: 0.809283, acc: 0.308594]\n",
      "1410: [D loss: 0.700039, acc: 0.539062]  [A loss: 1.041261, acc: 0.054688]\n",
      "1411: [D loss: 0.683973, acc: 0.541016]  [A loss: 0.747747, acc: 0.421875]\n",
      "1412: [D loss: 0.710806, acc: 0.529297]  [A loss: 0.996736, acc: 0.093750]\n",
      "1413: [D loss: 0.677223, acc: 0.580078]  [A loss: 0.834454, acc: 0.210938]\n",
      "1414: [D loss: 0.686814, acc: 0.564453]  [A loss: 0.899187, acc: 0.171875]\n",
      "1415: [D loss: 0.682415, acc: 0.562500]  [A loss: 0.891548, acc: 0.199219]\n",
      "1416: [D loss: 0.688541, acc: 0.535156]  [A loss: 0.912505, acc: 0.179688]\n",
      "1417: [D loss: 0.695184, acc: 0.519531]  [A loss: 0.901084, acc: 0.148438]\n",
      "1418: [D loss: 0.705387, acc: 0.529297]  [A loss: 0.998356, acc: 0.097656]\n",
      "1419: [D loss: 0.685669, acc: 0.583984]  [A loss: 0.883871, acc: 0.183594]\n",
      "1420: [D loss: 0.707608, acc: 0.521484]  [A loss: 0.943878, acc: 0.136719]\n",
      "1421: [D loss: 0.697894, acc: 0.537109]  [A loss: 1.064556, acc: 0.066406]\n",
      "1422: [D loss: 0.681017, acc: 0.597656]  [A loss: 0.677527, acc: 0.562500]\n",
      "1423: [D loss: 0.718896, acc: 0.509766]  [A loss: 1.261297, acc: 0.011719]\n",
      "1424: [D loss: 0.707999, acc: 0.517578]  [A loss: 0.678597, acc: 0.601562]\n",
      "1425: [D loss: 0.704434, acc: 0.533203]  [A loss: 1.036314, acc: 0.070312]\n",
      "1426: [D loss: 0.676773, acc: 0.556641]  [A loss: 0.696712, acc: 0.496094]\n",
      "1427: [D loss: 0.725063, acc: 0.527344]  [A loss: 1.074288, acc: 0.054688]\n",
      "1428: [D loss: 0.666570, acc: 0.597656]  [A loss: 0.736309, acc: 0.414062]\n",
      "1429: [D loss: 0.703837, acc: 0.541016]  [A loss: 1.054861, acc: 0.046875]\n",
      "1430: [D loss: 0.671240, acc: 0.593750]  [A loss: 0.771298, acc: 0.394531]\n",
      "1431: [D loss: 0.717433, acc: 0.494141]  [A loss: 0.983674, acc: 0.089844]\n",
      "1432: [D loss: 0.673872, acc: 0.556641]  [A loss: 0.793659, acc: 0.343750]\n",
      "1433: [D loss: 0.693164, acc: 0.552734]  [A loss: 0.991718, acc: 0.093750]\n",
      "1434: [D loss: 0.678154, acc: 0.564453]  [A loss: 0.829176, acc: 0.265625]\n",
      "1435: [D loss: 0.694825, acc: 0.542969]  [A loss: 1.017247, acc: 0.074219]\n",
      "1436: [D loss: 0.676980, acc: 0.591797]  [A loss: 0.790894, acc: 0.359375]\n",
      "1437: [D loss: 0.672084, acc: 0.585938]  [A loss: 0.986322, acc: 0.113281]\n",
      "1438: [D loss: 0.679099, acc: 0.576172]  [A loss: 0.835540, acc: 0.304688]\n",
      "1439: [D loss: 0.700584, acc: 0.550781]  [A loss: 0.924566, acc: 0.128906]\n",
      "1440: [D loss: 0.688202, acc: 0.554688]  [A loss: 0.812303, acc: 0.296875]\n",
      "1441: [D loss: 0.688044, acc: 0.564453]  [A loss: 1.024392, acc: 0.074219]\n",
      "1442: [D loss: 0.668645, acc: 0.583984]  [A loss: 0.788424, acc: 0.359375]\n",
      "1443: [D loss: 0.696652, acc: 0.535156]  [A loss: 0.999375, acc: 0.097656]\n",
      "1444: [D loss: 0.683838, acc: 0.548828]  [A loss: 0.810379, acc: 0.292969]\n",
      "1445: [D loss: 0.696848, acc: 0.542969]  [A loss: 1.099863, acc: 0.066406]\n",
      "1446: [D loss: 0.682803, acc: 0.593750]  [A loss: 0.692360, acc: 0.535156]\n",
      "1447: [D loss: 0.704796, acc: 0.539062]  [A loss: 1.134415, acc: 0.050781]\n",
      "1448: [D loss: 0.706917, acc: 0.503906]  [A loss: 0.724394, acc: 0.468750]\n",
      "1449: [D loss: 0.720268, acc: 0.541016]  [A loss: 1.106032, acc: 0.031250]\n",
      "1450: [D loss: 0.689040, acc: 0.529297]  [A loss: 0.697318, acc: 0.511719]\n",
      "1451: [D loss: 0.701143, acc: 0.539062]  [A loss: 0.998254, acc: 0.097656]\n",
      "1452: [D loss: 0.668003, acc: 0.576172]  [A loss: 0.749805, acc: 0.421875]\n",
      "1453: [D loss: 0.700050, acc: 0.541016]  [A loss: 1.046897, acc: 0.074219]\n",
      "1454: [D loss: 0.672367, acc: 0.595703]  [A loss: 0.740845, acc: 0.390625]\n",
      "1455: [D loss: 0.707597, acc: 0.541016]  [A loss: 1.072381, acc: 0.062500]\n",
      "1456: [D loss: 0.685315, acc: 0.554688]  [A loss: 0.763949, acc: 0.347656]\n",
      "1457: [D loss: 0.719007, acc: 0.525391]  [A loss: 1.024752, acc: 0.062500]\n",
      "1458: [D loss: 0.694126, acc: 0.527344]  [A loss: 0.750213, acc: 0.410156]\n",
      "1459: [D loss: 0.697964, acc: 0.544922]  [A loss: 1.027218, acc: 0.070312]\n",
      "1460: [D loss: 0.682080, acc: 0.582031]  [A loss: 0.764460, acc: 0.398438]\n",
      "1461: [D loss: 0.703374, acc: 0.568359]  [A loss: 1.014385, acc: 0.066406]\n",
      "1462: [D loss: 0.674019, acc: 0.580078]  [A loss: 0.764886, acc: 0.378906]\n",
      "1463: [D loss: 0.709378, acc: 0.525391]  [A loss: 1.021683, acc: 0.062500]\n",
      "1464: [D loss: 0.669113, acc: 0.593750]  [A loss: 0.789103, acc: 0.332031]\n",
      "1465: [D loss: 0.703808, acc: 0.539062]  [A loss: 0.971852, acc: 0.097656]\n",
      "1466: [D loss: 0.666761, acc: 0.611328]  [A loss: 0.797548, acc: 0.335938]\n",
      "1467: [D loss: 0.689923, acc: 0.527344]  [A loss: 1.016792, acc: 0.105469]\n",
      "1468: [D loss: 0.681045, acc: 0.552734]  [A loss: 0.777536, acc: 0.320312]\n",
      "1469: [D loss: 0.733415, acc: 0.503906]  [A loss: 1.065408, acc: 0.050781]\n",
      "1470: [D loss: 0.678318, acc: 0.593750]  [A loss: 0.704843, acc: 0.492188]\n",
      "1471: [D loss: 0.724656, acc: 0.527344]  [A loss: 1.192788, acc: 0.031250]\n",
      "1472: [D loss: 0.687887, acc: 0.576172]  [A loss: 0.622165, acc: 0.683594]\n",
      "1473: [D loss: 0.752971, acc: 0.515625]  [A loss: 1.094984, acc: 0.035156]\n",
      "1474: [D loss: 0.674498, acc: 0.580078]  [A loss: 0.724219, acc: 0.464844]\n",
      "1475: [D loss: 0.700664, acc: 0.550781]  [A loss: 1.002944, acc: 0.117188]\n",
      "1476: [D loss: 0.682156, acc: 0.566406]  [A loss: 0.814625, acc: 0.269531]\n",
      "1477: [D loss: 0.694153, acc: 0.576172]  [A loss: 1.025974, acc: 0.082031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1478: [D loss: 0.686133, acc: 0.550781]  [A loss: 0.793849, acc: 0.324219]\n",
      "1479: [D loss: 0.700373, acc: 0.523438]  [A loss: 0.935503, acc: 0.128906]\n",
      "1480: [D loss: 0.703262, acc: 0.535156]  [A loss: 0.870079, acc: 0.207031]\n",
      "1481: [D loss: 0.693074, acc: 0.546875]  [A loss: 0.867175, acc: 0.199219]\n",
      "1482: [D loss: 0.685648, acc: 0.564453]  [A loss: 0.918488, acc: 0.144531]\n",
      "1483: [D loss: 0.678798, acc: 0.572266]  [A loss: 0.899412, acc: 0.167969]\n",
      "1484: [D loss: 0.685468, acc: 0.560547]  [A loss: 0.937745, acc: 0.140625]\n",
      "1485: [D loss: 0.692072, acc: 0.539062]  [A loss: 0.869991, acc: 0.253906]\n",
      "1486: [D loss: 0.693380, acc: 0.537109]  [A loss: 1.007853, acc: 0.078125]\n",
      "1487: [D loss: 0.685847, acc: 0.533203]  [A loss: 0.806963, acc: 0.308594]\n",
      "1488: [D loss: 0.687317, acc: 0.560547]  [A loss: 1.064567, acc: 0.070312]\n",
      "1489: [D loss: 0.686112, acc: 0.539062]  [A loss: 0.755703, acc: 0.398438]\n",
      "1490: [D loss: 0.698104, acc: 0.550781]  [A loss: 1.156238, acc: 0.042969]\n",
      "1491: [D loss: 0.681261, acc: 0.554688]  [A loss: 0.714948, acc: 0.457031]\n",
      "1492: [D loss: 0.708758, acc: 0.541016]  [A loss: 1.179338, acc: 0.035156]\n",
      "1493: [D loss: 0.680492, acc: 0.546875]  [A loss: 0.643315, acc: 0.656250]\n",
      "1494: [D loss: 0.722363, acc: 0.537109]  [A loss: 1.120176, acc: 0.042969]\n",
      "1495: [D loss: 0.672679, acc: 0.562500]  [A loss: 0.703049, acc: 0.437500]\n",
      "1496: [D loss: 0.708062, acc: 0.529297]  [A loss: 1.003924, acc: 0.105469]\n",
      "1497: [D loss: 0.689293, acc: 0.544922]  [A loss: 0.802231, acc: 0.281250]\n",
      "1498: [D loss: 0.697967, acc: 0.539062]  [A loss: 0.940252, acc: 0.148438]\n",
      "1499: [D loss: 0.680036, acc: 0.550781]  [A loss: 0.877851, acc: 0.218750]\n",
      "1500: [D loss: 0.695718, acc: 0.576172]  [A loss: 0.892685, acc: 0.175781]\n",
      "1501: [D loss: 0.692779, acc: 0.554688]  [A loss: 0.772483, acc: 0.371094]\n",
      "1502: [D loss: 0.692942, acc: 0.562500]  [A loss: 1.037833, acc: 0.074219]\n",
      "1503: [D loss: 0.698432, acc: 0.535156]  [A loss: 0.742523, acc: 0.437500]\n",
      "1504: [D loss: 0.713260, acc: 0.529297]  [A loss: 1.071716, acc: 0.066406]\n",
      "1505: [D loss: 0.693447, acc: 0.560547]  [A loss: 0.711390, acc: 0.480469]\n",
      "1506: [D loss: 0.716618, acc: 0.509766]  [A loss: 1.087772, acc: 0.027344]\n",
      "1507: [D loss: 0.676708, acc: 0.562500]  [A loss: 0.720427, acc: 0.500000]\n",
      "1508: [D loss: 0.709914, acc: 0.537109]  [A loss: 0.989847, acc: 0.101562]\n",
      "1509: [D loss: 0.705729, acc: 0.501953]  [A loss: 0.753405, acc: 0.394531]\n",
      "1510: [D loss: 0.723270, acc: 0.517578]  [A loss: 1.045323, acc: 0.046875]\n",
      "1511: [D loss: 0.686530, acc: 0.572266]  [A loss: 0.762166, acc: 0.390625]\n",
      "1512: [D loss: 0.698347, acc: 0.531250]  [A loss: 0.954433, acc: 0.105469]\n",
      "1513: [D loss: 0.688075, acc: 0.550781]  [A loss: 0.696945, acc: 0.527344]\n",
      "1514: [D loss: 0.708643, acc: 0.546875]  [A loss: 1.001072, acc: 0.089844]\n",
      "1515: [D loss: 0.679867, acc: 0.564453]  [A loss: 0.757957, acc: 0.375000]\n",
      "1516: [D loss: 0.696166, acc: 0.539062]  [A loss: 0.968267, acc: 0.117188]\n",
      "1517: [D loss: 0.676329, acc: 0.591797]  [A loss: 0.810688, acc: 0.265625]\n",
      "1518: [D loss: 0.693263, acc: 0.539062]  [A loss: 0.931211, acc: 0.125000]\n",
      "1519: [D loss: 0.682694, acc: 0.556641]  [A loss: 0.855840, acc: 0.207031]\n",
      "1520: [D loss: 0.690005, acc: 0.554688]  [A loss: 0.967819, acc: 0.105469]\n",
      "1521: [D loss: 0.690196, acc: 0.558594]  [A loss: 0.797894, acc: 0.308594]\n",
      "1522: [D loss: 0.688682, acc: 0.566406]  [A loss: 0.963579, acc: 0.085938]\n",
      "1523: [D loss: 0.669187, acc: 0.587891]  [A loss: 0.805437, acc: 0.312500]\n",
      "1524: [D loss: 0.714837, acc: 0.525391]  [A loss: 1.096546, acc: 0.039062]\n",
      "1525: [D loss: 0.691209, acc: 0.546875]  [A loss: 0.670447, acc: 0.574219]\n",
      "1526: [D loss: 0.708029, acc: 0.533203]  [A loss: 1.198680, acc: 0.007812]\n",
      "1527: [D loss: 0.682806, acc: 0.566406]  [A loss: 0.644602, acc: 0.621094]\n",
      "1528: [D loss: 0.723100, acc: 0.523438]  [A loss: 1.003810, acc: 0.089844]\n",
      "1529: [D loss: 0.684494, acc: 0.589844]  [A loss: 0.746423, acc: 0.414062]\n",
      "1530: [D loss: 0.688173, acc: 0.519531]  [A loss: 0.949518, acc: 0.117188]\n",
      "1531: [D loss: 0.673909, acc: 0.574219]  [A loss: 0.731597, acc: 0.460938]\n",
      "1532: [D loss: 0.691677, acc: 0.535156]  [A loss: 0.983525, acc: 0.074219]\n",
      "1533: [D loss: 0.684167, acc: 0.564453]  [A loss: 0.889507, acc: 0.156250]\n",
      "1534: [D loss: 0.699966, acc: 0.537109]  [A loss: 0.884730, acc: 0.210938]\n",
      "1535: [D loss: 0.693205, acc: 0.515625]  [A loss: 0.842187, acc: 0.246094]\n",
      "1536: [D loss: 0.682896, acc: 0.552734]  [A loss: 0.940597, acc: 0.109375]\n",
      "1537: [D loss: 0.690867, acc: 0.550781]  [A loss: 0.887716, acc: 0.199219]\n",
      "1538: [D loss: 0.687075, acc: 0.552734]  [A loss: 0.986448, acc: 0.132812]\n",
      "1539: [D loss: 0.690985, acc: 0.507812]  [A loss: 0.834824, acc: 0.234375]\n",
      "1540: [D loss: 0.705207, acc: 0.539062]  [A loss: 1.043287, acc: 0.097656]\n",
      "1541: [D loss: 0.661287, acc: 0.625000]  [A loss: 0.721429, acc: 0.437500]\n",
      "1542: [D loss: 0.709711, acc: 0.515625]  [A loss: 1.131901, acc: 0.031250]\n",
      "1543: [D loss: 0.687779, acc: 0.539062]  [A loss: 0.681101, acc: 0.574219]\n",
      "1544: [D loss: 0.722624, acc: 0.511719]  [A loss: 1.150527, acc: 0.031250]\n",
      "1545: [D loss: 0.707506, acc: 0.513672]  [A loss: 0.665088, acc: 0.585938]\n",
      "1546: [D loss: 0.716024, acc: 0.515625]  [A loss: 1.037666, acc: 0.042969]\n",
      "1547: [D loss: 0.679555, acc: 0.591797]  [A loss: 0.751282, acc: 0.433594]\n",
      "1548: [D loss: 0.711136, acc: 0.519531]  [A loss: 0.951533, acc: 0.125000]\n",
      "1549: [D loss: 0.693620, acc: 0.542969]  [A loss: 0.796087, acc: 0.304688]\n",
      "1550: [D loss: 0.692703, acc: 0.560547]  [A loss: 0.911563, acc: 0.132812]\n",
      "1551: [D loss: 0.681128, acc: 0.542969]  [A loss: 0.800607, acc: 0.332031]\n",
      "1552: [D loss: 0.687030, acc: 0.564453]  [A loss: 0.893271, acc: 0.183594]\n",
      "1553: [D loss: 0.695893, acc: 0.531250]  [A loss: 0.881151, acc: 0.175781]\n",
      "1554: [D loss: 0.701623, acc: 0.537109]  [A loss: 0.913575, acc: 0.132812]\n",
      "1555: [D loss: 0.699145, acc: 0.548828]  [A loss: 0.856281, acc: 0.203125]\n",
      "1556: [D loss: 0.686582, acc: 0.564453]  [A loss: 0.971035, acc: 0.105469]\n",
      "1557: [D loss: 0.696220, acc: 0.531250]  [A loss: 0.820768, acc: 0.285156]\n",
      "1558: [D loss: 0.688657, acc: 0.564453]  [A loss: 1.048714, acc: 0.058594]\n",
      "1559: [D loss: 0.689220, acc: 0.570312]  [A loss: 0.804526, acc: 0.281250]\n",
      "1560: [D loss: 0.690476, acc: 0.521484]  [A loss: 1.026749, acc: 0.082031]\n",
      "1561: [D loss: 0.674216, acc: 0.556641]  [A loss: 0.721879, acc: 0.488281]\n",
      "1562: [D loss: 0.705703, acc: 0.513672]  [A loss: 1.143187, acc: 0.035156]\n",
      "1563: [D loss: 0.698758, acc: 0.544922]  [A loss: 0.630502, acc: 0.675781]\n",
      "1564: [D loss: 0.733318, acc: 0.505859]  [A loss: 1.083298, acc: 0.046875]\n",
      "1565: [D loss: 0.677680, acc: 0.572266]  [A loss: 0.737658, acc: 0.386719]\n",
      "1566: [D loss: 0.711329, acc: 0.537109]  [A loss: 1.007001, acc: 0.058594]\n",
      "1567: [D loss: 0.678229, acc: 0.562500]  [A loss: 0.693420, acc: 0.496094]\n",
      "1568: [D loss: 0.708315, acc: 0.519531]  [A loss: 0.934380, acc: 0.093750]\n",
      "1569: [D loss: 0.685873, acc: 0.542969]  [A loss: 0.750291, acc: 0.375000]\n",
      "1570: [D loss: 0.699473, acc: 0.529297]  [A loss: 0.976589, acc: 0.113281]\n",
      "1571: [D loss: 0.685020, acc: 0.578125]  [A loss: 0.756135, acc: 0.371094]\n",
      "1572: [D loss: 0.687831, acc: 0.570312]  [A loss: 0.995977, acc: 0.066406]\n",
      "1573: [D loss: 0.678487, acc: 0.539062]  [A loss: 0.773058, acc: 0.335938]\n",
      "1574: [D loss: 0.693313, acc: 0.546875]  [A loss: 0.942078, acc: 0.152344]\n",
      "1575: [D loss: 0.686807, acc: 0.554688]  [A loss: 0.844223, acc: 0.250000]\n",
      "1576: [D loss: 0.688584, acc: 0.531250]  [A loss: 0.914701, acc: 0.175781]\n",
      "1577: [D loss: 0.681286, acc: 0.568359]  [A loss: 0.888189, acc: 0.199219]\n",
      "1578: [D loss: 0.697316, acc: 0.539062]  [A loss: 0.971105, acc: 0.089844]\n",
      "1579: [D loss: 0.694417, acc: 0.544922]  [A loss: 0.864326, acc: 0.210938]\n",
      "1580: [D loss: 0.696231, acc: 0.554688]  [A loss: 0.958551, acc: 0.128906]\n",
      "1581: [D loss: 0.679411, acc: 0.564453]  [A loss: 0.902645, acc: 0.148438]\n",
      "1582: [D loss: 0.700975, acc: 0.552734]  [A loss: 0.999077, acc: 0.093750]\n",
      "1583: [D loss: 0.690544, acc: 0.550781]  [A loss: 0.730561, acc: 0.464844]\n",
      "1584: [D loss: 0.711146, acc: 0.539062]  [A loss: 1.086743, acc: 0.050781]\n",
      "1585: [D loss: 0.677948, acc: 0.578125]  [A loss: 0.712247, acc: 0.511719]\n",
      "1586: [D loss: 0.710323, acc: 0.523438]  [A loss: 1.138599, acc: 0.019531]\n",
      "1587: [D loss: 0.681014, acc: 0.541016]  [A loss: 0.657509, acc: 0.597656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1588: [D loss: 0.734132, acc: 0.490234]  [A loss: 1.053745, acc: 0.070312]\n",
      "1589: [D loss: 0.696738, acc: 0.515625]  [A loss: 0.727353, acc: 0.464844]\n",
      "1590: [D loss: 0.705506, acc: 0.525391]  [A loss: 0.977096, acc: 0.089844]\n",
      "1591: [D loss: 0.687674, acc: 0.542969]  [A loss: 0.738834, acc: 0.414062]\n",
      "1592: [D loss: 0.699005, acc: 0.525391]  [A loss: 0.972891, acc: 0.113281]\n",
      "1593: [D loss: 0.693210, acc: 0.529297]  [A loss: 0.822073, acc: 0.199219]\n",
      "1594: [D loss: 0.705421, acc: 0.525391]  [A loss: 0.914931, acc: 0.167969]\n",
      "1595: [D loss: 0.697174, acc: 0.527344]  [A loss: 0.788274, acc: 0.324219]\n",
      "1596: [D loss: 0.693145, acc: 0.523438]  [A loss: 1.010325, acc: 0.085938]\n",
      "1597: [D loss: 0.691513, acc: 0.554688]  [A loss: 0.746880, acc: 0.433594]\n",
      "1598: [D loss: 0.712348, acc: 0.509766]  [A loss: 1.062685, acc: 0.042969]\n",
      "1599: [D loss: 0.682659, acc: 0.568359]  [A loss: 0.721646, acc: 0.464844]\n",
      "1600: [D loss: 0.725201, acc: 0.498047]  [A loss: 1.039027, acc: 0.062500]\n",
      "1601: [D loss: 0.684219, acc: 0.554688]  [A loss: 0.703613, acc: 0.523438]\n",
      "1602: [D loss: 0.723910, acc: 0.513672]  [A loss: 1.024042, acc: 0.046875]\n",
      "1603: [D loss: 0.684486, acc: 0.527344]  [A loss: 0.748249, acc: 0.363281]\n",
      "1604: [D loss: 0.706305, acc: 0.501953]  [A loss: 1.013566, acc: 0.054688]\n",
      "1605: [D loss: 0.686330, acc: 0.542969]  [A loss: 0.767381, acc: 0.328125]\n",
      "1606: [D loss: 0.688379, acc: 0.560547]  [A loss: 0.955530, acc: 0.093750]\n",
      "1607: [D loss: 0.682568, acc: 0.572266]  [A loss: 0.769808, acc: 0.355469]\n",
      "1608: [D loss: 0.709785, acc: 0.505859]  [A loss: 0.986611, acc: 0.105469]\n",
      "1609: [D loss: 0.675973, acc: 0.589844]  [A loss: 0.739333, acc: 0.437500]\n",
      "1610: [D loss: 0.705538, acc: 0.544922]  [A loss: 1.045139, acc: 0.093750]\n",
      "1611: [D loss: 0.676800, acc: 0.560547]  [A loss: 0.724182, acc: 0.476562]\n",
      "1612: [D loss: 0.696931, acc: 0.556641]  [A loss: 0.919919, acc: 0.109375]\n",
      "1613: [D loss: 0.668840, acc: 0.574219]  [A loss: 0.766930, acc: 0.367188]\n",
      "1614: [D loss: 0.697795, acc: 0.517578]  [A loss: 0.971719, acc: 0.078125]\n",
      "1615: [D loss: 0.674920, acc: 0.574219]  [A loss: 0.785236, acc: 0.371094]\n",
      "1616: [D loss: 0.689899, acc: 0.556641]  [A loss: 0.983413, acc: 0.093750]\n",
      "1617: [D loss: 0.685173, acc: 0.548828]  [A loss: 0.799422, acc: 0.289062]\n",
      "1618: [D loss: 0.684570, acc: 0.587891]  [A loss: 0.937110, acc: 0.125000]\n",
      "1619: [D loss: 0.680997, acc: 0.576172]  [A loss: 0.844028, acc: 0.273438]\n",
      "1620: [D loss: 0.700149, acc: 0.525391]  [A loss: 1.039257, acc: 0.054688]\n",
      "1621: [D loss: 0.681516, acc: 0.552734]  [A loss: 0.756663, acc: 0.417969]\n",
      "1622: [D loss: 0.696679, acc: 0.537109]  [A loss: 1.061292, acc: 0.062500]\n",
      "1623: [D loss: 0.673296, acc: 0.580078]  [A loss: 0.705980, acc: 0.492188]\n",
      "1624: [D loss: 0.720272, acc: 0.527344]  [A loss: 1.146798, acc: 0.039062]\n",
      "1625: [D loss: 0.689547, acc: 0.554688]  [A loss: 0.644088, acc: 0.648438]\n",
      "1626: [D loss: 0.723109, acc: 0.523438]  [A loss: 1.053398, acc: 0.035156]\n",
      "1627: [D loss: 0.685315, acc: 0.583984]  [A loss: 0.712985, acc: 0.476562]\n",
      "1628: [D loss: 0.707860, acc: 0.541016]  [A loss: 0.993739, acc: 0.066406]\n",
      "1629: [D loss: 0.684280, acc: 0.568359]  [A loss: 0.818902, acc: 0.273438]\n",
      "1630: [D loss: 0.679278, acc: 0.591797]  [A loss: 0.974159, acc: 0.085938]\n",
      "1631: [D loss: 0.698362, acc: 0.507812]  [A loss: 0.834684, acc: 0.199219]\n",
      "1632: [D loss: 0.704136, acc: 0.521484]  [A loss: 0.887807, acc: 0.214844]\n",
      "1633: [D loss: 0.683244, acc: 0.544922]  [A loss: 0.848666, acc: 0.207031]\n",
      "1634: [D loss: 0.680148, acc: 0.554688]  [A loss: 0.882678, acc: 0.207031]\n",
      "1635: [D loss: 0.689414, acc: 0.554688]  [A loss: 0.897575, acc: 0.195312]\n",
      "1636: [D loss: 0.683902, acc: 0.560547]  [A loss: 0.893729, acc: 0.187500]\n",
      "1637: [D loss: 0.690560, acc: 0.529297]  [A loss: 0.956046, acc: 0.140625]\n",
      "1638: [D loss: 0.671689, acc: 0.587891]  [A loss: 0.852783, acc: 0.269531]\n",
      "1639: [D loss: 0.691525, acc: 0.542969]  [A loss: 0.991663, acc: 0.078125]\n",
      "1640: [D loss: 0.685122, acc: 0.548828]  [A loss: 0.721887, acc: 0.464844]\n",
      "1641: [D loss: 0.697882, acc: 0.539062]  [A loss: 1.085663, acc: 0.039062]\n",
      "1642: [D loss: 0.679982, acc: 0.550781]  [A loss: 0.736654, acc: 0.445312]\n",
      "1643: [D loss: 0.698820, acc: 0.533203]  [A loss: 1.111765, acc: 0.035156]\n",
      "1644: [D loss: 0.699107, acc: 0.515625]  [A loss: 0.657242, acc: 0.597656]\n",
      "1645: [D loss: 0.718168, acc: 0.521484]  [A loss: 1.059181, acc: 0.039062]\n",
      "1646: [D loss: 0.689017, acc: 0.544922]  [A loss: 0.682024, acc: 0.539062]\n",
      "1647: [D loss: 0.702255, acc: 0.535156]  [A loss: 0.940216, acc: 0.109375]\n",
      "1648: [D loss: 0.681592, acc: 0.568359]  [A loss: 0.782162, acc: 0.339844]\n",
      "1649: [D loss: 0.693099, acc: 0.515625]  [A loss: 0.854176, acc: 0.214844]\n",
      "1650: [D loss: 0.688840, acc: 0.572266]  [A loss: 0.908923, acc: 0.128906]\n",
      "1651: [D loss: 0.692681, acc: 0.554688]  [A loss: 0.878554, acc: 0.156250]\n",
      "1652: [D loss: 0.679693, acc: 0.562500]  [A loss: 0.930354, acc: 0.125000]\n",
      "1653: [D loss: 0.672370, acc: 0.593750]  [A loss: 0.845766, acc: 0.238281]\n",
      "1654: [D loss: 0.700759, acc: 0.546875]  [A loss: 0.887948, acc: 0.187500]\n",
      "1655: [D loss: 0.684590, acc: 0.564453]  [A loss: 0.817912, acc: 0.285156]\n",
      "1656: [D loss: 0.697912, acc: 0.550781]  [A loss: 1.022134, acc: 0.085938]\n",
      "1657: [D loss: 0.695236, acc: 0.548828]  [A loss: 0.673289, acc: 0.582031]\n",
      "1658: [D loss: 0.727208, acc: 0.527344]  [A loss: 1.090412, acc: 0.015625]\n",
      "1659: [D loss: 0.683363, acc: 0.562500]  [A loss: 0.687581, acc: 0.531250]\n",
      "1660: [D loss: 0.714390, acc: 0.515625]  [A loss: 1.024521, acc: 0.062500]\n",
      "1661: [D loss: 0.686792, acc: 0.544922]  [A loss: 0.739969, acc: 0.441406]\n",
      "1662: [D loss: 0.711952, acc: 0.515625]  [A loss: 0.954836, acc: 0.101562]\n",
      "1663: [D loss: 0.697431, acc: 0.544922]  [A loss: 0.826306, acc: 0.222656]\n",
      "1664: [D loss: 0.700079, acc: 0.533203]  [A loss: 0.912326, acc: 0.132812]\n",
      "1665: [D loss: 0.672438, acc: 0.582031]  [A loss: 0.808714, acc: 0.277344]\n",
      "1666: [D loss: 0.690936, acc: 0.558594]  [A loss: 1.021707, acc: 0.066406]\n",
      "1667: [D loss: 0.676032, acc: 0.580078]  [A loss: 0.741172, acc: 0.394531]\n",
      "1668: [D loss: 0.702266, acc: 0.548828]  [A loss: 0.998685, acc: 0.097656]\n",
      "1669: [D loss: 0.686762, acc: 0.541016]  [A loss: 0.695854, acc: 0.527344]\n",
      "1670: [D loss: 0.718514, acc: 0.513672]  [A loss: 1.024578, acc: 0.058594]\n",
      "1671: [D loss: 0.692346, acc: 0.560547]  [A loss: 0.708793, acc: 0.476562]\n",
      "1672: [D loss: 0.707894, acc: 0.521484]  [A loss: 1.016389, acc: 0.050781]\n",
      "1673: [D loss: 0.678755, acc: 0.591797]  [A loss: 0.731523, acc: 0.445312]\n",
      "1674: [D loss: 0.695689, acc: 0.533203]  [A loss: 0.993513, acc: 0.078125]\n",
      "1675: [D loss: 0.662153, acc: 0.597656]  [A loss: 0.737588, acc: 0.406250]\n",
      "1676: [D loss: 0.704942, acc: 0.542969]  [A loss: 0.984429, acc: 0.097656]\n",
      "1677: [D loss: 0.687696, acc: 0.570312]  [A loss: 0.703961, acc: 0.527344]\n",
      "1678: [D loss: 0.734350, acc: 0.501953]  [A loss: 0.955550, acc: 0.105469]\n",
      "1679: [D loss: 0.694682, acc: 0.533203]  [A loss: 0.788194, acc: 0.343750]\n",
      "1680: [D loss: 0.695721, acc: 0.546875]  [A loss: 0.901085, acc: 0.152344]\n",
      "1681: [D loss: 0.677033, acc: 0.591797]  [A loss: 0.823368, acc: 0.253906]\n",
      "1682: [D loss: 0.683874, acc: 0.562500]  [A loss: 0.866820, acc: 0.226562]\n",
      "1683: [D loss: 0.686625, acc: 0.570312]  [A loss: 0.851420, acc: 0.265625]\n",
      "1684: [D loss: 0.688730, acc: 0.542969]  [A loss: 0.980321, acc: 0.113281]\n",
      "1685: [D loss: 0.693422, acc: 0.533203]  [A loss: 0.741664, acc: 0.386719]\n",
      "1686: [D loss: 0.694627, acc: 0.558594]  [A loss: 1.017133, acc: 0.082031]\n",
      "1687: [D loss: 0.670611, acc: 0.585938]  [A loss: 0.748096, acc: 0.398438]\n",
      "1688: [D loss: 0.695965, acc: 0.542969]  [A loss: 1.018596, acc: 0.062500]\n",
      "1689: [D loss: 0.687183, acc: 0.576172]  [A loss: 0.743795, acc: 0.453125]\n",
      "1690: [D loss: 0.707935, acc: 0.511719]  [A loss: 1.055357, acc: 0.042969]\n",
      "1691: [D loss: 0.689341, acc: 0.566406]  [A loss: 0.652569, acc: 0.585938]\n",
      "1692: [D loss: 0.719586, acc: 0.515625]  [A loss: 0.972713, acc: 0.101562]\n",
      "1693: [D loss: 0.677085, acc: 0.574219]  [A loss: 0.750156, acc: 0.398438]\n",
      "1694: [D loss: 0.688593, acc: 0.566406]  [A loss: 0.941829, acc: 0.128906]\n",
      "1695: [D loss: 0.683035, acc: 0.552734]  [A loss: 0.829752, acc: 0.292969]\n",
      "1696: [D loss: 0.699794, acc: 0.531250]  [A loss: 0.928409, acc: 0.140625]\n",
      "1697: [D loss: 0.680203, acc: 0.566406]  [A loss: 0.805383, acc: 0.273438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1698: [D loss: 0.697070, acc: 0.523438]  [A loss: 1.005432, acc: 0.089844]\n",
      "1699: [D loss: 0.689680, acc: 0.548828]  [A loss: 0.755391, acc: 0.386719]\n",
      "1700: [D loss: 0.703946, acc: 0.492188]  [A loss: 1.008146, acc: 0.082031]\n",
      "1701: [D loss: 0.679529, acc: 0.558594]  [A loss: 0.725528, acc: 0.445312]\n",
      "1702: [D loss: 0.721577, acc: 0.523438]  [A loss: 1.085888, acc: 0.058594]\n",
      "1703: [D loss: 0.681569, acc: 0.531250]  [A loss: 0.726225, acc: 0.433594]\n",
      "1704: [D loss: 0.696903, acc: 0.537109]  [A loss: 1.006298, acc: 0.082031]\n",
      "1705: [D loss: 0.679392, acc: 0.554688]  [A loss: 0.759996, acc: 0.414062]\n",
      "1706: [D loss: 0.689988, acc: 0.548828]  [A loss: 0.946578, acc: 0.121094]\n",
      "1707: [D loss: 0.684599, acc: 0.566406]  [A loss: 0.801996, acc: 0.253906]\n",
      "1708: [D loss: 0.698877, acc: 0.527344]  [A loss: 0.947409, acc: 0.113281]\n",
      "1709: [D loss: 0.672151, acc: 0.597656]  [A loss: 0.820084, acc: 0.246094]\n",
      "1710: [D loss: 0.689821, acc: 0.558594]  [A loss: 0.953279, acc: 0.113281]\n",
      "1711: [D loss: 0.689485, acc: 0.550781]  [A loss: 0.872069, acc: 0.207031]\n",
      "1712: [D loss: 0.693747, acc: 0.546875]  [A loss: 1.021497, acc: 0.078125]\n",
      "1713: [D loss: 0.684151, acc: 0.574219]  [A loss: 0.739627, acc: 0.410156]\n",
      "1714: [D loss: 0.710064, acc: 0.507812]  [A loss: 1.124406, acc: 0.046875]\n",
      "1715: [D loss: 0.686952, acc: 0.572266]  [A loss: 0.686419, acc: 0.527344]\n",
      "1716: [D loss: 0.708348, acc: 0.509766]  [A loss: 1.087246, acc: 0.046875]\n",
      "1717: [D loss: 0.683088, acc: 0.562500]  [A loss: 0.692680, acc: 0.507812]\n",
      "1718: [D loss: 0.714104, acc: 0.519531]  [A loss: 1.067842, acc: 0.054688]\n",
      "1719: [D loss: 0.678998, acc: 0.556641]  [A loss: 0.745600, acc: 0.394531]\n",
      "1720: [D loss: 0.696676, acc: 0.529297]  [A loss: 1.006583, acc: 0.097656]\n",
      "1721: [D loss: 0.689551, acc: 0.544922]  [A loss: 0.736779, acc: 0.410156]\n",
      "1722: [D loss: 0.701300, acc: 0.535156]  [A loss: 0.991904, acc: 0.070312]\n",
      "1723: [D loss: 0.682879, acc: 0.556641]  [A loss: 0.710914, acc: 0.484375]\n",
      "1724: [D loss: 0.723295, acc: 0.505859]  [A loss: 0.955570, acc: 0.105469]\n",
      "1725: [D loss: 0.680615, acc: 0.578125]  [A loss: 0.796979, acc: 0.304688]\n",
      "1726: [D loss: 0.690899, acc: 0.539062]  [A loss: 0.893090, acc: 0.117188]\n",
      "1727: [D loss: 0.672396, acc: 0.576172]  [A loss: 0.816638, acc: 0.269531]\n",
      "1728: [D loss: 0.693684, acc: 0.535156]  [A loss: 0.945628, acc: 0.078125]\n",
      "1729: [D loss: 0.684185, acc: 0.539062]  [A loss: 0.836442, acc: 0.242188]\n",
      "1730: [D loss: 0.695890, acc: 0.531250]  [A loss: 0.956791, acc: 0.101562]\n",
      "1731: [D loss: 0.676138, acc: 0.582031]  [A loss: 0.819099, acc: 0.269531]\n",
      "1732: [D loss: 0.675080, acc: 0.542969]  [A loss: 0.989635, acc: 0.074219]\n",
      "1733: [D loss: 0.692607, acc: 0.529297]  [A loss: 0.747976, acc: 0.371094]\n",
      "1734: [D loss: 0.699801, acc: 0.550781]  [A loss: 1.006958, acc: 0.082031]\n",
      "1735: [D loss: 0.694743, acc: 0.527344]  [A loss: 0.789100, acc: 0.316406]\n",
      "1736: [D loss: 0.690880, acc: 0.570312]  [A loss: 0.963458, acc: 0.113281]\n",
      "1737: [D loss: 0.684800, acc: 0.537109]  [A loss: 0.793026, acc: 0.320312]\n",
      "1738: [D loss: 0.702590, acc: 0.539062]  [A loss: 1.068013, acc: 0.058594]\n",
      "1739: [D loss: 0.691931, acc: 0.539062]  [A loss: 0.695038, acc: 0.515625]\n",
      "1740: [D loss: 0.707186, acc: 0.541016]  [A loss: 1.054231, acc: 0.046875]\n",
      "1741: [D loss: 0.678316, acc: 0.566406]  [A loss: 0.681381, acc: 0.535156]\n",
      "1742: [D loss: 0.718525, acc: 0.517578]  [A loss: 0.965214, acc: 0.132812]\n",
      "1743: [D loss: 0.675371, acc: 0.580078]  [A loss: 0.756083, acc: 0.371094]\n",
      "1744: [D loss: 0.693730, acc: 0.537109]  [A loss: 0.927324, acc: 0.140625]\n",
      "1745: [D loss: 0.680480, acc: 0.570312]  [A loss: 0.787056, acc: 0.320312]\n",
      "1746: [D loss: 0.695842, acc: 0.519531]  [A loss: 0.929843, acc: 0.156250]\n",
      "1747: [D loss: 0.664005, acc: 0.607422]  [A loss: 0.759845, acc: 0.363281]\n",
      "1748: [D loss: 0.697919, acc: 0.527344]  [A loss: 0.968500, acc: 0.125000]\n",
      "1749: [D loss: 0.673925, acc: 0.580078]  [A loss: 0.731456, acc: 0.421875]\n",
      "1750: [D loss: 0.702086, acc: 0.521484]  [A loss: 1.078238, acc: 0.058594]\n",
      "1751: [D loss: 0.680462, acc: 0.580078]  [A loss: 0.695716, acc: 0.519531]\n",
      "1752: [D loss: 0.695108, acc: 0.533203]  [A loss: 0.922731, acc: 0.140625]\n",
      "1753: [D loss: 0.699122, acc: 0.544922]  [A loss: 0.837259, acc: 0.210938]\n",
      "1754: [D loss: 0.689240, acc: 0.556641]  [A loss: 0.945611, acc: 0.121094]\n",
      "1755: [D loss: 0.683269, acc: 0.533203]  [A loss: 0.870331, acc: 0.207031]\n",
      "1756: [D loss: 0.695056, acc: 0.542969]  [A loss: 0.863471, acc: 0.171875]\n",
      "1757: [D loss: 0.698661, acc: 0.519531]  [A loss: 0.931814, acc: 0.113281]\n",
      "1758: [D loss: 0.673739, acc: 0.578125]  [A loss: 0.753312, acc: 0.410156]\n",
      "1759: [D loss: 0.707373, acc: 0.519531]  [A loss: 0.980819, acc: 0.085938]\n",
      "1760: [D loss: 0.689958, acc: 0.525391]  [A loss: 0.721965, acc: 0.468750]\n",
      "1761: [D loss: 0.701646, acc: 0.527344]  [A loss: 1.106815, acc: 0.019531]\n",
      "1762: [D loss: 0.684727, acc: 0.546875]  [A loss: 0.664508, acc: 0.648438]\n",
      "1763: [D loss: 0.721712, acc: 0.519531]  [A loss: 0.974167, acc: 0.113281]\n",
      "1764: [D loss: 0.692034, acc: 0.529297]  [A loss: 0.748913, acc: 0.371094]\n",
      "1765: [D loss: 0.712827, acc: 0.535156]  [A loss: 0.941941, acc: 0.093750]\n",
      "1766: [D loss: 0.676874, acc: 0.572266]  [A loss: 0.794683, acc: 0.296875]\n",
      "1767: [D loss: 0.693954, acc: 0.548828]  [A loss: 0.992799, acc: 0.097656]\n",
      "1768: [D loss: 0.678807, acc: 0.537109]  [A loss: 0.797995, acc: 0.328125]\n",
      "1769: [D loss: 0.676166, acc: 0.564453]  [A loss: 0.971342, acc: 0.085938]\n",
      "1770: [D loss: 0.692461, acc: 0.519531]  [A loss: 0.758451, acc: 0.382812]\n",
      "1771: [D loss: 0.691988, acc: 0.542969]  [A loss: 0.996961, acc: 0.078125]\n",
      "1772: [D loss: 0.682709, acc: 0.570312]  [A loss: 0.747099, acc: 0.378906]\n",
      "1773: [D loss: 0.709220, acc: 0.498047]  [A loss: 0.935860, acc: 0.121094]\n",
      "1774: [D loss: 0.670858, acc: 0.582031]  [A loss: 0.846775, acc: 0.214844]\n",
      "1775: [D loss: 0.687845, acc: 0.572266]  [A loss: 0.993722, acc: 0.078125]\n",
      "1776: [D loss: 0.679389, acc: 0.558594]  [A loss: 0.767093, acc: 0.347656]\n",
      "1777: [D loss: 0.705055, acc: 0.529297]  [A loss: 1.089775, acc: 0.062500]\n",
      "1778: [D loss: 0.689062, acc: 0.548828]  [A loss: 0.665578, acc: 0.609375]\n",
      "1779: [D loss: 0.707531, acc: 0.525391]  [A loss: 1.044761, acc: 0.035156]\n",
      "1780: [D loss: 0.671156, acc: 0.587891]  [A loss: 0.741748, acc: 0.421875]\n",
      "1781: [D loss: 0.706665, acc: 0.544922]  [A loss: 0.940363, acc: 0.109375]\n",
      "1782: [D loss: 0.687220, acc: 0.554688]  [A loss: 0.800010, acc: 0.292969]\n",
      "1783: [D loss: 0.708767, acc: 0.501953]  [A loss: 0.854783, acc: 0.214844]\n",
      "1784: [D loss: 0.685203, acc: 0.570312]  [A loss: 0.847001, acc: 0.238281]\n",
      "1785: [D loss: 0.686318, acc: 0.548828]  [A loss: 0.840643, acc: 0.242188]\n",
      "1786: [D loss: 0.682988, acc: 0.568359]  [A loss: 0.929483, acc: 0.160156]\n",
      "1787: [D loss: 0.687023, acc: 0.572266]  [A loss: 0.799437, acc: 0.320312]\n",
      "1788: [D loss: 0.700074, acc: 0.548828]  [A loss: 0.984364, acc: 0.085938]\n",
      "1789: [D loss: 0.684281, acc: 0.554688]  [A loss: 0.723263, acc: 0.457031]\n",
      "1790: [D loss: 0.690858, acc: 0.544922]  [A loss: 1.035030, acc: 0.078125]\n",
      "1791: [D loss: 0.681686, acc: 0.568359]  [A loss: 0.763026, acc: 0.347656]\n",
      "1792: [D loss: 0.695327, acc: 0.533203]  [A loss: 1.041691, acc: 0.062500]\n",
      "1793: [D loss: 0.687391, acc: 0.546875]  [A loss: 0.737090, acc: 0.441406]\n",
      "1794: [D loss: 0.720624, acc: 0.509766]  [A loss: 0.992277, acc: 0.070312]\n",
      "1795: [D loss: 0.675864, acc: 0.568359]  [A loss: 0.742126, acc: 0.421875]\n",
      "1796: [D loss: 0.679987, acc: 0.537109]  [A loss: 0.922002, acc: 0.121094]\n",
      "1797: [D loss: 0.691827, acc: 0.539062]  [A loss: 0.809946, acc: 0.312500]\n",
      "1798: [D loss: 0.701252, acc: 0.515625]  [A loss: 0.901590, acc: 0.125000]\n",
      "1799: [D loss: 0.679369, acc: 0.595703]  [A loss: 0.773280, acc: 0.347656]\n",
      "1800: [D loss: 0.705727, acc: 0.533203]  [A loss: 0.968380, acc: 0.093750]\n",
      "1801: [D loss: 0.681934, acc: 0.574219]  [A loss: 0.704085, acc: 0.511719]\n",
      "1802: [D loss: 0.707059, acc: 0.554688]  [A loss: 1.023697, acc: 0.050781]\n",
      "1803: [D loss: 0.676336, acc: 0.582031]  [A loss: 0.743101, acc: 0.421875]\n",
      "1804: [D loss: 0.687891, acc: 0.566406]  [A loss: 0.957974, acc: 0.101562]\n",
      "1805: [D loss: 0.699605, acc: 0.527344]  [A loss: 0.749587, acc: 0.363281]\n",
      "1806: [D loss: 0.714374, acc: 0.529297]  [A loss: 1.056274, acc: 0.035156]\n",
      "1807: [D loss: 0.683048, acc: 0.550781]  [A loss: 0.712461, acc: 0.503906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808: [D loss: 0.705765, acc: 0.521484]  [A loss: 0.930737, acc: 0.105469]\n",
      "1809: [D loss: 0.697031, acc: 0.529297]  [A loss: 0.818554, acc: 0.250000]\n",
      "1810: [D loss: 0.687159, acc: 0.574219]  [A loss: 0.847895, acc: 0.195312]\n",
      "1811: [D loss: 0.704175, acc: 0.521484]  [A loss: 0.875081, acc: 0.156250]\n",
      "1812: [D loss: 0.689168, acc: 0.541016]  [A loss: 0.919028, acc: 0.128906]\n",
      "1813: [D loss: 0.691532, acc: 0.560547]  [A loss: 0.868244, acc: 0.175781]\n",
      "1814: [D loss: 0.693738, acc: 0.564453]  [A loss: 0.877573, acc: 0.156250]\n",
      "1815: [D loss: 0.693460, acc: 0.562500]  [A loss: 0.920541, acc: 0.121094]\n",
      "1816: [D loss: 0.692970, acc: 0.521484]  [A loss: 0.829523, acc: 0.265625]\n",
      "1817: [D loss: 0.696001, acc: 0.525391]  [A loss: 0.972263, acc: 0.066406]\n",
      "1818: [D loss: 0.695596, acc: 0.511719]  [A loss: 0.774452, acc: 0.339844]\n",
      "1819: [D loss: 0.691702, acc: 0.548828]  [A loss: 0.927086, acc: 0.125000]\n",
      "1820: [D loss: 0.699912, acc: 0.507812]  [A loss: 0.771623, acc: 0.332031]\n",
      "1821: [D loss: 0.700598, acc: 0.527344]  [A loss: 0.976680, acc: 0.078125]\n",
      "1822: [D loss: 0.681309, acc: 0.556641]  [A loss: 0.740163, acc: 0.410156]\n",
      "1823: [D loss: 0.697464, acc: 0.544922]  [A loss: 0.973600, acc: 0.066406]\n",
      "1824: [D loss: 0.692937, acc: 0.537109]  [A loss: 0.730120, acc: 0.468750]\n",
      "1825: [D loss: 0.698638, acc: 0.541016]  [A loss: 1.015211, acc: 0.050781]\n",
      "1826: [D loss: 0.684128, acc: 0.539062]  [A loss: 0.717203, acc: 0.480469]\n",
      "1827: [D loss: 0.707926, acc: 0.511719]  [A loss: 0.969942, acc: 0.097656]\n",
      "1828: [D loss: 0.691171, acc: 0.533203]  [A loss: 0.750825, acc: 0.394531]\n",
      "1829: [D loss: 0.700427, acc: 0.527344]  [A loss: 0.894524, acc: 0.148438]\n",
      "1830: [D loss: 0.678224, acc: 0.562500]  [A loss: 0.771238, acc: 0.355469]\n",
      "1831: [D loss: 0.696680, acc: 0.539062]  [A loss: 0.867499, acc: 0.164062]\n",
      "1832: [D loss: 0.675179, acc: 0.558594]  [A loss: 0.840693, acc: 0.187500]\n",
      "1833: [D loss: 0.693787, acc: 0.544922]  [A loss: 0.867538, acc: 0.160156]\n",
      "1834: [D loss: 0.692510, acc: 0.533203]  [A loss: 0.873668, acc: 0.183594]\n",
      "1835: [D loss: 0.685449, acc: 0.544922]  [A loss: 0.856426, acc: 0.160156]\n",
      "1836: [D loss: 0.689898, acc: 0.541016]  [A loss: 0.908728, acc: 0.140625]\n",
      "1837: [D loss: 0.688876, acc: 0.562500]  [A loss: 0.715863, acc: 0.484375]\n",
      "1838: [D loss: 0.705780, acc: 0.539062]  [A loss: 1.046775, acc: 0.019531]\n",
      "1839: [D loss: 0.691197, acc: 0.521484]  [A loss: 0.673356, acc: 0.632812]\n",
      "1840: [D loss: 0.710616, acc: 0.529297]  [A loss: 1.012693, acc: 0.058594]\n",
      "1841: [D loss: 0.691745, acc: 0.505859]  [A loss: 0.693900, acc: 0.523438]\n",
      "1842: [D loss: 0.691308, acc: 0.562500]  [A loss: 0.888136, acc: 0.140625]\n",
      "1843: [D loss: 0.674161, acc: 0.585938]  [A loss: 0.793786, acc: 0.308594]\n",
      "1844: [D loss: 0.693203, acc: 0.546875]  [A loss: 0.852017, acc: 0.195312]\n",
      "1845: [D loss: 0.678221, acc: 0.566406]  [A loss: 0.880173, acc: 0.179688]\n",
      "1846: [D loss: 0.699177, acc: 0.513672]  [A loss: 0.941602, acc: 0.085938]\n",
      "1847: [D loss: 0.682325, acc: 0.574219]  [A loss: 0.835640, acc: 0.234375]\n",
      "1848: [D loss: 0.674579, acc: 0.572266]  [A loss: 0.910970, acc: 0.125000]\n",
      "1849: [D loss: 0.693775, acc: 0.535156]  [A loss: 0.894439, acc: 0.136719]\n",
      "1850: [D loss: 0.693408, acc: 0.542969]  [A loss: 0.804776, acc: 0.210938]\n",
      "1851: [D loss: 0.690729, acc: 0.560547]  [A loss: 0.987878, acc: 0.062500]\n",
      "1852: [D loss: 0.680513, acc: 0.564453]  [A loss: 0.767212, acc: 0.335938]\n",
      "1853: [D loss: 0.687998, acc: 0.546875]  [A loss: 1.015573, acc: 0.042969]\n",
      "1854: [D loss: 0.681910, acc: 0.566406]  [A loss: 0.701961, acc: 0.484375]\n",
      "1855: [D loss: 0.713844, acc: 0.511719]  [A loss: 1.048555, acc: 0.023438]\n",
      "1856: [D loss: 0.677832, acc: 0.574219]  [A loss: 0.676742, acc: 0.589844]\n",
      "1857: [D loss: 0.697918, acc: 0.548828]  [A loss: 0.954526, acc: 0.105469]\n",
      "1858: [D loss: 0.695417, acc: 0.503906]  [A loss: 0.742097, acc: 0.398438]\n",
      "1859: [D loss: 0.686909, acc: 0.541016]  [A loss: 0.925858, acc: 0.105469]\n",
      "1860: [D loss: 0.682298, acc: 0.548828]  [A loss: 0.780067, acc: 0.316406]\n",
      "1861: [D loss: 0.684872, acc: 0.544922]  [A loss: 0.966683, acc: 0.105469]\n",
      "1862: [D loss: 0.677103, acc: 0.576172]  [A loss: 0.783206, acc: 0.332031]\n",
      "1863: [D loss: 0.688732, acc: 0.560547]  [A loss: 0.889449, acc: 0.144531]\n",
      "1864: [D loss: 0.701013, acc: 0.496094]  [A loss: 0.737171, acc: 0.398438]\n",
      "1865: [D loss: 0.711101, acc: 0.527344]  [A loss: 1.044138, acc: 0.042969]\n",
      "1866: [D loss: 0.674820, acc: 0.552734]  [A loss: 0.710906, acc: 0.500000]\n",
      "1867: [D loss: 0.704803, acc: 0.523438]  [A loss: 0.939870, acc: 0.101562]\n",
      "1868: [D loss: 0.663422, acc: 0.597656]  [A loss: 0.735514, acc: 0.410156]\n",
      "1869: [D loss: 0.693590, acc: 0.548828]  [A loss: 0.944721, acc: 0.109375]\n",
      "1870: [D loss: 0.697940, acc: 0.515625]  [A loss: 0.724696, acc: 0.429688]\n",
      "1871: [D loss: 0.702078, acc: 0.509766]  [A loss: 0.886057, acc: 0.164062]\n",
      "1872: [D loss: 0.662491, acc: 0.595703]  [A loss: 0.753228, acc: 0.363281]\n",
      "1873: [D loss: 0.675547, acc: 0.550781]  [A loss: 0.886297, acc: 0.156250]\n",
      "1874: [D loss: 0.685258, acc: 0.570312]  [A loss: 0.765762, acc: 0.347656]\n",
      "1875: [D loss: 0.694407, acc: 0.519531]  [A loss: 0.914136, acc: 0.152344]\n",
      "1876: [D loss: 0.692575, acc: 0.544922]  [A loss: 0.769606, acc: 0.332031]\n",
      "1877: [D loss: 0.704773, acc: 0.533203]  [A loss: 0.924022, acc: 0.085938]\n",
      "1878: [D loss: 0.671194, acc: 0.572266]  [A loss: 0.788672, acc: 0.316406]\n",
      "1879: [D loss: 0.701992, acc: 0.509766]  [A loss: 0.958005, acc: 0.105469]\n",
      "1880: [D loss: 0.692151, acc: 0.556641]  [A loss: 0.739856, acc: 0.414062]\n",
      "1881: [D loss: 0.712568, acc: 0.517578]  [A loss: 0.960827, acc: 0.082031]\n",
      "1882: [D loss: 0.678637, acc: 0.583984]  [A loss: 0.728419, acc: 0.429688]\n",
      "1883: [D loss: 0.692765, acc: 0.541016]  [A loss: 0.898495, acc: 0.144531]\n",
      "1884: [D loss: 0.687232, acc: 0.554688]  [A loss: 0.741858, acc: 0.382812]\n",
      "1885: [D loss: 0.692569, acc: 0.548828]  [A loss: 0.945667, acc: 0.109375]\n",
      "1886: [D loss: 0.678285, acc: 0.560547]  [A loss: 0.842547, acc: 0.214844]\n",
      "1887: [D loss: 0.692501, acc: 0.535156]  [A loss: 0.872546, acc: 0.167969]\n",
      "1888: [D loss: 0.693574, acc: 0.542969]  [A loss: 0.898985, acc: 0.136719]\n",
      "1889: [D loss: 0.681700, acc: 0.560547]  [A loss: 0.783753, acc: 0.308594]\n",
      "1890: [D loss: 0.694576, acc: 0.529297]  [A loss: 0.921671, acc: 0.140625]\n",
      "1891: [D loss: 0.675784, acc: 0.583984]  [A loss: 0.739900, acc: 0.437500]\n",
      "1892: [D loss: 0.701336, acc: 0.525391]  [A loss: 1.010636, acc: 0.042969]\n",
      "1893: [D loss: 0.680866, acc: 0.558594]  [A loss: 0.744805, acc: 0.402344]\n",
      "1894: [D loss: 0.685924, acc: 0.544922]  [A loss: 0.968103, acc: 0.132812]\n",
      "1895: [D loss: 0.669020, acc: 0.593750]  [A loss: 0.784773, acc: 0.269531]\n",
      "1896: [D loss: 0.691854, acc: 0.539062]  [A loss: 0.953126, acc: 0.105469]\n",
      "1897: [D loss: 0.679698, acc: 0.558594]  [A loss: 0.752734, acc: 0.402344]\n",
      "1898: [D loss: 0.713023, acc: 0.517578]  [A loss: 1.003155, acc: 0.070312]\n",
      "1899: [D loss: 0.688730, acc: 0.542969]  [A loss: 0.722576, acc: 0.464844]\n",
      "1900: [D loss: 0.706309, acc: 0.509766]  [A loss: 0.958025, acc: 0.089844]\n",
      "1901: [D loss: 0.686828, acc: 0.548828]  [A loss: 0.712654, acc: 0.468750]\n",
      "1902: [D loss: 0.706126, acc: 0.509766]  [A loss: 0.973465, acc: 0.105469]\n",
      "1903: [D loss: 0.686113, acc: 0.562500]  [A loss: 0.692080, acc: 0.542969]\n",
      "1904: [D loss: 0.702042, acc: 0.529297]  [A loss: 0.952669, acc: 0.066406]\n",
      "1905: [D loss: 0.687574, acc: 0.556641]  [A loss: 0.776603, acc: 0.308594]\n",
      "1906: [D loss: 0.694413, acc: 0.554688]  [A loss: 0.939311, acc: 0.105469]\n",
      "1907: [D loss: 0.687764, acc: 0.539062]  [A loss: 0.770448, acc: 0.300781]\n",
      "1908: [D loss: 0.691822, acc: 0.539062]  [A loss: 0.957284, acc: 0.101562]\n",
      "1909: [D loss: 0.680612, acc: 0.552734]  [A loss: 0.770848, acc: 0.332031]\n",
      "1910: [D loss: 0.689109, acc: 0.558594]  [A loss: 0.929392, acc: 0.109375]\n",
      "1911: [D loss: 0.665538, acc: 0.615234]  [A loss: 0.762988, acc: 0.375000]\n",
      "1912: [D loss: 0.703346, acc: 0.554688]  [A loss: 0.968044, acc: 0.101562]\n",
      "1913: [D loss: 0.687418, acc: 0.568359]  [A loss: 0.749526, acc: 0.402344]\n",
      "1914: [D loss: 0.686674, acc: 0.554688]  [A loss: 0.918145, acc: 0.140625]\n",
      "1915: [D loss: 0.684676, acc: 0.546875]  [A loss: 0.768319, acc: 0.324219]\n",
      "1916: [D loss: 0.707479, acc: 0.523438]  [A loss: 0.999786, acc: 0.050781]\n",
      "1917: [D loss: 0.679081, acc: 0.562500]  [A loss: 0.739751, acc: 0.410156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1918: [D loss: 0.707165, acc: 0.531250]  [A loss: 1.020478, acc: 0.050781]\n",
      "1919: [D loss: 0.672471, acc: 0.580078]  [A loss: 0.695572, acc: 0.488281]\n",
      "1920: [D loss: 0.701118, acc: 0.521484]  [A loss: 0.933004, acc: 0.117188]\n",
      "1921: [D loss: 0.702067, acc: 0.541016]  [A loss: 0.826234, acc: 0.250000]\n",
      "1922: [D loss: 0.697799, acc: 0.544922]  [A loss: 0.848624, acc: 0.207031]\n",
      "1923: [D loss: 0.687596, acc: 0.568359]  [A loss: 0.819180, acc: 0.277344]\n",
      "1924: [D loss: 0.700063, acc: 0.505859]  [A loss: 0.909476, acc: 0.164062]\n",
      "1925: [D loss: 0.695706, acc: 0.527344]  [A loss: 0.778376, acc: 0.300781]\n",
      "1926: [D loss: 0.709605, acc: 0.503906]  [A loss: 0.906017, acc: 0.125000]\n",
      "1927: [D loss: 0.693235, acc: 0.562500]  [A loss: 0.817283, acc: 0.242188]\n",
      "1928: [D loss: 0.698262, acc: 0.527344]  [A loss: 0.905864, acc: 0.136719]\n",
      "1929: [D loss: 0.691240, acc: 0.537109]  [A loss: 0.755821, acc: 0.363281]\n",
      "1930: [D loss: 0.695370, acc: 0.552734]  [A loss: 0.953593, acc: 0.085938]\n",
      "1931: [D loss: 0.681306, acc: 0.537109]  [A loss: 0.727190, acc: 0.414062]\n",
      "1932: [D loss: 0.698912, acc: 0.521484]  [A loss: 1.010614, acc: 0.042969]\n",
      "1933: [D loss: 0.682327, acc: 0.574219]  [A loss: 0.759116, acc: 0.378906]\n",
      "1934: [D loss: 0.686655, acc: 0.554688]  [A loss: 0.908255, acc: 0.144531]\n",
      "1935: [D loss: 0.674233, acc: 0.593750]  [A loss: 0.788991, acc: 0.320312]\n",
      "1936: [D loss: 0.696317, acc: 0.546875]  [A loss: 0.871672, acc: 0.140625]\n",
      "1937: [D loss: 0.689610, acc: 0.546875]  [A loss: 0.841801, acc: 0.214844]\n",
      "1938: [D loss: 0.694940, acc: 0.546875]  [A loss: 0.969702, acc: 0.140625]\n",
      "1939: [D loss: 0.699157, acc: 0.505859]  [A loss: 0.817786, acc: 0.269531]\n",
      "1940: [D loss: 0.703091, acc: 0.542969]  [A loss: 0.947811, acc: 0.117188]\n",
      "1941: [D loss: 0.677742, acc: 0.580078]  [A loss: 0.828426, acc: 0.261719]\n",
      "1942: [D loss: 0.688393, acc: 0.544922]  [A loss: 0.801498, acc: 0.289062]\n",
      "1943: [D loss: 0.678174, acc: 0.578125]  [A loss: 0.859949, acc: 0.191406]\n",
      "1944: [D loss: 0.681301, acc: 0.572266]  [A loss: 0.841611, acc: 0.214844]\n",
      "1945: [D loss: 0.700361, acc: 0.533203]  [A loss: 0.905387, acc: 0.097656]\n",
      "1946: [D loss: 0.691516, acc: 0.542969]  [A loss: 0.902447, acc: 0.136719]\n",
      "1947: [D loss: 0.686324, acc: 0.539062]  [A loss: 0.802739, acc: 0.292969]\n",
      "1948: [D loss: 0.671705, acc: 0.599609]  [A loss: 0.866920, acc: 0.191406]\n",
      "1949: [D loss: 0.690854, acc: 0.529297]  [A loss: 0.855252, acc: 0.230469]\n",
      "1950: [D loss: 0.687173, acc: 0.556641]  [A loss: 0.886755, acc: 0.164062]\n",
      "1951: [D loss: 0.701255, acc: 0.527344]  [A loss: 0.958167, acc: 0.113281]\n",
      "1952: [D loss: 0.675500, acc: 0.576172]  [A loss: 0.762792, acc: 0.328125]\n",
      "1953: [D loss: 0.708054, acc: 0.541016]  [A loss: 1.142158, acc: 0.027344]\n",
      "1954: [D loss: 0.700548, acc: 0.515625]  [A loss: 0.607839, acc: 0.703125]\n",
      "1955: [D loss: 0.726034, acc: 0.505859]  [A loss: 1.059865, acc: 0.015625]\n",
      "1956: [D loss: 0.678213, acc: 0.558594]  [A loss: 0.682844, acc: 0.558594]\n",
      "1957: [D loss: 0.707592, acc: 0.525391]  [A loss: 0.902369, acc: 0.175781]\n",
      "1958: [D loss: 0.703752, acc: 0.503906]  [A loss: 0.780856, acc: 0.355469]\n",
      "1959: [D loss: 0.705951, acc: 0.525391]  [A loss: 0.892959, acc: 0.144531]\n",
      "1960: [D loss: 0.682450, acc: 0.568359]  [A loss: 0.809633, acc: 0.277344]\n",
      "1961: [D loss: 0.700671, acc: 0.509766]  [A loss: 0.876064, acc: 0.164062]\n",
      "1962: [D loss: 0.687212, acc: 0.544922]  [A loss: 0.784811, acc: 0.281250]\n",
      "1963: [D loss: 0.698890, acc: 0.517578]  [A loss: 0.883195, acc: 0.171875]\n",
      "1964: [D loss: 0.679295, acc: 0.568359]  [A loss: 0.814238, acc: 0.296875]\n",
      "1965: [D loss: 0.704345, acc: 0.525391]  [A loss: 0.839305, acc: 0.199219]\n",
      "1966: [D loss: 0.693966, acc: 0.554688]  [A loss: 0.877908, acc: 0.183594]\n",
      "1967: [D loss: 0.686112, acc: 0.542969]  [A loss: 0.831073, acc: 0.218750]\n",
      "1968: [D loss: 0.698208, acc: 0.525391]  [A loss: 0.860984, acc: 0.226562]\n",
      "1969: [D loss: 0.685168, acc: 0.552734]  [A loss: 0.798931, acc: 0.285156]\n",
      "1970: [D loss: 0.687005, acc: 0.560547]  [A loss: 0.903312, acc: 0.128906]\n",
      "1971: [D loss: 0.684551, acc: 0.550781]  [A loss: 0.819351, acc: 0.257812]\n",
      "1972: [D loss: 0.690943, acc: 0.564453]  [A loss: 0.943512, acc: 0.113281]\n",
      "1973: [D loss: 0.687637, acc: 0.554688]  [A loss: 0.800152, acc: 0.281250]\n",
      "1974: [D loss: 0.704168, acc: 0.531250]  [A loss: 1.041622, acc: 0.062500]\n",
      "1975: [D loss: 0.684109, acc: 0.539062]  [A loss: 0.672695, acc: 0.562500]\n",
      "1976: [D loss: 0.699586, acc: 0.548828]  [A loss: 1.048902, acc: 0.074219]\n",
      "1977: [D loss: 0.688054, acc: 0.548828]  [A loss: 0.687397, acc: 0.558594]\n",
      "1978: [D loss: 0.702776, acc: 0.501953]  [A loss: 1.000903, acc: 0.062500]\n",
      "1979: [D loss: 0.682110, acc: 0.568359]  [A loss: 0.713266, acc: 0.472656]\n",
      "1980: [D loss: 0.695217, acc: 0.548828]  [A loss: 0.894514, acc: 0.152344]\n",
      "1981: [D loss: 0.687338, acc: 0.548828]  [A loss: 0.824365, acc: 0.226562]\n",
      "1982: [D loss: 0.690215, acc: 0.531250]  [A loss: 0.878881, acc: 0.160156]\n",
      "1983: [D loss: 0.679714, acc: 0.558594]  [A loss: 0.798602, acc: 0.250000]\n",
      "1984: [D loss: 0.698172, acc: 0.509766]  [A loss: 0.924435, acc: 0.113281]\n",
      "1985: [D loss: 0.689075, acc: 0.537109]  [A loss: 0.751726, acc: 0.382812]\n",
      "1986: [D loss: 0.702410, acc: 0.509766]  [A loss: 0.963519, acc: 0.089844]\n",
      "1987: [D loss: 0.697531, acc: 0.505859]  [A loss: 0.730922, acc: 0.433594]\n",
      "1988: [D loss: 0.705356, acc: 0.519531]  [A loss: 0.963130, acc: 0.101562]\n",
      "1989: [D loss: 0.679375, acc: 0.578125]  [A loss: 0.715656, acc: 0.464844]\n",
      "1990: [D loss: 0.705294, acc: 0.521484]  [A loss: 0.927897, acc: 0.171875]\n",
      "1991: [D loss: 0.701609, acc: 0.533203]  [A loss: 0.759227, acc: 0.398438]\n",
      "1992: [D loss: 0.699544, acc: 0.529297]  [A loss: 0.903639, acc: 0.140625]\n",
      "1993: [D loss: 0.691571, acc: 0.546875]  [A loss: 0.741559, acc: 0.429688]\n",
      "1994: [D loss: 0.720659, acc: 0.500000]  [A loss: 0.944975, acc: 0.113281]\n",
      "1995: [D loss: 0.702643, acc: 0.523438]  [A loss: 0.741061, acc: 0.386719]\n",
      "1996: [D loss: 0.710878, acc: 0.515625]  [A loss: 0.850448, acc: 0.199219]\n",
      "1997: [D loss: 0.687002, acc: 0.552734]  [A loss: 0.832196, acc: 0.222656]\n",
      "1998: [D loss: 0.692560, acc: 0.544922]  [A loss: 0.827672, acc: 0.226562]\n",
      "1999: [D loss: 0.690838, acc: 0.533203]  [A loss: 0.863481, acc: 0.167969]\n",
      "2000: [D loss: 0.701824, acc: 0.537109]  [A loss: 0.844324, acc: 0.187500]\n",
      "2001: [D loss: 0.694895, acc: 0.533203]  [A loss: 0.863577, acc: 0.160156]\n",
      "2002: [D loss: 0.694461, acc: 0.550781]  [A loss: 0.842600, acc: 0.226562]\n",
      "2003: [D loss: 0.694486, acc: 0.531250]  [A loss: 0.847966, acc: 0.207031]\n",
      "2004: [D loss: 0.702818, acc: 0.484375]  [A loss: 0.906477, acc: 0.144531]\n",
      "2005: [D loss: 0.693785, acc: 0.529297]  [A loss: 0.794145, acc: 0.257812]\n",
      "2006: [D loss: 0.699247, acc: 0.511719]  [A loss: 0.888505, acc: 0.140625]\n",
      "2007: [D loss: 0.676380, acc: 0.587891]  [A loss: 0.775934, acc: 0.308594]\n",
      "2008: [D loss: 0.694230, acc: 0.558594]  [A loss: 0.906916, acc: 0.164062]\n",
      "2009: [D loss: 0.686281, acc: 0.542969]  [A loss: 0.787317, acc: 0.277344]\n",
      "2010: [D loss: 0.696628, acc: 0.537109]  [A loss: 0.939662, acc: 0.121094]\n",
      "2011: [D loss: 0.687361, acc: 0.564453]  [A loss: 0.731049, acc: 0.480469]\n",
      "2012: [D loss: 0.702971, acc: 0.531250]  [A loss: 0.979503, acc: 0.078125]\n",
      "2013: [D loss: 0.692523, acc: 0.501953]  [A loss: 0.741422, acc: 0.375000]\n",
      "2014: [D loss: 0.691115, acc: 0.537109]  [A loss: 0.973675, acc: 0.070312]\n",
      "2015: [D loss: 0.685104, acc: 0.562500]  [A loss: 0.735226, acc: 0.390625]\n",
      "2016: [D loss: 0.700479, acc: 0.533203]  [A loss: 0.967648, acc: 0.089844]\n",
      "2017: [D loss: 0.679617, acc: 0.570312]  [A loss: 0.730695, acc: 0.464844]\n",
      "2018: [D loss: 0.702671, acc: 0.562500]  [A loss: 0.937186, acc: 0.136719]\n",
      "2019: [D loss: 0.690976, acc: 0.537109]  [A loss: 0.767529, acc: 0.351562]\n",
      "2020: [D loss: 0.705091, acc: 0.554688]  [A loss: 0.875192, acc: 0.152344]\n",
      "2021: [D loss: 0.686005, acc: 0.572266]  [A loss: 0.781609, acc: 0.296875]\n",
      "2022: [D loss: 0.698474, acc: 0.539062]  [A loss: 0.919681, acc: 0.082031]\n",
      "2023: [D loss: 0.694232, acc: 0.529297]  [A loss: 0.802701, acc: 0.308594]\n",
      "2024: [D loss: 0.677338, acc: 0.564453]  [A loss: 0.945335, acc: 0.093750]\n",
      "2025: [D loss: 0.669496, acc: 0.593750]  [A loss: 0.771753, acc: 0.332031]\n",
      "2026: [D loss: 0.708098, acc: 0.482422]  [A loss: 0.884965, acc: 0.160156]\n",
      "2027: [D loss: 0.683179, acc: 0.572266]  [A loss: 0.817053, acc: 0.273438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2028: [D loss: 0.691906, acc: 0.533203]  [A loss: 0.876613, acc: 0.183594]\n",
      "2029: [D loss: 0.678469, acc: 0.562500]  [A loss: 0.843213, acc: 0.218750]\n",
      "2030: [D loss: 0.695842, acc: 0.529297]  [A loss: 0.900970, acc: 0.144531]\n",
      "2031: [D loss: 0.687124, acc: 0.539062]  [A loss: 0.765722, acc: 0.363281]\n",
      "2032: [D loss: 0.698730, acc: 0.515625]  [A loss: 1.004640, acc: 0.050781]\n",
      "2033: [D loss: 0.681480, acc: 0.562500]  [A loss: 0.645584, acc: 0.625000]\n",
      "2034: [D loss: 0.726333, acc: 0.503906]  [A loss: 0.997113, acc: 0.058594]\n",
      "2035: [D loss: 0.696414, acc: 0.542969]  [A loss: 0.740203, acc: 0.382812]\n",
      "2036: [D loss: 0.685220, acc: 0.550781]  [A loss: 0.907017, acc: 0.113281]\n",
      "2037: [D loss: 0.678470, acc: 0.578125]  [A loss: 0.748971, acc: 0.398438]\n",
      "2038: [D loss: 0.700214, acc: 0.529297]  [A loss: 0.962500, acc: 0.050781]\n",
      "2039: [D loss: 0.689490, acc: 0.517578]  [A loss: 0.726728, acc: 0.457031]\n",
      "2040: [D loss: 0.703628, acc: 0.505859]  [A loss: 0.906457, acc: 0.105469]\n",
      "2041: [D loss: 0.679146, acc: 0.570312]  [A loss: 0.739243, acc: 0.386719]\n",
      "2042: [D loss: 0.700632, acc: 0.521484]  [A loss: 0.932337, acc: 0.085938]\n",
      "2043: [D loss: 0.682508, acc: 0.560547]  [A loss: 0.741848, acc: 0.406250]\n",
      "2044: [D loss: 0.702868, acc: 0.535156]  [A loss: 0.831268, acc: 0.250000]\n",
      "2045: [D loss: 0.708949, acc: 0.484375]  [A loss: 0.888544, acc: 0.140625]\n",
      "2046: [D loss: 0.683722, acc: 0.556641]  [A loss: 0.816062, acc: 0.242188]\n",
      "2047: [D loss: 0.698634, acc: 0.537109]  [A loss: 0.871997, acc: 0.203125]\n",
      "2048: [D loss: 0.690924, acc: 0.562500]  [A loss: 0.866511, acc: 0.167969]\n",
      "2049: [D loss: 0.684962, acc: 0.544922]  [A loss: 0.796524, acc: 0.300781]\n",
      "2050: [D loss: 0.706489, acc: 0.521484]  [A loss: 0.919734, acc: 0.144531]\n",
      "2051: [D loss: 0.687589, acc: 0.544922]  [A loss: 0.804862, acc: 0.265625]\n",
      "2052: [D loss: 0.694973, acc: 0.537109]  [A loss: 0.948636, acc: 0.074219]\n",
      "2053: [D loss: 0.685953, acc: 0.541016]  [A loss: 0.746867, acc: 0.375000]\n",
      "2054: [D loss: 0.707330, acc: 0.537109]  [A loss: 0.958948, acc: 0.066406]\n",
      "2055: [D loss: 0.687791, acc: 0.521484]  [A loss: 0.760203, acc: 0.402344]\n",
      "2056: [D loss: 0.689868, acc: 0.556641]  [A loss: 0.941806, acc: 0.125000]\n",
      "2057: [D loss: 0.680777, acc: 0.568359]  [A loss: 0.761756, acc: 0.371094]\n",
      "2058: [D loss: 0.700660, acc: 0.519531]  [A loss: 1.008153, acc: 0.054688]\n",
      "2059: [D loss: 0.693862, acc: 0.507812]  [A loss: 0.710942, acc: 0.464844]\n",
      "2060: [D loss: 0.709518, acc: 0.527344]  [A loss: 0.959338, acc: 0.062500]\n",
      "2061: [D loss: 0.685062, acc: 0.544922]  [A loss: 0.737649, acc: 0.382812]\n",
      "2062: [D loss: 0.706309, acc: 0.535156]  [A loss: 0.936661, acc: 0.085938]\n",
      "2063: [D loss: 0.680334, acc: 0.578125]  [A loss: 0.790554, acc: 0.296875]\n",
      "2064: [D loss: 0.694140, acc: 0.539062]  [A loss: 0.916236, acc: 0.109375]\n",
      "2065: [D loss: 0.684843, acc: 0.546875]  [A loss: 0.801787, acc: 0.281250]\n",
      "2066: [D loss: 0.695922, acc: 0.507812]  [A loss: 0.926428, acc: 0.121094]\n",
      "2067: [D loss: 0.695661, acc: 0.564453]  [A loss: 0.794751, acc: 0.343750]\n",
      "2068: [D loss: 0.688787, acc: 0.537109]  [A loss: 0.889819, acc: 0.117188]\n",
      "2069: [D loss: 0.692256, acc: 0.525391]  [A loss: 0.818899, acc: 0.265625]\n",
      "2070: [D loss: 0.665921, acc: 0.601562]  [A loss: 0.891066, acc: 0.125000]\n",
      "2071: [D loss: 0.681105, acc: 0.544922]  [A loss: 0.838605, acc: 0.230469]\n",
      "2072: [D loss: 0.671757, acc: 0.580078]  [A loss: 0.882267, acc: 0.183594]\n",
      "2073: [D loss: 0.684540, acc: 0.529297]  [A loss: 0.821403, acc: 0.296875]\n",
      "2074: [D loss: 0.684908, acc: 0.546875]  [A loss: 0.864486, acc: 0.199219]\n",
      "2075: [D loss: 0.706007, acc: 0.527344]  [A loss: 0.912294, acc: 0.148438]\n",
      "2076: [D loss: 0.691117, acc: 0.576172]  [A loss: 0.766238, acc: 0.382812]\n",
      "2077: [D loss: 0.689414, acc: 0.541016]  [A loss: 0.966231, acc: 0.117188]\n",
      "2078: [D loss: 0.696537, acc: 0.519531]  [A loss: 0.795647, acc: 0.292969]\n",
      "2079: [D loss: 0.695722, acc: 0.533203]  [A loss: 0.949075, acc: 0.109375]\n",
      "2080: [D loss: 0.684696, acc: 0.537109]  [A loss: 0.768922, acc: 0.367188]\n",
      "2081: [D loss: 0.705560, acc: 0.537109]  [A loss: 1.018124, acc: 0.070312]\n",
      "2082: [D loss: 0.688690, acc: 0.531250]  [A loss: 0.638456, acc: 0.632812]\n",
      "2083: [D loss: 0.712916, acc: 0.527344]  [A loss: 0.997281, acc: 0.062500]\n",
      "2084: [D loss: 0.690590, acc: 0.533203]  [A loss: 0.783455, acc: 0.304688]\n",
      "2085: [D loss: 0.697673, acc: 0.523438]  [A loss: 0.942622, acc: 0.128906]\n",
      "2086: [D loss: 0.677245, acc: 0.564453]  [A loss: 0.777950, acc: 0.328125]\n",
      "2087: [D loss: 0.705117, acc: 0.541016]  [A loss: 0.921600, acc: 0.128906]\n",
      "2088: [D loss: 0.687567, acc: 0.564453]  [A loss: 0.877194, acc: 0.160156]\n",
      "2089: [D loss: 0.700860, acc: 0.527344]  [A loss: 0.864650, acc: 0.171875]\n",
      "2090: [D loss: 0.689703, acc: 0.533203]  [A loss: 0.898651, acc: 0.152344]\n",
      "2091: [D loss: 0.695651, acc: 0.550781]  [A loss: 0.917718, acc: 0.136719]\n",
      "2092: [D loss: 0.695096, acc: 0.542969]  [A loss: 0.811199, acc: 0.285156]\n",
      "2093: [D loss: 0.681086, acc: 0.566406]  [A loss: 0.900838, acc: 0.125000]\n",
      "2094: [D loss: 0.693153, acc: 0.513672]  [A loss: 0.815714, acc: 0.269531]\n",
      "2095: [D loss: 0.696460, acc: 0.533203]  [A loss: 0.876425, acc: 0.171875]\n",
      "2096: [D loss: 0.686885, acc: 0.537109]  [A loss: 0.826911, acc: 0.265625]\n",
      "2097: [D loss: 0.694997, acc: 0.548828]  [A loss: 0.951344, acc: 0.109375]\n",
      "2098: [D loss: 0.673796, acc: 0.564453]  [A loss: 0.746786, acc: 0.425781]\n",
      "2099: [D loss: 0.694716, acc: 0.546875]  [A loss: 1.071693, acc: 0.066406]\n",
      "2100: [D loss: 0.701428, acc: 0.517578]  [A loss: 0.632047, acc: 0.644531]\n",
      "2101: [D loss: 0.723438, acc: 0.519531]  [A loss: 1.037039, acc: 0.058594]\n",
      "2102: [D loss: 0.690633, acc: 0.535156]  [A loss: 0.679207, acc: 0.546875]\n",
      "2103: [D loss: 0.696895, acc: 0.531250]  [A loss: 0.868763, acc: 0.199219]\n",
      "2104: [D loss: 0.676512, acc: 0.566406]  [A loss: 0.794614, acc: 0.296875]\n",
      "2105: [D loss: 0.678471, acc: 0.578125]  [A loss: 0.841090, acc: 0.238281]\n",
      "2106: [D loss: 0.683150, acc: 0.550781]  [A loss: 0.794767, acc: 0.332031]\n",
      "2107: [D loss: 0.695884, acc: 0.552734]  [A loss: 0.904323, acc: 0.167969]\n",
      "2108: [D loss: 0.700241, acc: 0.533203]  [A loss: 0.828611, acc: 0.230469]\n",
      "2109: [D loss: 0.684881, acc: 0.546875]  [A loss: 0.849093, acc: 0.199219]\n",
      "2110: [D loss: 0.693789, acc: 0.535156]  [A loss: 0.810118, acc: 0.253906]\n",
      "2111: [D loss: 0.677320, acc: 0.572266]  [A loss: 0.921979, acc: 0.140625]\n",
      "2112: [D loss: 0.684375, acc: 0.546875]  [A loss: 0.813695, acc: 0.246094]\n",
      "2113: [D loss: 0.681434, acc: 0.550781]  [A loss: 0.883265, acc: 0.187500]\n",
      "2114: [D loss: 0.696391, acc: 0.515625]  [A loss: 0.785829, acc: 0.289062]\n",
      "2115: [D loss: 0.699333, acc: 0.541016]  [A loss: 0.890363, acc: 0.207031]\n",
      "2116: [D loss: 0.697650, acc: 0.503906]  [A loss: 0.841823, acc: 0.222656]\n",
      "2117: [D loss: 0.695137, acc: 0.519531]  [A loss: 0.895180, acc: 0.152344]\n",
      "2118: [D loss: 0.687411, acc: 0.529297]  [A loss: 0.839744, acc: 0.242188]\n",
      "2119: [D loss: 0.681466, acc: 0.568359]  [A loss: 0.888818, acc: 0.144531]\n",
      "2120: [D loss: 0.702745, acc: 0.531250]  [A loss: 0.828613, acc: 0.261719]\n",
      "2121: [D loss: 0.698228, acc: 0.550781]  [A loss: 0.920353, acc: 0.125000]\n",
      "2122: [D loss: 0.698764, acc: 0.533203]  [A loss: 0.778972, acc: 0.339844]\n",
      "2123: [D loss: 0.710989, acc: 0.517578]  [A loss: 1.146376, acc: 0.027344]\n",
      "2124: [D loss: 0.685363, acc: 0.546875]  [A loss: 0.652833, acc: 0.613281]\n",
      "2125: [D loss: 0.721046, acc: 0.515625]  [A loss: 0.940148, acc: 0.117188]\n",
      "2126: [D loss: 0.678763, acc: 0.554688]  [A loss: 0.722817, acc: 0.464844]\n",
      "2127: [D loss: 0.726942, acc: 0.505859]  [A loss: 0.904858, acc: 0.128906]\n",
      "2128: [D loss: 0.688550, acc: 0.552734]  [A loss: 0.800583, acc: 0.257812]\n",
      "2129: [D loss: 0.700073, acc: 0.537109]  [A loss: 0.904631, acc: 0.132812]\n",
      "2130: [D loss: 0.689474, acc: 0.529297]  [A loss: 0.807426, acc: 0.261719]\n",
      "2131: [D loss: 0.686899, acc: 0.533203]  [A loss: 0.871536, acc: 0.167969]\n",
      "2132: [D loss: 0.686966, acc: 0.548828]  [A loss: 0.845271, acc: 0.195312]\n",
      "2133: [D loss: 0.686529, acc: 0.525391]  [A loss: 0.848465, acc: 0.238281]\n",
      "2134: [D loss: 0.683872, acc: 0.583984]  [A loss: 0.771544, acc: 0.351562]\n",
      "2135: [D loss: 0.692068, acc: 0.535156]  [A loss: 0.877430, acc: 0.152344]\n",
      "2136: [D loss: 0.699613, acc: 0.509766]  [A loss: 0.844636, acc: 0.210938]\n",
      "2137: [D loss: 0.689331, acc: 0.541016]  [A loss: 0.832585, acc: 0.218750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2138: [D loss: 0.690925, acc: 0.525391]  [A loss: 0.874725, acc: 0.167969]\n",
      "2139: [D loss: 0.685998, acc: 0.513672]  [A loss: 0.838020, acc: 0.226562]\n",
      "2140: [D loss: 0.703029, acc: 0.521484]  [A loss: 0.857243, acc: 0.203125]\n",
      "2141: [D loss: 0.683856, acc: 0.564453]  [A loss: 0.823270, acc: 0.230469]\n",
      "2142: [D loss: 0.682917, acc: 0.546875]  [A loss: 0.883940, acc: 0.167969]\n",
      "2143: [D loss: 0.682536, acc: 0.537109]  [A loss: 0.825872, acc: 0.238281]\n",
      "2144: [D loss: 0.694824, acc: 0.511719]  [A loss: 0.902110, acc: 0.164062]\n",
      "2145: [D loss: 0.689098, acc: 0.556641]  [A loss: 0.786318, acc: 0.308594]\n",
      "2146: [D loss: 0.698287, acc: 0.498047]  [A loss: 0.869110, acc: 0.195312]\n",
      "2147: [D loss: 0.683771, acc: 0.574219]  [A loss: 0.847667, acc: 0.238281]\n",
      "2148: [D loss: 0.719075, acc: 0.490234]  [A loss: 0.733478, acc: 0.460938]\n",
      "2149: [D loss: 0.725780, acc: 0.525391]  [A loss: 1.123266, acc: 0.039062]\n",
      "2150: [D loss: 0.693164, acc: 0.531250]  [A loss: 0.607671, acc: 0.710938]\n",
      "2151: [D loss: 0.743376, acc: 0.521484]  [A loss: 0.986363, acc: 0.078125]\n",
      "2152: [D loss: 0.686824, acc: 0.537109]  [A loss: 0.702693, acc: 0.468750]\n",
      "2153: [D loss: 0.712261, acc: 0.515625]  [A loss: 0.845097, acc: 0.171875]\n",
      "2154: [D loss: 0.684234, acc: 0.572266]  [A loss: 0.847345, acc: 0.187500]\n",
      "2155: [D loss: 0.682046, acc: 0.537109]  [A loss: 0.839656, acc: 0.238281]\n",
      "2156: [D loss: 0.683945, acc: 0.550781]  [A loss: 0.832429, acc: 0.234375]\n",
      "2157: [D loss: 0.682917, acc: 0.564453]  [A loss: 0.848987, acc: 0.214844]\n",
      "2158: [D loss: 0.680065, acc: 0.578125]  [A loss: 0.819895, acc: 0.226562]\n",
      "2159: [D loss: 0.705805, acc: 0.500000]  [A loss: 0.841862, acc: 0.203125]\n",
      "2160: [D loss: 0.696878, acc: 0.544922]  [A loss: 0.801433, acc: 0.312500]\n",
      "2161: [D loss: 0.690709, acc: 0.562500]  [A loss: 0.857913, acc: 0.167969]\n",
      "2162: [D loss: 0.696901, acc: 0.523438]  [A loss: 0.770706, acc: 0.347656]\n",
      "2163: [D loss: 0.689761, acc: 0.552734]  [A loss: 0.936800, acc: 0.097656]\n",
      "2164: [D loss: 0.693792, acc: 0.527344]  [A loss: 0.694497, acc: 0.523438]\n",
      "2165: [D loss: 0.717506, acc: 0.507812]  [A loss: 1.030068, acc: 0.042969]\n",
      "2166: [D loss: 0.681809, acc: 0.552734]  [A loss: 0.674036, acc: 0.566406]\n",
      "2167: [D loss: 0.719494, acc: 0.492188]  [A loss: 0.945738, acc: 0.082031]\n",
      "2168: [D loss: 0.691866, acc: 0.523438]  [A loss: 0.713210, acc: 0.449219]\n",
      "2169: [D loss: 0.700413, acc: 0.513672]  [A loss: 0.858405, acc: 0.210938]\n",
      "2170: [D loss: 0.707576, acc: 0.511719]  [A loss: 0.775703, acc: 0.339844]\n",
      "2171: [D loss: 0.696715, acc: 0.529297]  [A loss: 0.815697, acc: 0.273438]\n",
      "2172: [D loss: 0.692478, acc: 0.550781]  [A loss: 0.789053, acc: 0.289062]\n",
      "2173: [D loss: 0.690076, acc: 0.533203]  [A loss: 0.782147, acc: 0.257812]\n",
      "2174: [D loss: 0.697680, acc: 0.527344]  [A loss: 0.841116, acc: 0.238281]\n",
      "2175: [D loss: 0.696183, acc: 0.554688]  [A loss: 0.881305, acc: 0.179688]\n",
      "2176: [D loss: 0.683691, acc: 0.560547]  [A loss: 0.738845, acc: 0.417969]\n",
      "2177: [D loss: 0.698699, acc: 0.535156]  [A loss: 0.969345, acc: 0.070312]\n",
      "2178: [D loss: 0.700051, acc: 0.521484]  [A loss: 0.720214, acc: 0.437500]\n",
      "2179: [D loss: 0.704389, acc: 0.511719]  [A loss: 0.929806, acc: 0.097656]\n",
      "2180: [D loss: 0.684059, acc: 0.542969]  [A loss: 0.823660, acc: 0.238281]\n",
      "2181: [D loss: 0.692722, acc: 0.541016]  [A loss: 0.886586, acc: 0.132812]\n",
      "2182: [D loss: 0.702690, acc: 0.525391]  [A loss: 0.860016, acc: 0.164062]\n",
      "2183: [D loss: 0.699793, acc: 0.505859]  [A loss: 0.868677, acc: 0.164062]\n",
      "2184: [D loss: 0.697165, acc: 0.513672]  [A loss: 0.802931, acc: 0.257812]\n",
      "2185: [D loss: 0.697512, acc: 0.546875]  [A loss: 0.896943, acc: 0.160156]\n",
      "2186: [D loss: 0.688830, acc: 0.531250]  [A loss: 0.853216, acc: 0.203125]\n",
      "2187: [D loss: 0.691071, acc: 0.535156]  [A loss: 0.823547, acc: 0.253906]\n",
      "2188: [D loss: 0.681693, acc: 0.533203]  [A loss: 0.846423, acc: 0.238281]\n",
      "2189: [D loss: 0.687390, acc: 0.533203]  [A loss: 0.794666, acc: 0.312500]\n",
      "2190: [D loss: 0.678932, acc: 0.587891]  [A loss: 0.903232, acc: 0.128906]\n",
      "2191: [D loss: 0.701256, acc: 0.494141]  [A loss: 0.733090, acc: 0.445312]\n",
      "2192: [D loss: 0.714879, acc: 0.501953]  [A loss: 1.105041, acc: 0.011719]\n",
      "2193: [D loss: 0.699442, acc: 0.507812]  [A loss: 0.659690, acc: 0.625000]\n",
      "2194: [D loss: 0.721138, acc: 0.505859]  [A loss: 0.906714, acc: 0.136719]\n",
      "2195: [D loss: 0.688362, acc: 0.537109]  [A loss: 0.741890, acc: 0.406250]\n",
      "2196: [D loss: 0.688559, acc: 0.554688]  [A loss: 0.884591, acc: 0.187500]\n",
      "2197: [D loss: 0.681181, acc: 0.568359]  [A loss: 0.762288, acc: 0.320312]\n",
      "2198: [D loss: 0.695810, acc: 0.531250]  [A loss: 0.932253, acc: 0.101562]\n",
      "2199: [D loss: 0.673441, acc: 0.583984]  [A loss: 0.718235, acc: 0.445312]\n",
      "2200: [D loss: 0.696215, acc: 0.535156]  [A loss: 0.928997, acc: 0.101562]\n",
      "2201: [D loss: 0.684883, acc: 0.552734]  [A loss: 0.737215, acc: 0.433594]\n",
      "2202: [D loss: 0.699198, acc: 0.531250]  [A loss: 0.876608, acc: 0.152344]\n",
      "2203: [D loss: 0.689783, acc: 0.525391]  [A loss: 0.808338, acc: 0.242188]\n",
      "2204: [D loss: 0.690616, acc: 0.531250]  [A loss: 0.857369, acc: 0.199219]\n",
      "2205: [D loss: 0.683874, acc: 0.572266]  [A loss: 0.758704, acc: 0.343750]\n",
      "2206: [D loss: 0.709707, acc: 0.496094]  [A loss: 0.926556, acc: 0.117188]\n",
      "2207: [D loss: 0.685468, acc: 0.550781]  [A loss: 0.757226, acc: 0.375000]\n",
      "2208: [D loss: 0.707238, acc: 0.525391]  [A loss: 0.941290, acc: 0.113281]\n",
      "2209: [D loss: 0.704546, acc: 0.507812]  [A loss: 0.700323, acc: 0.480469]\n",
      "2210: [D loss: 0.696231, acc: 0.556641]  [A loss: 0.904574, acc: 0.132812]\n",
      "2211: [D loss: 0.689317, acc: 0.535156]  [A loss: 0.791330, acc: 0.304688]\n",
      "2212: [D loss: 0.691605, acc: 0.541016]  [A loss: 0.843092, acc: 0.214844]\n",
      "2213: [D loss: 0.700824, acc: 0.505859]  [A loss: 0.824442, acc: 0.230469]\n",
      "2214: [D loss: 0.684199, acc: 0.572266]  [A loss: 0.877921, acc: 0.183594]\n",
      "2215: [D loss: 0.687691, acc: 0.537109]  [A loss: 0.738048, acc: 0.417969]\n",
      "2216: [D loss: 0.701560, acc: 0.521484]  [A loss: 0.949795, acc: 0.082031]\n",
      "2217: [D loss: 0.689986, acc: 0.535156]  [A loss: 0.700566, acc: 0.503906]\n",
      "2218: [D loss: 0.698246, acc: 0.525391]  [A loss: 0.899482, acc: 0.160156]\n",
      "2219: [D loss: 0.686644, acc: 0.568359]  [A loss: 0.824003, acc: 0.242188]\n",
      "2220: [D loss: 0.690065, acc: 0.544922]  [A loss: 0.868953, acc: 0.167969]\n",
      "2221: [D loss: 0.681915, acc: 0.568359]  [A loss: 0.845700, acc: 0.183594]\n",
      "2222: [D loss: 0.691562, acc: 0.544922]  [A loss: 0.865884, acc: 0.136719]\n",
      "2223: [D loss: 0.695179, acc: 0.533203]  [A loss: 0.851151, acc: 0.207031]\n",
      "2224: [D loss: 0.681421, acc: 0.570312]  [A loss: 0.828903, acc: 0.226562]\n",
      "2225: [D loss: 0.687306, acc: 0.556641]  [A loss: 0.882493, acc: 0.191406]\n",
      "2226: [D loss: 0.688814, acc: 0.556641]  [A loss: 0.820529, acc: 0.257812]\n",
      "2227: [D loss: 0.698810, acc: 0.539062]  [A loss: 0.944518, acc: 0.113281]\n",
      "2228: [D loss: 0.689539, acc: 0.541016]  [A loss: 0.706096, acc: 0.492188]\n",
      "2229: [D loss: 0.711497, acc: 0.517578]  [A loss: 0.997737, acc: 0.066406]\n",
      "2230: [D loss: 0.691982, acc: 0.529297]  [A loss: 0.662901, acc: 0.621094]\n",
      "2231: [D loss: 0.716741, acc: 0.527344]  [A loss: 0.935095, acc: 0.117188]\n",
      "2232: [D loss: 0.672332, acc: 0.597656]  [A loss: 0.710582, acc: 0.488281]\n",
      "2233: [D loss: 0.701436, acc: 0.527344]  [A loss: 0.917724, acc: 0.101562]\n",
      "2234: [D loss: 0.691904, acc: 0.539062]  [A loss: 0.756635, acc: 0.367188]\n",
      "2235: [D loss: 0.692383, acc: 0.554688]  [A loss: 0.915897, acc: 0.117188]\n",
      "2236: [D loss: 0.696681, acc: 0.529297]  [A loss: 0.761129, acc: 0.343750]\n",
      "2237: [D loss: 0.698520, acc: 0.550781]  [A loss: 0.918293, acc: 0.113281]\n",
      "2238: [D loss: 0.692217, acc: 0.513672]  [A loss: 0.704721, acc: 0.496094]\n",
      "2239: [D loss: 0.703169, acc: 0.535156]  [A loss: 0.886595, acc: 0.136719]\n",
      "2240: [D loss: 0.688611, acc: 0.544922]  [A loss: 0.768826, acc: 0.324219]\n",
      "2241: [D loss: 0.702886, acc: 0.500000]  [A loss: 0.961251, acc: 0.105469]\n",
      "2242: [D loss: 0.671882, acc: 0.572266]  [A loss: 0.743997, acc: 0.378906]\n",
      "2243: [D loss: 0.696800, acc: 0.566406]  [A loss: 0.847186, acc: 0.226562]\n",
      "2244: [D loss: 0.686274, acc: 0.535156]  [A loss: 0.767952, acc: 0.328125]\n",
      "2245: [D loss: 0.705080, acc: 0.501953]  [A loss: 0.873078, acc: 0.175781]\n",
      "2246: [D loss: 0.688030, acc: 0.535156]  [A loss: 0.775214, acc: 0.316406]\n",
      "2247: [D loss: 0.686303, acc: 0.558594]  [A loss: 0.877533, acc: 0.152344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2248: [D loss: 0.678547, acc: 0.566406]  [A loss: 0.789556, acc: 0.285156]\n",
      "2249: [D loss: 0.686924, acc: 0.558594]  [A loss: 0.847196, acc: 0.214844]\n",
      "2250: [D loss: 0.693757, acc: 0.548828]  [A loss: 0.880429, acc: 0.156250]\n",
      "2251: [D loss: 0.690800, acc: 0.537109]  [A loss: 0.795148, acc: 0.281250]\n",
      "2252: [D loss: 0.698174, acc: 0.529297]  [A loss: 0.938546, acc: 0.109375]\n",
      "2253: [D loss: 0.681729, acc: 0.544922]  [A loss: 0.796153, acc: 0.269531]\n",
      "2254: [D loss: 0.691455, acc: 0.564453]  [A loss: 0.973816, acc: 0.078125]\n",
      "2255: [D loss: 0.688365, acc: 0.550781]  [A loss: 0.795601, acc: 0.316406]\n",
      "2256: [D loss: 0.695982, acc: 0.531250]  [A loss: 0.959577, acc: 0.097656]\n",
      "2257: [D loss: 0.695435, acc: 0.503906]  [A loss: 0.769464, acc: 0.335938]\n",
      "2258: [D loss: 0.710205, acc: 0.529297]  [A loss: 0.965951, acc: 0.097656]\n",
      "2259: [D loss: 0.682092, acc: 0.554688]  [A loss: 0.695056, acc: 0.523438]\n",
      "2260: [D loss: 0.702409, acc: 0.531250]  [A loss: 0.916963, acc: 0.132812]\n",
      "2261: [D loss: 0.692827, acc: 0.523438]  [A loss: 0.838287, acc: 0.207031]\n",
      "2262: [D loss: 0.681392, acc: 0.585938]  [A loss: 0.823485, acc: 0.242188]\n",
      "2263: [D loss: 0.687239, acc: 0.570312]  [A loss: 0.829699, acc: 0.250000]\n",
      "2264: [D loss: 0.695202, acc: 0.541016]  [A loss: 0.752121, acc: 0.414062]\n",
      "2265: [D loss: 0.718950, acc: 0.490234]  [A loss: 1.063329, acc: 0.058594]\n",
      "2266: [D loss: 0.683577, acc: 0.583984]  [A loss: 0.651280, acc: 0.621094]\n",
      "2267: [D loss: 0.716777, acc: 0.505859]  [A loss: 0.939196, acc: 0.128906]\n",
      "2268: [D loss: 0.682148, acc: 0.560547]  [A loss: 0.795599, acc: 0.308594]\n",
      "2269: [D loss: 0.690326, acc: 0.550781]  [A loss: 0.887600, acc: 0.152344]\n",
      "2270: [D loss: 0.682448, acc: 0.566406]  [A loss: 0.773428, acc: 0.324219]\n",
      "2271: [D loss: 0.697689, acc: 0.533203]  [A loss: 0.886696, acc: 0.156250]\n",
      "2272: [D loss: 0.687833, acc: 0.560547]  [A loss: 0.794526, acc: 0.324219]\n",
      "2273: [D loss: 0.704472, acc: 0.519531]  [A loss: 0.843036, acc: 0.253906]\n",
      "2274: [D loss: 0.707094, acc: 0.558594]  [A loss: 0.937225, acc: 0.089844]\n",
      "2275: [D loss: 0.689045, acc: 0.537109]  [A loss: 0.798918, acc: 0.273438]\n",
      "2276: [D loss: 0.708312, acc: 0.519531]  [A loss: 0.900528, acc: 0.140625]\n",
      "2277: [D loss: 0.673822, acc: 0.576172]  [A loss: 0.768902, acc: 0.363281]\n",
      "2278: [D loss: 0.691515, acc: 0.533203]  [A loss: 0.931042, acc: 0.132812]\n",
      "2279: [D loss: 0.690453, acc: 0.533203]  [A loss: 0.724910, acc: 0.417969]\n",
      "2280: [D loss: 0.690797, acc: 0.537109]  [A loss: 0.957696, acc: 0.070312]\n",
      "2281: [D loss: 0.680520, acc: 0.578125]  [A loss: 0.722087, acc: 0.460938]\n",
      "2282: [D loss: 0.710874, acc: 0.535156]  [A loss: 0.992662, acc: 0.078125]\n",
      "2283: [D loss: 0.693126, acc: 0.564453]  [A loss: 0.691041, acc: 0.500000]\n",
      "2284: [D loss: 0.703452, acc: 0.531250]  [A loss: 0.853490, acc: 0.210938]\n",
      "2285: [D loss: 0.693369, acc: 0.509766]  [A loss: 0.840138, acc: 0.187500]\n",
      "2286: [D loss: 0.699473, acc: 0.507812]  [A loss: 0.794395, acc: 0.296875]\n",
      "2287: [D loss: 0.694246, acc: 0.535156]  [A loss: 0.840648, acc: 0.207031]\n",
      "2288: [D loss: 0.696725, acc: 0.523438]  [A loss: 0.804480, acc: 0.285156]\n",
      "2289: [D loss: 0.684785, acc: 0.556641]  [A loss: 0.838270, acc: 0.210938]\n",
      "2290: [D loss: 0.689076, acc: 0.564453]  [A loss: 0.780298, acc: 0.320312]\n",
      "2291: [D loss: 0.686238, acc: 0.564453]  [A loss: 0.830905, acc: 0.269531]\n",
      "2292: [D loss: 0.691471, acc: 0.546875]  [A loss: 0.858371, acc: 0.183594]\n",
      "2293: [D loss: 0.690977, acc: 0.541016]  [A loss: 0.825383, acc: 0.222656]\n",
      "2294: [D loss: 0.685647, acc: 0.539062]  [A loss: 0.826705, acc: 0.250000]\n",
      "2295: [D loss: 0.692577, acc: 0.537109]  [A loss: 0.911002, acc: 0.109375]\n",
      "2296: [D loss: 0.686925, acc: 0.554688]  [A loss: 0.789331, acc: 0.308594]\n",
      "2297: [D loss: 0.702187, acc: 0.541016]  [A loss: 0.965275, acc: 0.085938]\n",
      "2298: [D loss: 0.692827, acc: 0.529297]  [A loss: 0.681544, acc: 0.574219]\n",
      "2299: [D loss: 0.722025, acc: 0.509766]  [A loss: 0.991905, acc: 0.070312]\n",
      "2300: [D loss: 0.706880, acc: 0.517578]  [A loss: 0.693843, acc: 0.511719]\n",
      "2301: [D loss: 0.710008, acc: 0.527344]  [A loss: 0.936197, acc: 0.140625]\n",
      "2302: [D loss: 0.675409, acc: 0.574219]  [A loss: 0.726675, acc: 0.429688]\n",
      "2303: [D loss: 0.722607, acc: 0.511719]  [A loss: 0.911406, acc: 0.117188]\n",
      "2304: [D loss: 0.680855, acc: 0.568359]  [A loss: 0.791916, acc: 0.277344]\n",
      "2305: [D loss: 0.697708, acc: 0.556641]  [A loss: 0.896616, acc: 0.125000]\n",
      "2306: [D loss: 0.676991, acc: 0.572266]  [A loss: 0.722180, acc: 0.441406]\n",
      "2307: [D loss: 0.698865, acc: 0.529297]  [A loss: 0.926617, acc: 0.136719]\n",
      "2308: [D loss: 0.699230, acc: 0.509766]  [A loss: 0.780734, acc: 0.332031]\n",
      "2309: [D loss: 0.714065, acc: 0.505859]  [A loss: 0.884582, acc: 0.148438]\n",
      "2310: [D loss: 0.690833, acc: 0.529297]  [A loss: 0.921600, acc: 0.160156]\n",
      "2311: [D loss: 0.695236, acc: 0.523438]  [A loss: 0.790748, acc: 0.312500]\n",
      "2312: [D loss: 0.680907, acc: 0.560547]  [A loss: 0.878335, acc: 0.171875]\n",
      "2313: [D loss: 0.679995, acc: 0.599609]  [A loss: 0.799944, acc: 0.253906]\n",
      "2314: [D loss: 0.696013, acc: 0.556641]  [A loss: 0.973421, acc: 0.097656]\n",
      "2315: [D loss: 0.693122, acc: 0.550781]  [A loss: 0.665801, acc: 0.613281]\n",
      "2316: [D loss: 0.713671, acc: 0.527344]  [A loss: 0.996652, acc: 0.078125]\n",
      "2317: [D loss: 0.693000, acc: 0.537109]  [A loss: 0.750327, acc: 0.355469]\n",
      "2318: [D loss: 0.686791, acc: 0.566406]  [A loss: 0.885824, acc: 0.160156]\n",
      "2319: [D loss: 0.696957, acc: 0.548828]  [A loss: 0.730893, acc: 0.433594]\n",
      "2320: [D loss: 0.692506, acc: 0.529297]  [A loss: 0.942102, acc: 0.140625]\n",
      "2321: [D loss: 0.680584, acc: 0.562500]  [A loss: 0.795189, acc: 0.277344]\n",
      "2322: [D loss: 0.693800, acc: 0.539062]  [A loss: 0.832505, acc: 0.222656]\n",
      "2323: [D loss: 0.687795, acc: 0.568359]  [A loss: 0.873613, acc: 0.183594]\n",
      "2324: [D loss: 0.685065, acc: 0.542969]  [A loss: 0.827701, acc: 0.222656]\n",
      "2325: [D loss: 0.695474, acc: 0.529297]  [A loss: 0.892223, acc: 0.164062]\n",
      "2326: [D loss: 0.689542, acc: 0.533203]  [A loss: 0.797504, acc: 0.277344]\n",
      "2327: [D loss: 0.689962, acc: 0.562500]  [A loss: 0.888805, acc: 0.148438]\n",
      "2328: [D loss: 0.692332, acc: 0.523438]  [A loss: 0.759325, acc: 0.339844]\n",
      "2329: [D loss: 0.702419, acc: 0.529297]  [A loss: 0.914948, acc: 0.128906]\n",
      "2330: [D loss: 0.686424, acc: 0.560547]  [A loss: 0.739130, acc: 0.406250]\n",
      "2331: [D loss: 0.707069, acc: 0.521484]  [A loss: 0.975175, acc: 0.105469]\n",
      "2332: [D loss: 0.702776, acc: 0.517578]  [A loss: 0.757278, acc: 0.386719]\n",
      "2333: [D loss: 0.701911, acc: 0.533203]  [A loss: 1.009000, acc: 0.054688]\n",
      "2334: [D loss: 0.685987, acc: 0.541016]  [A loss: 0.689863, acc: 0.542969]\n",
      "2335: [D loss: 0.733008, acc: 0.496094]  [A loss: 0.933583, acc: 0.109375]\n",
      "2336: [D loss: 0.685527, acc: 0.566406]  [A loss: 0.758560, acc: 0.347656]\n",
      "2337: [D loss: 0.691784, acc: 0.546875]  [A loss: 0.810872, acc: 0.265625]\n",
      "2338: [D loss: 0.699153, acc: 0.531250]  [A loss: 0.838556, acc: 0.230469]\n",
      "2339: [D loss: 0.693835, acc: 0.554688]  [A loss: 0.813727, acc: 0.261719]\n",
      "2340: [D loss: 0.698544, acc: 0.531250]  [A loss: 0.898399, acc: 0.128906]\n",
      "2341: [D loss: 0.673216, acc: 0.580078]  [A loss: 0.759633, acc: 0.378906]\n",
      "2342: [D loss: 0.703129, acc: 0.498047]  [A loss: 0.970349, acc: 0.097656]\n",
      "2343: [D loss: 0.695936, acc: 0.527344]  [A loss: 0.694575, acc: 0.500000]\n",
      "2344: [D loss: 0.712977, acc: 0.519531]  [A loss: 0.963645, acc: 0.105469]\n",
      "2345: [D loss: 0.692126, acc: 0.529297]  [A loss: 0.693609, acc: 0.550781]\n",
      "2346: [D loss: 0.720101, acc: 0.511719]  [A loss: 0.920035, acc: 0.132812]\n",
      "2347: [D loss: 0.693000, acc: 0.519531]  [A loss: 0.800411, acc: 0.296875]\n",
      "2348: [D loss: 0.705797, acc: 0.539062]  [A loss: 0.866393, acc: 0.160156]\n",
      "2349: [D loss: 0.683040, acc: 0.550781]  [A loss: 0.805145, acc: 0.261719]\n",
      "2350: [D loss: 0.700741, acc: 0.531250]  [A loss: 0.891993, acc: 0.140625]\n",
      "2351: [D loss: 0.682636, acc: 0.552734]  [A loss: 0.772753, acc: 0.359375]\n",
      "2352: [D loss: 0.692733, acc: 0.531250]  [A loss: 0.858244, acc: 0.203125]\n",
      "2353: [D loss: 0.687844, acc: 0.537109]  [A loss: 0.787114, acc: 0.300781]\n",
      "2354: [D loss: 0.691679, acc: 0.546875]  [A loss: 0.859242, acc: 0.203125]\n",
      "2355: [D loss: 0.703106, acc: 0.511719]  [A loss: 0.853703, acc: 0.207031]\n",
      "2356: [D loss: 0.694263, acc: 0.511719]  [A loss: 0.877978, acc: 0.160156]\n",
      "2357: [D loss: 0.685776, acc: 0.578125]  [A loss: 0.839420, acc: 0.222656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2358: [D loss: 0.706157, acc: 0.529297]  [A loss: 0.847167, acc: 0.195312]\n",
      "2359: [D loss: 0.686595, acc: 0.548828]  [A loss: 0.806116, acc: 0.273438]\n",
      "2360: [D loss: 0.699052, acc: 0.539062]  [A loss: 0.997180, acc: 0.074219]\n",
      "2361: [D loss: 0.696348, acc: 0.521484]  [A loss: 0.737682, acc: 0.421875]\n",
      "2362: [D loss: 0.691997, acc: 0.554688]  [A loss: 0.920084, acc: 0.152344]\n",
      "2363: [D loss: 0.692509, acc: 0.535156]  [A loss: 0.765916, acc: 0.351562]\n",
      "2364: [D loss: 0.698022, acc: 0.558594]  [A loss: 0.944199, acc: 0.097656]\n",
      "2365: [D loss: 0.693609, acc: 0.529297]  [A loss: 0.749257, acc: 0.414062]\n",
      "2366: [D loss: 0.708315, acc: 0.525391]  [A loss: 0.897250, acc: 0.148438]\n",
      "2367: [D loss: 0.676781, acc: 0.587891]  [A loss: 0.748869, acc: 0.402344]\n",
      "2368: [D loss: 0.711706, acc: 0.511719]  [A loss: 0.957313, acc: 0.093750]\n",
      "2369: [D loss: 0.691935, acc: 0.564453]  [A loss: 0.796632, acc: 0.273438]\n",
      "2370: [D loss: 0.699696, acc: 0.513672]  [A loss: 0.937102, acc: 0.136719]\n",
      "2371: [D loss: 0.697680, acc: 0.525391]  [A loss: 0.758936, acc: 0.410156]\n",
      "2372: [D loss: 0.713166, acc: 0.519531]  [A loss: 0.903354, acc: 0.160156]\n",
      "2373: [D loss: 0.702414, acc: 0.517578]  [A loss: 0.771232, acc: 0.347656]\n",
      "2374: [D loss: 0.707004, acc: 0.513672]  [A loss: 1.011785, acc: 0.046875]\n",
      "2375: [D loss: 0.689437, acc: 0.533203]  [A loss: 0.695230, acc: 0.480469]\n",
      "2376: [D loss: 0.713808, acc: 0.515625]  [A loss: 0.923265, acc: 0.097656]\n",
      "2377: [D loss: 0.701321, acc: 0.505859]  [A loss: 0.707531, acc: 0.492188]\n",
      "2378: [D loss: 0.719121, acc: 0.525391]  [A loss: 0.934685, acc: 0.097656]\n",
      "2379: [D loss: 0.690431, acc: 0.529297]  [A loss: 0.714130, acc: 0.453125]\n",
      "2380: [D loss: 0.702090, acc: 0.531250]  [A loss: 0.883339, acc: 0.132812]\n",
      "2381: [D loss: 0.676321, acc: 0.564453]  [A loss: 0.693972, acc: 0.531250]\n",
      "2382: [D loss: 0.702385, acc: 0.533203]  [A loss: 0.943117, acc: 0.089844]\n",
      "2383: [D loss: 0.682298, acc: 0.556641]  [A loss: 0.699295, acc: 0.527344]\n",
      "2384: [D loss: 0.713881, acc: 0.527344]  [A loss: 0.904222, acc: 0.144531]\n",
      "2385: [D loss: 0.673567, acc: 0.580078]  [A loss: 0.742847, acc: 0.363281]\n",
      "2386: [D loss: 0.694228, acc: 0.560547]  [A loss: 0.861485, acc: 0.195312]\n",
      "2387: [D loss: 0.697861, acc: 0.535156]  [A loss: 0.807673, acc: 0.226562]\n",
      "2388: [D loss: 0.700270, acc: 0.523438]  [A loss: 0.874402, acc: 0.167969]\n",
      "2389: [D loss: 0.696695, acc: 0.521484]  [A loss: 0.769732, acc: 0.339844]\n",
      "2390: [D loss: 0.673932, acc: 0.595703]  [A loss: 0.864284, acc: 0.230469]\n",
      "2391: [D loss: 0.699920, acc: 0.521484]  [A loss: 0.785923, acc: 0.308594]\n",
      "2392: [D loss: 0.695007, acc: 0.556641]  [A loss: 0.983089, acc: 0.078125]\n",
      "2393: [D loss: 0.676761, acc: 0.568359]  [A loss: 0.736604, acc: 0.445312]\n",
      "2394: [D loss: 0.690773, acc: 0.537109]  [A loss: 0.910331, acc: 0.156250]\n",
      "2395: [D loss: 0.689333, acc: 0.554688]  [A loss: 0.743772, acc: 0.410156]\n",
      "2396: [D loss: 0.699872, acc: 0.533203]  [A loss: 0.979209, acc: 0.082031]\n",
      "2397: [D loss: 0.688846, acc: 0.523438]  [A loss: 0.710351, acc: 0.484375]\n",
      "2398: [D loss: 0.700223, acc: 0.521484]  [A loss: 0.905853, acc: 0.152344]\n",
      "2399: [D loss: 0.694926, acc: 0.521484]  [A loss: 0.753081, acc: 0.382812]\n",
      "2400: [D loss: 0.700641, acc: 0.525391]  [A loss: 0.932188, acc: 0.093750]\n",
      "2401: [D loss: 0.696019, acc: 0.568359]  [A loss: 0.744368, acc: 0.402344]\n",
      "2402: [D loss: 0.702101, acc: 0.529297]  [A loss: 0.956250, acc: 0.125000]\n",
      "2403: [D loss: 0.685984, acc: 0.554688]  [A loss: 0.715661, acc: 0.453125]\n",
      "2404: [D loss: 0.690732, acc: 0.552734]  [A loss: 0.931505, acc: 0.125000]\n",
      "2405: [D loss: 0.694121, acc: 0.541016]  [A loss: 0.738009, acc: 0.453125]\n",
      "2406: [D loss: 0.714380, acc: 0.525391]  [A loss: 0.971485, acc: 0.097656]\n",
      "2407: [D loss: 0.694751, acc: 0.521484]  [A loss: 0.717933, acc: 0.468750]\n",
      "2408: [D loss: 0.710680, acc: 0.521484]  [A loss: 0.912970, acc: 0.125000]\n",
      "2409: [D loss: 0.687829, acc: 0.531250]  [A loss: 0.748306, acc: 0.410156]\n",
      "2410: [D loss: 0.689229, acc: 0.550781]  [A loss: 0.905340, acc: 0.179688]\n",
      "2411: [D loss: 0.689128, acc: 0.523438]  [A loss: 0.789561, acc: 0.320312]\n",
      "2412: [D loss: 0.688197, acc: 0.550781]  [A loss: 0.920139, acc: 0.144531]\n",
      "2413: [D loss: 0.689183, acc: 0.537109]  [A loss: 0.720675, acc: 0.445312]\n",
      "2414: [D loss: 0.719017, acc: 0.511719]  [A loss: 0.998950, acc: 0.085938]\n",
      "2415: [D loss: 0.689873, acc: 0.556641]  [A loss: 0.712494, acc: 0.433594]\n",
      "2416: [D loss: 0.715738, acc: 0.517578]  [A loss: 0.946391, acc: 0.121094]\n",
      "2417: [D loss: 0.683932, acc: 0.574219]  [A loss: 0.666405, acc: 0.574219]\n",
      "2418: [D loss: 0.701750, acc: 0.550781]  [A loss: 0.923824, acc: 0.125000]\n",
      "2419: [D loss: 0.692098, acc: 0.523438]  [A loss: 0.782386, acc: 0.343750]\n",
      "2420: [D loss: 0.690511, acc: 0.527344]  [A loss: 0.811332, acc: 0.273438]\n",
      "2421: [D loss: 0.698701, acc: 0.525391]  [A loss: 0.839606, acc: 0.195312]\n",
      "2422: [D loss: 0.690293, acc: 0.560547]  [A loss: 0.820020, acc: 0.210938]\n",
      "2423: [D loss: 0.696310, acc: 0.523438]  [A loss: 0.813978, acc: 0.261719]\n",
      "2424: [D loss: 0.693036, acc: 0.541016]  [A loss: 0.873800, acc: 0.203125]\n",
      "2425: [D loss: 0.683334, acc: 0.539062]  [A loss: 0.835769, acc: 0.234375]\n",
      "2426: [D loss: 0.696575, acc: 0.533203]  [A loss: 0.892797, acc: 0.175781]\n",
      "2427: [D loss: 0.698205, acc: 0.525391]  [A loss: 0.784684, acc: 0.261719]\n",
      "2428: [D loss: 0.697775, acc: 0.542969]  [A loss: 0.985141, acc: 0.054688]\n",
      "2429: [D loss: 0.700749, acc: 0.513672]  [A loss: 0.701883, acc: 0.488281]\n",
      "2430: [D loss: 0.716642, acc: 0.529297]  [A loss: 0.968406, acc: 0.082031]\n",
      "2431: [D loss: 0.693149, acc: 0.560547]  [A loss: 0.743686, acc: 0.410156]\n",
      "2432: [D loss: 0.682879, acc: 0.546875]  [A loss: 0.885881, acc: 0.136719]\n",
      "2433: [D loss: 0.677787, acc: 0.591797]  [A loss: 0.813251, acc: 0.289062]\n",
      "2434: [D loss: 0.703972, acc: 0.519531]  [A loss: 0.865123, acc: 0.167969]\n",
      "2435: [D loss: 0.684824, acc: 0.556641]  [A loss: 0.749878, acc: 0.406250]\n",
      "2436: [D loss: 0.763097, acc: 0.478516]  [A loss: 0.858320, acc: 0.156250]\n",
      "2437: [D loss: 0.709895, acc: 0.513672]  [A loss: 1.019835, acc: 0.050781]\n",
      "2438: [D loss: 0.704263, acc: 0.507812]  [A loss: 0.721982, acc: 0.417969]\n",
      "2439: [D loss: 0.709207, acc: 0.503906]  [A loss: 0.962037, acc: 0.082031]\n",
      "2440: [D loss: 0.678167, acc: 0.572266]  [A loss: 0.701595, acc: 0.500000]\n",
      "2441: [D loss: 0.709574, acc: 0.492188]  [A loss: 0.939084, acc: 0.085938]\n",
      "2442: [D loss: 0.669191, acc: 0.607422]  [A loss: 0.731772, acc: 0.421875]\n",
      "2443: [D loss: 0.717095, acc: 0.529297]  [A loss: 0.962022, acc: 0.070312]\n",
      "2444: [D loss: 0.692203, acc: 0.523438]  [A loss: 0.732443, acc: 0.429688]\n",
      "2445: [D loss: 0.714524, acc: 0.519531]  [A loss: 0.929841, acc: 0.101562]\n",
      "2446: [D loss: 0.696502, acc: 0.527344]  [A loss: 0.736580, acc: 0.398438]\n",
      "2447: [D loss: 0.717920, acc: 0.503906]  [A loss: 0.891936, acc: 0.160156]\n",
      "2448: [D loss: 0.696990, acc: 0.503906]  [A loss: 0.778859, acc: 0.339844]\n",
      "2449: [D loss: 0.707547, acc: 0.517578]  [A loss: 0.874178, acc: 0.187500]\n",
      "2450: [D loss: 0.706877, acc: 0.500000]  [A loss: 0.795674, acc: 0.300781]\n",
      "2451: [D loss: 0.702138, acc: 0.521484]  [A loss: 0.880067, acc: 0.140625]\n",
      "2452: [D loss: 0.694387, acc: 0.539062]  [A loss: 0.767473, acc: 0.363281]\n",
      "2453: [D loss: 0.714934, acc: 0.511719]  [A loss: 0.982564, acc: 0.097656]\n",
      "2454: [D loss: 0.689148, acc: 0.556641]  [A loss: 0.713476, acc: 0.449219]\n",
      "2455: [D loss: 0.708644, acc: 0.521484]  [A loss: 0.860752, acc: 0.230469]\n",
      "2456: [D loss: 0.691046, acc: 0.542969]  [A loss: 0.784220, acc: 0.332031]\n",
      "2457: [D loss: 0.694449, acc: 0.566406]  [A loss: 0.897299, acc: 0.144531]\n",
      "2458: [D loss: 0.686415, acc: 0.554688]  [A loss: 0.813110, acc: 0.281250]\n",
      "2459: [D loss: 0.694995, acc: 0.535156]  [A loss: 0.858894, acc: 0.191406]\n",
      "2460: [D loss: 0.682474, acc: 0.554688]  [A loss: 0.861561, acc: 0.179688]\n",
      "2461: [D loss: 0.684266, acc: 0.544922]  [A loss: 0.816761, acc: 0.250000]\n",
      "2462: [D loss: 0.699560, acc: 0.546875]  [A loss: 0.843606, acc: 0.250000]\n",
      "2463: [D loss: 0.693094, acc: 0.541016]  [A loss: 0.875104, acc: 0.152344]\n",
      "2464: [D loss: 0.685643, acc: 0.558594]  [A loss: 0.828201, acc: 0.242188]\n",
      "2465: [D loss: 0.693713, acc: 0.525391]  [A loss: 0.906297, acc: 0.164062]\n",
      "2466: [D loss: 0.705112, acc: 0.533203]  [A loss: 0.785033, acc: 0.332031]\n",
      "2467: [D loss: 0.719177, acc: 0.539062]  [A loss: 1.101971, acc: 0.019531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2468: [D loss: 0.709659, acc: 0.507812]  [A loss: 0.592955, acc: 0.769531]\n",
      "2469: [D loss: 0.731257, acc: 0.505859]  [A loss: 0.992633, acc: 0.074219]\n",
      "2470: [D loss: 0.692682, acc: 0.554688]  [A loss: 0.677359, acc: 0.554688]\n",
      "2471: [D loss: 0.704547, acc: 0.542969]  [A loss: 0.906209, acc: 0.117188]\n",
      "2472: [D loss: 0.684918, acc: 0.564453]  [A loss: 0.789351, acc: 0.312500]\n",
      "2473: [D loss: 0.705428, acc: 0.511719]  [A loss: 0.822927, acc: 0.253906]\n",
      "2474: [D loss: 0.691017, acc: 0.546875]  [A loss: 0.826661, acc: 0.242188]\n",
      "2475: [D loss: 0.704020, acc: 0.498047]  [A loss: 0.858395, acc: 0.253906]\n",
      "2476: [D loss: 0.685369, acc: 0.552734]  [A loss: 0.760155, acc: 0.332031]\n",
      "2477: [D loss: 0.692743, acc: 0.523438]  [A loss: 0.898571, acc: 0.156250]\n",
      "2478: [D loss: 0.685322, acc: 0.552734]  [A loss: 0.802611, acc: 0.250000]\n",
      "2479: [D loss: 0.694373, acc: 0.523438]  [A loss: 0.830019, acc: 0.238281]\n",
      "2480: [D loss: 0.678282, acc: 0.574219]  [A loss: 0.809472, acc: 0.265625]\n",
      "2481: [D loss: 0.695787, acc: 0.541016]  [A loss: 0.933421, acc: 0.113281]\n",
      "2482: [D loss: 0.695083, acc: 0.544922]  [A loss: 0.697538, acc: 0.500000]\n",
      "2483: [D loss: 0.722197, acc: 0.505859]  [A loss: 1.019176, acc: 0.074219]\n",
      "2484: [D loss: 0.689395, acc: 0.542969]  [A loss: 0.689601, acc: 0.531250]\n",
      "2485: [D loss: 0.708344, acc: 0.527344]  [A loss: 0.922274, acc: 0.164062]\n",
      "2486: [D loss: 0.690171, acc: 0.542969]  [A loss: 0.733015, acc: 0.441406]\n",
      "2487: [D loss: 0.700195, acc: 0.503906]  [A loss: 0.912480, acc: 0.125000]\n",
      "2488: [D loss: 0.678276, acc: 0.566406]  [A loss: 0.796208, acc: 0.261719]\n",
      "2489: [D loss: 0.690859, acc: 0.558594]  [A loss: 0.920208, acc: 0.117188]\n",
      "2490: [D loss: 0.695647, acc: 0.517578]  [A loss: 0.716995, acc: 0.437500]\n",
      "2491: [D loss: 0.702297, acc: 0.531250]  [A loss: 1.053737, acc: 0.062500]\n",
      "2492: [D loss: 0.699228, acc: 0.558594]  [A loss: 0.648336, acc: 0.632812]\n",
      "2493: [D loss: 0.716890, acc: 0.537109]  [A loss: 0.877746, acc: 0.179688]\n",
      "2494: [D loss: 0.702045, acc: 0.523438]  [A loss: 0.835347, acc: 0.210938]\n",
      "2495: [D loss: 0.695325, acc: 0.539062]  [A loss: 0.817234, acc: 0.226562]\n",
      "2496: [D loss: 0.696310, acc: 0.552734]  [A loss: 0.802721, acc: 0.281250]\n",
      "2497: [D loss: 0.697384, acc: 0.529297]  [A loss: 0.832561, acc: 0.242188]\n",
      "2498: [D loss: 0.700019, acc: 0.529297]  [A loss: 0.854816, acc: 0.164062]\n",
      "2499: [D loss: 0.691031, acc: 0.560547]  [A loss: 0.840543, acc: 0.214844]\n",
      "2500: [D loss: 0.683499, acc: 0.558594]  [A loss: 0.802470, acc: 0.265625]\n",
      "2501: [D loss: 0.700824, acc: 0.519531]  [A loss: 0.879984, acc: 0.175781]\n",
      "2502: [D loss: 0.709677, acc: 0.498047]  [A loss: 0.799233, acc: 0.277344]\n",
      "2503: [D loss: 0.693968, acc: 0.537109]  [A loss: 0.898470, acc: 0.136719]\n",
      "2504: [D loss: 0.688277, acc: 0.546875]  [A loss: 0.826327, acc: 0.234375]\n",
      "2505: [D loss: 0.680692, acc: 0.556641]  [A loss: 0.839722, acc: 0.238281]\n",
      "2506: [D loss: 0.683064, acc: 0.562500]  [A loss: 0.881317, acc: 0.164062]\n",
      "2507: [D loss: 0.707376, acc: 0.509766]  [A loss: 0.756959, acc: 0.359375]\n",
      "2508: [D loss: 0.677823, acc: 0.552734]  [A loss: 0.845716, acc: 0.195312]\n",
      "2509: [D loss: 0.682458, acc: 0.546875]  [A loss: 0.974138, acc: 0.078125]\n",
      "2510: [D loss: 0.689303, acc: 0.537109]  [A loss: 0.671589, acc: 0.558594]\n",
      "2511: [D loss: 0.718760, acc: 0.531250]  [A loss: 1.083884, acc: 0.050781]\n",
      "2512: [D loss: 0.708860, acc: 0.521484]  [A loss: 0.716374, acc: 0.449219]\n",
      "2513: [D loss: 0.717249, acc: 0.511719]  [A loss: 0.883470, acc: 0.140625]\n",
      "2514: [D loss: 0.681539, acc: 0.558594]  [A loss: 0.811252, acc: 0.277344]\n",
      "2515: [D loss: 0.700980, acc: 0.507812]  [A loss: 0.860919, acc: 0.203125]\n",
      "2516: [D loss: 0.695818, acc: 0.548828]  [A loss: 0.841371, acc: 0.191406]\n",
      "2517: [D loss: 0.685115, acc: 0.542969]  [A loss: 0.831565, acc: 0.246094]\n",
      "2518: [D loss: 0.682945, acc: 0.566406]  [A loss: 0.876661, acc: 0.140625]\n",
      "2519: [D loss: 0.685924, acc: 0.546875]  [A loss: 0.783186, acc: 0.347656]\n",
      "2520: [D loss: 0.691671, acc: 0.539062]  [A loss: 0.917769, acc: 0.140625]\n",
      "2521: [D loss: 0.692304, acc: 0.542969]  [A loss: 0.713203, acc: 0.445312]\n",
      "2522: [D loss: 0.731662, acc: 0.519531]  [A loss: 1.064447, acc: 0.054688]\n",
      "2523: [D loss: 0.702081, acc: 0.521484]  [A loss: 0.710780, acc: 0.488281]\n",
      "2524: [D loss: 0.704024, acc: 0.519531]  [A loss: 0.888367, acc: 0.144531]\n",
      "2525: [D loss: 0.701348, acc: 0.531250]  [A loss: 0.793157, acc: 0.351562]\n",
      "2526: [D loss: 0.698911, acc: 0.527344]  [A loss: 0.903893, acc: 0.156250]\n",
      "2527: [D loss: 0.683611, acc: 0.564453]  [A loss: 0.761168, acc: 0.375000]\n",
      "2528: [D loss: 0.709192, acc: 0.529297]  [A loss: 0.891413, acc: 0.148438]\n",
      "2529: [D loss: 0.690050, acc: 0.554688]  [A loss: 0.802526, acc: 0.277344]\n",
      "2530: [D loss: 0.692319, acc: 0.558594]  [A loss: 0.937437, acc: 0.093750]\n",
      "2531: [D loss: 0.702102, acc: 0.511719]  [A loss: 0.786550, acc: 0.332031]\n",
      "2532: [D loss: 0.693101, acc: 0.556641]  [A loss: 0.906827, acc: 0.109375]\n",
      "2533: [D loss: 0.684432, acc: 0.537109]  [A loss: 0.766356, acc: 0.363281]\n",
      "2534: [D loss: 0.707878, acc: 0.484375]  [A loss: 0.990364, acc: 0.074219]\n",
      "2535: [D loss: 0.685616, acc: 0.562500]  [A loss: 0.718868, acc: 0.441406]\n",
      "2536: [D loss: 0.709519, acc: 0.525391]  [A loss: 1.025998, acc: 0.078125]\n",
      "2537: [D loss: 0.703313, acc: 0.537109]  [A loss: 0.693533, acc: 0.488281]\n",
      "2538: [D loss: 0.713811, acc: 0.511719]  [A loss: 0.973897, acc: 0.062500]\n",
      "2539: [D loss: 0.688853, acc: 0.544922]  [A loss: 0.700257, acc: 0.531250]\n",
      "2540: [D loss: 0.700111, acc: 0.521484]  [A loss: 0.932713, acc: 0.132812]\n",
      "2541: [D loss: 0.683189, acc: 0.523438]  [A loss: 0.744195, acc: 0.421875]\n",
      "2542: [D loss: 0.712636, acc: 0.527344]  [A loss: 0.921652, acc: 0.132812]\n",
      "2543: [D loss: 0.690787, acc: 0.527344]  [A loss: 0.774389, acc: 0.332031]\n",
      "2544: [D loss: 0.707409, acc: 0.533203]  [A loss: 0.901592, acc: 0.128906]\n",
      "2545: [D loss: 0.701242, acc: 0.488281]  [A loss: 0.810823, acc: 0.257812]\n",
      "2546: [D loss: 0.698831, acc: 0.537109]  [A loss: 0.907128, acc: 0.121094]\n",
      "2547: [D loss: 0.697933, acc: 0.513672]  [A loss: 0.798061, acc: 0.308594]\n",
      "2548: [D loss: 0.703657, acc: 0.517578]  [A loss: 0.851602, acc: 0.191406]\n",
      "2549: [D loss: 0.699004, acc: 0.523438]  [A loss: 0.809278, acc: 0.269531]\n",
      "2550: [D loss: 0.702366, acc: 0.531250]  [A loss: 0.847745, acc: 0.199219]\n",
      "2551: [D loss: 0.686384, acc: 0.550781]  [A loss: 0.861428, acc: 0.187500]\n",
      "2552: [D loss: 0.706368, acc: 0.501953]  [A loss: 0.854426, acc: 0.222656]\n",
      "2553: [D loss: 0.691198, acc: 0.531250]  [A loss: 0.923594, acc: 0.132812]\n",
      "2554: [D loss: 0.681706, acc: 0.574219]  [A loss: 0.705880, acc: 0.488281]\n",
      "2555: [D loss: 0.709095, acc: 0.517578]  [A loss: 1.021543, acc: 0.035156]\n",
      "2556: [D loss: 0.693594, acc: 0.511719]  [A loss: 0.618110, acc: 0.722656]\n",
      "2557: [D loss: 0.735296, acc: 0.501953]  [A loss: 1.028266, acc: 0.042969]\n",
      "2558: [D loss: 0.690320, acc: 0.568359]  [A loss: 0.735709, acc: 0.398438]\n",
      "2559: [D loss: 0.727354, acc: 0.484375]  [A loss: 0.850316, acc: 0.210938]\n",
      "2560: [D loss: 0.676130, acc: 0.576172]  [A loss: 0.821222, acc: 0.207031]\n",
      "2561: [D loss: 0.692763, acc: 0.550781]  [A loss: 0.866414, acc: 0.140625]\n",
      "2562: [D loss: 0.694157, acc: 0.517578]  [A loss: 0.819265, acc: 0.234375]\n",
      "2563: [D loss: 0.707781, acc: 0.513672]  [A loss: 0.921135, acc: 0.082031]\n",
      "2564: [D loss: 0.696670, acc: 0.558594]  [A loss: 0.754481, acc: 0.343750]\n",
      "2565: [D loss: 0.704035, acc: 0.519531]  [A loss: 0.888098, acc: 0.156250]\n",
      "2566: [D loss: 0.691044, acc: 0.548828]  [A loss: 0.756950, acc: 0.382812]\n",
      "2567: [D loss: 0.715494, acc: 0.503906]  [A loss: 0.960606, acc: 0.085938]\n",
      "2568: [D loss: 0.694358, acc: 0.513672]  [A loss: 0.756635, acc: 0.355469]\n",
      "2569: [D loss: 0.700044, acc: 0.533203]  [A loss: 0.885320, acc: 0.148438]\n",
      "2570: [D loss: 0.694730, acc: 0.523438]  [A loss: 0.751119, acc: 0.375000]\n",
      "2571: [D loss: 0.711332, acc: 0.535156]  [A loss: 0.925251, acc: 0.144531]\n",
      "2572: [D loss: 0.684346, acc: 0.564453]  [A loss: 0.760034, acc: 0.375000]\n",
      "2573: [D loss: 0.702937, acc: 0.558594]  [A loss: 0.935851, acc: 0.117188]\n",
      "2574: [D loss: 0.693154, acc: 0.533203]  [A loss: 0.719692, acc: 0.433594]\n",
      "2575: [D loss: 0.711960, acc: 0.527344]  [A loss: 0.976328, acc: 0.058594]\n",
      "2576: [D loss: 0.694297, acc: 0.529297]  [A loss: 0.662704, acc: 0.613281]\n",
      "2577: [D loss: 0.704143, acc: 0.511719]  [A loss: 0.874315, acc: 0.171875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2578: [D loss: 0.705379, acc: 0.482422]  [A loss: 0.796048, acc: 0.308594]\n",
      "2579: [D loss: 0.693283, acc: 0.531250]  [A loss: 0.864120, acc: 0.179688]\n",
      "2580: [D loss: 0.687494, acc: 0.542969]  [A loss: 0.819352, acc: 0.242188]\n",
      "2581: [D loss: 0.692683, acc: 0.533203]  [A loss: 0.836159, acc: 0.214844]\n",
      "2582: [D loss: 0.690351, acc: 0.527344]  [A loss: 0.826634, acc: 0.242188]\n",
      "2583: [D loss: 0.707634, acc: 0.507812]  [A loss: 0.850940, acc: 0.207031]\n",
      "2584: [D loss: 0.699814, acc: 0.509766]  [A loss: 0.892660, acc: 0.175781]\n",
      "2585: [D loss: 0.687990, acc: 0.568359]  [A loss: 0.737708, acc: 0.406250]\n",
      "2586: [D loss: 0.722405, acc: 0.525391]  [A loss: 1.072153, acc: 0.015625]\n",
      "2587: [D loss: 0.694926, acc: 0.539062]  [A loss: 0.653484, acc: 0.601562]\n",
      "2588: [D loss: 0.717054, acc: 0.509766]  [A loss: 0.957808, acc: 0.078125]\n",
      "2589: [D loss: 0.690303, acc: 0.541016]  [A loss: 0.710630, acc: 0.468750]\n",
      "2590: [D loss: 0.702100, acc: 0.542969]  [A loss: 0.870334, acc: 0.136719]\n",
      "2591: [D loss: 0.699952, acc: 0.509766]  [A loss: 0.800070, acc: 0.292969]\n",
      "2592: [D loss: 0.712642, acc: 0.503906]  [A loss: 0.869648, acc: 0.164062]\n",
      "2593: [D loss: 0.681051, acc: 0.546875]  [A loss: 0.859254, acc: 0.199219]\n",
      "2594: [D loss: 0.691945, acc: 0.503906]  [A loss: 0.766401, acc: 0.359375]\n",
      "2595: [D loss: 0.696983, acc: 0.529297]  [A loss: 0.903000, acc: 0.109375]\n",
      "2596: [D loss: 0.693410, acc: 0.525391]  [A loss: 0.801387, acc: 0.277344]\n",
      "2597: [D loss: 0.704014, acc: 0.523438]  [A loss: 0.855350, acc: 0.175781]\n",
      "2598: [D loss: 0.705786, acc: 0.509766]  [A loss: 0.884118, acc: 0.160156]\n",
      "2599: [D loss: 0.697581, acc: 0.517578]  [A loss: 0.782134, acc: 0.289062]\n",
      "2600: [D loss: 0.696184, acc: 0.521484]  [A loss: 0.907686, acc: 0.148438]\n",
      "2601: [D loss: 0.701789, acc: 0.527344]  [A loss: 0.707518, acc: 0.511719]\n",
      "2602: [D loss: 0.703866, acc: 0.523438]  [A loss: 0.992465, acc: 0.082031]\n",
      "2603: [D loss: 0.692457, acc: 0.542969]  [A loss: 0.656169, acc: 0.632812]\n",
      "2604: [D loss: 0.700045, acc: 0.542969]  [A loss: 0.953292, acc: 0.058594]\n",
      "2605: [D loss: 0.686447, acc: 0.556641]  [A loss: 0.703664, acc: 0.480469]\n",
      "2606: [D loss: 0.713559, acc: 0.490234]  [A loss: 0.851468, acc: 0.179688]\n",
      "2607: [D loss: 0.686095, acc: 0.568359]  [A loss: 0.776165, acc: 0.296875]\n",
      "2608: [D loss: 0.692733, acc: 0.550781]  [A loss: 0.797904, acc: 0.273438]\n",
      "2609: [D loss: 0.683541, acc: 0.537109]  [A loss: 0.824560, acc: 0.214844]\n",
      "2610: [D loss: 0.701135, acc: 0.511719]  [A loss: 0.899995, acc: 0.117188]\n",
      "2611: [D loss: 0.692076, acc: 0.535156]  [A loss: 0.814457, acc: 0.234375]\n",
      "2612: [D loss: 0.690071, acc: 0.521484]  [A loss: 0.835795, acc: 0.175781]\n",
      "2613: [D loss: 0.699571, acc: 0.498047]  [A loss: 0.816170, acc: 0.222656]\n",
      "2614: [D loss: 0.696043, acc: 0.525391]  [A loss: 0.922032, acc: 0.113281]\n",
      "2615: [D loss: 0.690095, acc: 0.550781]  [A loss: 0.712879, acc: 0.503906]\n",
      "2616: [D loss: 0.694068, acc: 0.558594]  [A loss: 0.986276, acc: 0.066406]\n",
      "2617: [D loss: 0.699774, acc: 0.525391]  [A loss: 0.707527, acc: 0.492188]\n",
      "2618: [D loss: 0.693833, acc: 0.541016]  [A loss: 0.970511, acc: 0.058594]\n",
      "2619: [D loss: 0.688209, acc: 0.529297]  [A loss: 0.710757, acc: 0.503906]\n",
      "2620: [D loss: 0.707154, acc: 0.523438]  [A loss: 1.020646, acc: 0.050781]\n",
      "2621: [D loss: 0.683147, acc: 0.556641]  [A loss: 0.702818, acc: 0.503906]\n",
      "2622: [D loss: 0.704887, acc: 0.521484]  [A loss: 0.962890, acc: 0.089844]\n",
      "2623: [D loss: 0.690444, acc: 0.560547]  [A loss: 0.712634, acc: 0.453125]\n",
      "2624: [D loss: 0.721827, acc: 0.482422]  [A loss: 0.963676, acc: 0.078125]\n",
      "2625: [D loss: 0.690196, acc: 0.537109]  [A loss: 0.668822, acc: 0.597656]\n",
      "2626: [D loss: 0.711151, acc: 0.505859]  [A loss: 0.911427, acc: 0.128906]\n",
      "2627: [D loss: 0.699988, acc: 0.533203]  [A loss: 0.723489, acc: 0.433594]\n",
      "2628: [D loss: 0.689791, acc: 0.533203]  [A loss: 0.855639, acc: 0.195312]\n",
      "2629: [D loss: 0.689386, acc: 0.550781]  [A loss: 0.792572, acc: 0.253906]\n",
      "2630: [D loss: 0.694589, acc: 0.509766]  [A loss: 0.810237, acc: 0.269531]\n",
      "2631: [D loss: 0.692717, acc: 0.552734]  [A loss: 0.801649, acc: 0.261719]\n",
      "2632: [D loss: 0.700122, acc: 0.541016]  [A loss: 0.868811, acc: 0.167969]\n",
      "2633: [D loss: 0.696628, acc: 0.525391]  [A loss: 0.908401, acc: 0.144531]\n",
      "2634: [D loss: 0.691521, acc: 0.548828]  [A loss: 0.802505, acc: 0.285156]\n",
      "2635: [D loss: 0.683250, acc: 0.587891]  [A loss: 0.899530, acc: 0.148438]\n",
      "2636: [D loss: 0.695009, acc: 0.509766]  [A loss: 0.747957, acc: 0.394531]\n",
      "2637: [D loss: 0.686718, acc: 0.554688]  [A loss: 0.937827, acc: 0.132812]\n",
      "2638: [D loss: 0.684315, acc: 0.554688]  [A loss: 0.721655, acc: 0.457031]\n",
      "2639: [D loss: 0.703459, acc: 0.552734]  [A loss: 0.921097, acc: 0.144531]\n",
      "2640: [D loss: 0.694998, acc: 0.529297]  [A loss: 0.788105, acc: 0.335938]\n",
      "2641: [D loss: 0.706750, acc: 0.513672]  [A loss: 0.882863, acc: 0.160156]\n",
      "2642: [D loss: 0.693246, acc: 0.529297]  [A loss: 0.781663, acc: 0.316406]\n",
      "2643: [D loss: 0.698289, acc: 0.541016]  [A loss: 0.893168, acc: 0.148438]\n",
      "2644: [D loss: 0.679569, acc: 0.564453]  [A loss: 0.797962, acc: 0.253906]\n",
      "2645: [D loss: 0.699287, acc: 0.521484]  [A loss: 0.907977, acc: 0.140625]\n",
      "2646: [D loss: 0.681973, acc: 0.552734]  [A loss: 0.751875, acc: 0.363281]\n",
      "2647: [D loss: 0.709770, acc: 0.521484]  [A loss: 0.950796, acc: 0.097656]\n",
      "2648: [D loss: 0.676791, acc: 0.576172]  [A loss: 0.726591, acc: 0.445312]\n",
      "2649: [D loss: 0.700169, acc: 0.519531]  [A loss: 0.947520, acc: 0.113281]\n",
      "2650: [D loss: 0.718835, acc: 0.498047]  [A loss: 0.821980, acc: 0.281250]\n",
      "2651: [D loss: 0.702339, acc: 0.513672]  [A loss: 0.818418, acc: 0.226562]\n",
      "2652: [D loss: 0.701205, acc: 0.509766]  [A loss: 0.915172, acc: 0.093750]\n",
      "2653: [D loss: 0.677970, acc: 0.597656]  [A loss: 0.774257, acc: 0.324219]\n",
      "2654: [D loss: 0.703361, acc: 0.515625]  [A loss: 0.874640, acc: 0.179688]\n",
      "2655: [D loss: 0.695493, acc: 0.521484]  [A loss: 0.904087, acc: 0.136719]\n",
      "2656: [D loss: 0.685307, acc: 0.529297]  [A loss: 0.770715, acc: 0.324219]\n",
      "2657: [D loss: 0.713405, acc: 0.503906]  [A loss: 1.010442, acc: 0.074219]\n",
      "2658: [D loss: 0.701657, acc: 0.519531]  [A loss: 0.688424, acc: 0.500000]\n",
      "2659: [D loss: 0.736730, acc: 0.490234]  [A loss: 1.107873, acc: 0.011719]\n",
      "2660: [D loss: 0.691891, acc: 0.527344]  [A loss: 0.632571, acc: 0.640625]\n",
      "2661: [D loss: 0.736313, acc: 0.498047]  [A loss: 0.950379, acc: 0.070312]\n",
      "2662: [D loss: 0.689025, acc: 0.537109]  [A loss: 0.710061, acc: 0.472656]\n",
      "2663: [D loss: 0.705230, acc: 0.517578]  [A loss: 0.837700, acc: 0.183594]\n",
      "2664: [D loss: 0.695523, acc: 0.535156]  [A loss: 0.848890, acc: 0.195312]\n",
      "2665: [D loss: 0.685857, acc: 0.542969]  [A loss: 0.813609, acc: 0.214844]\n",
      "2666: [D loss: 0.681774, acc: 0.562500]  [A loss: 0.834143, acc: 0.246094]\n",
      "2667: [D loss: 0.688984, acc: 0.546875]  [A loss: 0.793413, acc: 0.296875]\n",
      "2668: [D loss: 0.697150, acc: 0.529297]  [A loss: 0.867143, acc: 0.144531]\n",
      "2669: [D loss: 0.698336, acc: 0.537109]  [A loss: 0.742644, acc: 0.363281]\n",
      "2670: [D loss: 0.701137, acc: 0.544922]  [A loss: 0.929431, acc: 0.093750]\n",
      "2671: [D loss: 0.678849, acc: 0.564453]  [A loss: 0.730297, acc: 0.410156]\n",
      "2672: [D loss: 0.697985, acc: 0.529297]  [A loss: 0.932399, acc: 0.109375]\n",
      "2673: [D loss: 0.680696, acc: 0.564453]  [A loss: 0.743082, acc: 0.367188]\n",
      "2674: [D loss: 0.708513, acc: 0.539062]  [A loss: 0.977106, acc: 0.101562]\n",
      "2675: [D loss: 0.701952, acc: 0.529297]  [A loss: 0.694702, acc: 0.523438]\n",
      "2676: [D loss: 0.709555, acc: 0.509766]  [A loss: 0.983273, acc: 0.070312]\n",
      "2677: [D loss: 0.690267, acc: 0.550781]  [A loss: 0.728577, acc: 0.406250]\n",
      "2678: [D loss: 0.712308, acc: 0.500000]  [A loss: 0.865888, acc: 0.156250]\n",
      "2679: [D loss: 0.692292, acc: 0.560547]  [A loss: 0.813576, acc: 0.234375]\n",
      "2680: [D loss: 0.709829, acc: 0.507812]  [A loss: 0.915945, acc: 0.125000]\n",
      "2681: [D loss: 0.685586, acc: 0.550781]  [A loss: 0.736782, acc: 0.414062]\n",
      "2682: [D loss: 0.702264, acc: 0.515625]  [A loss: 0.939376, acc: 0.128906]\n",
      "2683: [D loss: 0.685306, acc: 0.548828]  [A loss: 0.695685, acc: 0.519531]\n",
      "2684: [D loss: 0.725283, acc: 0.535156]  [A loss: 1.025880, acc: 0.042969]\n",
      "2685: [D loss: 0.689115, acc: 0.544922]  [A loss: 0.640789, acc: 0.699219]\n",
      "2686: [D loss: 0.724156, acc: 0.515625]  [A loss: 0.921352, acc: 0.125000]\n",
      "2687: [D loss: 0.687429, acc: 0.570312]  [A loss: 0.697910, acc: 0.488281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688: [D loss: 0.720521, acc: 0.523438]  [A loss: 0.945780, acc: 0.097656]\n",
      "2689: [D loss: 0.698572, acc: 0.509766]  [A loss: 0.715490, acc: 0.464844]\n",
      "2690: [D loss: 0.692975, acc: 0.523438]  [A loss: 0.840441, acc: 0.203125]\n",
      "2691: [D loss: 0.682362, acc: 0.542969]  [A loss: 0.759820, acc: 0.375000]\n",
      "2692: [D loss: 0.713342, acc: 0.525391]  [A loss: 0.938991, acc: 0.105469]\n",
      "2693: [D loss: 0.689570, acc: 0.539062]  [A loss: 0.752197, acc: 0.394531]\n",
      "2694: [D loss: 0.710382, acc: 0.505859]  [A loss: 0.902114, acc: 0.152344]\n",
      "2695: [D loss: 0.691352, acc: 0.546875]  [A loss: 0.806126, acc: 0.269531]\n",
      "2696: [D loss: 0.704897, acc: 0.535156]  [A loss: 0.872115, acc: 0.171875]\n",
      "2697: [D loss: 0.705714, acc: 0.527344]  [A loss: 0.801926, acc: 0.269531]\n",
      "2698: [D loss: 0.712145, acc: 0.494141]  [A loss: 0.828768, acc: 0.203125]\n",
      "2699: [D loss: 0.694765, acc: 0.527344]  [A loss: 0.830119, acc: 0.222656]\n",
      "2700: [D loss: 0.688208, acc: 0.554688]  [A loss: 0.831175, acc: 0.195312]\n",
      "2701: [D loss: 0.696176, acc: 0.531250]  [A loss: 0.877908, acc: 0.136719]\n",
      "2702: [D loss: 0.688352, acc: 0.568359]  [A loss: 0.868419, acc: 0.183594]\n",
      "2703: [D loss: 0.688341, acc: 0.548828]  [A loss: 0.807609, acc: 0.285156]\n",
      "2704: [D loss: 0.700768, acc: 0.519531]  [A loss: 0.908077, acc: 0.121094]\n",
      "2705: [D loss: 0.700474, acc: 0.513672]  [A loss: 0.780679, acc: 0.300781]\n",
      "2706: [D loss: 0.689895, acc: 0.544922]  [A loss: 0.986517, acc: 0.074219]\n",
      "2707: [D loss: 0.695022, acc: 0.535156]  [A loss: 0.671200, acc: 0.566406]\n",
      "2708: [D loss: 0.727723, acc: 0.519531]  [A loss: 1.047870, acc: 0.039062]\n",
      "2709: [D loss: 0.685491, acc: 0.554688]  [A loss: 0.671415, acc: 0.558594]\n",
      "2710: [D loss: 0.731380, acc: 0.474609]  [A loss: 0.914401, acc: 0.125000]\n",
      "2711: [D loss: 0.697544, acc: 0.531250]  [A loss: 0.718861, acc: 0.460938]\n",
      "2712: [D loss: 0.716052, acc: 0.490234]  [A loss: 0.894285, acc: 0.109375]\n",
      "2713: [D loss: 0.680934, acc: 0.546875]  [A loss: 0.684195, acc: 0.511719]\n",
      "2714: [D loss: 0.705827, acc: 0.535156]  [A loss: 0.975423, acc: 0.054688]\n",
      "2715: [D loss: 0.686348, acc: 0.521484]  [A loss: 0.683296, acc: 0.535156]\n",
      "2716: [D loss: 0.714019, acc: 0.529297]  [A loss: 0.948774, acc: 0.109375]\n",
      "2717: [D loss: 0.684003, acc: 0.554688]  [A loss: 0.742582, acc: 0.437500]\n",
      "2718: [D loss: 0.704276, acc: 0.535156]  [A loss: 0.896722, acc: 0.144531]\n",
      "2719: [D loss: 0.690496, acc: 0.554688]  [A loss: 0.723050, acc: 0.453125]\n",
      "2720: [D loss: 0.721699, acc: 0.519531]  [A loss: 0.930372, acc: 0.089844]\n",
      "2721: [D loss: 0.678952, acc: 0.564453]  [A loss: 0.745636, acc: 0.410156]\n",
      "2722: [D loss: 0.700244, acc: 0.517578]  [A loss: 0.874523, acc: 0.171875]\n",
      "2723: [D loss: 0.681718, acc: 0.544922]  [A loss: 0.748579, acc: 0.394531]\n",
      "2724: [D loss: 0.699398, acc: 0.535156]  [A loss: 0.924939, acc: 0.101562]\n",
      "2725: [D loss: 0.676522, acc: 0.580078]  [A loss: 0.772511, acc: 0.351562]\n",
      "2726: [D loss: 0.700902, acc: 0.523438]  [A loss: 0.875618, acc: 0.199219]\n",
      "2727: [D loss: 0.701116, acc: 0.513672]  [A loss: 0.822897, acc: 0.265625]\n",
      "2728: [D loss: 0.700576, acc: 0.519531]  [A loss: 0.830157, acc: 0.226562]\n",
      "2729: [D loss: 0.693511, acc: 0.529297]  [A loss: 0.866146, acc: 0.183594]\n",
      "2730: [D loss: 0.694954, acc: 0.513672]  [A loss: 0.822758, acc: 0.253906]\n",
      "2731: [D loss: 0.699419, acc: 0.515625]  [A loss: 0.903784, acc: 0.156250]\n",
      "2732: [D loss: 0.705297, acc: 0.503906]  [A loss: 0.728322, acc: 0.433594]\n",
      "2733: [D loss: 0.698892, acc: 0.539062]  [A loss: 1.000395, acc: 0.089844]\n",
      "2734: [D loss: 0.686731, acc: 0.546875]  [A loss: 0.705117, acc: 0.531250]\n",
      "2735: [D loss: 0.708054, acc: 0.515625]  [A loss: 0.942175, acc: 0.109375]\n",
      "2736: [D loss: 0.689336, acc: 0.552734]  [A loss: 0.766714, acc: 0.382812]\n",
      "2737: [D loss: 0.706511, acc: 0.523438]  [A loss: 0.926742, acc: 0.140625]\n",
      "2738: [D loss: 0.699031, acc: 0.533203]  [A loss: 0.747444, acc: 0.386719]\n",
      "2739: [D loss: 0.705574, acc: 0.523438]  [A loss: 0.885226, acc: 0.152344]\n",
      "2740: [D loss: 0.691800, acc: 0.521484]  [A loss: 0.820904, acc: 0.269531]\n",
      "2741: [D loss: 0.687019, acc: 0.554688]  [A loss: 0.824835, acc: 0.250000]\n",
      "2742: [D loss: 0.692395, acc: 0.531250]  [A loss: 0.864464, acc: 0.164062]\n",
      "2743: [D loss: 0.705583, acc: 0.498047]  [A loss: 0.854023, acc: 0.257812]\n",
      "2744: [D loss: 0.702749, acc: 0.488281]  [A loss: 0.814623, acc: 0.257812]\n",
      "2745: [D loss: 0.703951, acc: 0.515625]  [A loss: 0.899729, acc: 0.136719]\n",
      "2746: [D loss: 0.687884, acc: 0.552734]  [A loss: 0.894384, acc: 0.156250]\n",
      "2747: [D loss: 0.681264, acc: 0.550781]  [A loss: 0.780732, acc: 0.347656]\n",
      "2748: [D loss: 0.701393, acc: 0.515625]  [A loss: 0.952878, acc: 0.101562]\n",
      "2749: [D loss: 0.690675, acc: 0.535156]  [A loss: 0.689650, acc: 0.511719]\n",
      "2750: [D loss: 0.716073, acc: 0.511719]  [A loss: 0.961899, acc: 0.089844]\n",
      "2751: [D loss: 0.710668, acc: 0.505859]  [A loss: 0.683006, acc: 0.546875]\n",
      "2752: [D loss: 0.695608, acc: 0.527344]  [A loss: 0.905951, acc: 0.128906]\n",
      "2753: [D loss: 0.687942, acc: 0.554688]  [A loss: 0.703504, acc: 0.503906]\n",
      "2754: [D loss: 0.725038, acc: 0.527344]  [A loss: 0.954552, acc: 0.105469]\n",
      "2755: [D loss: 0.700443, acc: 0.523438]  [A loss: 0.727434, acc: 0.406250]\n",
      "2756: [D loss: 0.693464, acc: 0.554688]  [A loss: 0.922315, acc: 0.160156]\n",
      "2757: [D loss: 0.691080, acc: 0.544922]  [A loss: 0.713175, acc: 0.480469]\n",
      "2758: [D loss: 0.701653, acc: 0.541016]  [A loss: 0.892218, acc: 0.140625]\n",
      "2759: [D loss: 0.699312, acc: 0.550781]  [A loss: 0.767640, acc: 0.343750]\n",
      "2760: [D loss: 0.712149, acc: 0.521484]  [A loss: 0.897143, acc: 0.128906]\n",
      "2761: [D loss: 0.698009, acc: 0.511719]  [A loss: 0.799071, acc: 0.285156]\n",
      "2762: [D loss: 0.702821, acc: 0.525391]  [A loss: 0.952126, acc: 0.121094]\n",
      "2763: [D loss: 0.694199, acc: 0.544922]  [A loss: 0.675549, acc: 0.597656]\n",
      "2764: [D loss: 0.725384, acc: 0.507812]  [A loss: 1.018911, acc: 0.066406]\n",
      "2765: [D loss: 0.688914, acc: 0.558594]  [A loss: 0.730839, acc: 0.398438]\n",
      "2766: [D loss: 0.701541, acc: 0.507812]  [A loss: 0.864381, acc: 0.175781]\n",
      "2767: [D loss: 0.695864, acc: 0.537109]  [A loss: 0.775417, acc: 0.351562]\n",
      "2768: [D loss: 0.704437, acc: 0.498047]  [A loss: 0.867340, acc: 0.199219]\n",
      "2769: [D loss: 0.700565, acc: 0.513672]  [A loss: 0.808511, acc: 0.261719]\n",
      "2770: [D loss: 0.700737, acc: 0.511719]  [A loss: 0.934574, acc: 0.105469]\n",
      "2771: [D loss: 0.693268, acc: 0.535156]  [A loss: 0.784667, acc: 0.312500]\n",
      "2772: [D loss: 0.697840, acc: 0.515625]  [A loss: 0.987068, acc: 0.070312]\n",
      "2773: [D loss: 0.696748, acc: 0.517578]  [A loss: 0.686649, acc: 0.570312]\n",
      "2774: [D loss: 0.701211, acc: 0.525391]  [A loss: 0.962387, acc: 0.097656]\n",
      "2775: [D loss: 0.705448, acc: 0.505859]  [A loss: 0.746207, acc: 0.386719]\n",
      "2776: [D loss: 0.695105, acc: 0.544922]  [A loss: 0.843165, acc: 0.207031]\n",
      "2777: [D loss: 0.695369, acc: 0.531250]  [A loss: 0.752978, acc: 0.406250]\n",
      "2778: [D loss: 0.689476, acc: 0.539062]  [A loss: 0.888674, acc: 0.167969]\n",
      "2779: [D loss: 0.705974, acc: 0.529297]  [A loss: 0.704418, acc: 0.488281]\n",
      "2780: [D loss: 0.727227, acc: 0.492188]  [A loss: 0.992107, acc: 0.089844]\n",
      "2781: [D loss: 0.688027, acc: 0.537109]  [A loss: 0.693933, acc: 0.515625]\n",
      "2782: [D loss: 0.718646, acc: 0.498047]  [A loss: 0.933013, acc: 0.085938]\n",
      "2783: [D loss: 0.694893, acc: 0.527344]  [A loss: 0.727789, acc: 0.433594]\n",
      "2784: [D loss: 0.703261, acc: 0.535156]  [A loss: 0.908471, acc: 0.128906]\n",
      "2785: [D loss: 0.696511, acc: 0.546875]  [A loss: 0.752294, acc: 0.386719]\n",
      "2786: [D loss: 0.702207, acc: 0.511719]  [A loss: 0.825282, acc: 0.230469]\n",
      "2787: [D loss: 0.690631, acc: 0.554688]  [A loss: 0.860221, acc: 0.152344]\n",
      "2788: [D loss: 0.689071, acc: 0.552734]  [A loss: 0.811525, acc: 0.269531]\n",
      "2789: [D loss: 0.706993, acc: 0.521484]  [A loss: 0.949111, acc: 0.101562]\n",
      "2790: [D loss: 0.686175, acc: 0.542969]  [A loss: 0.780973, acc: 0.289062]\n",
      "2791: [D loss: 0.720314, acc: 0.501953]  [A loss: 1.039281, acc: 0.058594]\n",
      "2792: [D loss: 0.685533, acc: 0.550781]  [A loss: 0.630823, acc: 0.667969]\n",
      "2793: [D loss: 0.731325, acc: 0.511719]  [A loss: 0.907750, acc: 0.136719]\n",
      "2794: [D loss: 0.701392, acc: 0.509766]  [A loss: 0.750449, acc: 0.394531]\n",
      "2795: [D loss: 0.708525, acc: 0.521484]  [A loss: 0.832037, acc: 0.210938]\n",
      "2796: [D loss: 0.692928, acc: 0.519531]  [A loss: 0.827875, acc: 0.246094]\n",
      "2797: [D loss: 0.692149, acc: 0.541016]  [A loss: 0.837437, acc: 0.230469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2798: [D loss: 0.687017, acc: 0.558594]  [A loss: 0.813867, acc: 0.273438]\n",
      "2799: [D loss: 0.700561, acc: 0.519531]  [A loss: 0.947823, acc: 0.066406]\n",
      "2800: [D loss: 0.682619, acc: 0.572266]  [A loss: 0.750008, acc: 0.390625]\n",
      "2801: [D loss: 0.698881, acc: 0.533203]  [A loss: 0.896538, acc: 0.179688]\n",
      "2802: [D loss: 0.699781, acc: 0.537109]  [A loss: 0.854844, acc: 0.191406]\n",
      "2803: [D loss: 0.695303, acc: 0.511719]  [A loss: 0.804906, acc: 0.261719]\n",
      "2804: [D loss: 0.706608, acc: 0.539062]  [A loss: 0.903453, acc: 0.121094]\n",
      "2805: [D loss: 0.701086, acc: 0.496094]  [A loss: 0.779189, acc: 0.300781]\n",
      "2806: [D loss: 0.690657, acc: 0.515625]  [A loss: 0.850080, acc: 0.230469]\n",
      "2807: [D loss: 0.694917, acc: 0.560547]  [A loss: 0.774095, acc: 0.359375]\n",
      "2808: [D loss: 0.698546, acc: 0.509766]  [A loss: 0.883942, acc: 0.113281]\n",
      "2809: [D loss: 0.685541, acc: 0.548828]  [A loss: 0.825272, acc: 0.226562]\n",
      "2810: [D loss: 0.692741, acc: 0.535156]  [A loss: 0.846030, acc: 0.187500]\n",
      "2811: [D loss: 0.676847, acc: 0.544922]  [A loss: 0.877033, acc: 0.156250]\n",
      "2812: [D loss: 0.680954, acc: 0.562500]  [A loss: 0.841716, acc: 0.207031]\n",
      "2813: [D loss: 0.693050, acc: 0.564453]  [A loss: 0.916263, acc: 0.128906]\n",
      "2814: [D loss: 0.693654, acc: 0.552734]  [A loss: 0.774584, acc: 0.320312]\n",
      "2815: [D loss: 0.676327, acc: 0.576172]  [A loss: 0.969621, acc: 0.097656]\n",
      "2816: [D loss: 0.691339, acc: 0.552734]  [A loss: 0.700536, acc: 0.507812]\n",
      "2817: [D loss: 0.715702, acc: 0.503906]  [A loss: 1.030362, acc: 0.066406]\n",
      "2818: [D loss: 0.712283, acc: 0.509766]  [A loss: 0.667986, acc: 0.593750]\n",
      "2819: [D loss: 0.716720, acc: 0.531250]  [A loss: 1.024552, acc: 0.070312]\n",
      "2820: [D loss: 0.702722, acc: 0.533203]  [A loss: 0.670345, acc: 0.582031]\n",
      "2821: [D loss: 0.739224, acc: 0.486328]  [A loss: 0.867097, acc: 0.187500]\n",
      "2822: [D loss: 0.709046, acc: 0.531250]  [A loss: 0.895209, acc: 0.136719]\n",
      "2823: [D loss: 0.701549, acc: 0.503906]  [A loss: 0.758529, acc: 0.347656]\n",
      "2824: [D loss: 0.707153, acc: 0.488281]  [A loss: 0.938376, acc: 0.121094]\n",
      "2825: [D loss: 0.705222, acc: 0.500000]  [A loss: 0.778367, acc: 0.296875]\n",
      "2826: [D loss: 0.698793, acc: 0.548828]  [A loss: 0.887226, acc: 0.164062]\n",
      "2827: [D loss: 0.700618, acc: 0.517578]  [A loss: 0.767766, acc: 0.332031]\n",
      "2828: [D loss: 0.700573, acc: 0.533203]  [A loss: 0.880468, acc: 0.167969]\n",
      "2829: [D loss: 0.695444, acc: 0.519531]  [A loss: 0.806807, acc: 0.226562]\n",
      "2830: [D loss: 0.707327, acc: 0.501953]  [A loss: 0.859166, acc: 0.191406]\n",
      "2831: [D loss: 0.698281, acc: 0.537109]  [A loss: 0.856055, acc: 0.218750]\n",
      "2832: [D loss: 0.700908, acc: 0.517578]  [A loss: 0.772678, acc: 0.308594]\n",
      "2833: [D loss: 0.705385, acc: 0.507812]  [A loss: 0.861385, acc: 0.175781]\n",
      "2834: [D loss: 0.701237, acc: 0.494141]  [A loss: 0.791642, acc: 0.281250]\n",
      "2835: [D loss: 0.687661, acc: 0.572266]  [A loss: 0.914365, acc: 0.093750]\n",
      "2836: [D loss: 0.687147, acc: 0.539062]  [A loss: 0.826191, acc: 0.234375]\n",
      "2837: [D loss: 0.715595, acc: 0.486328]  [A loss: 0.851949, acc: 0.195312]\n",
      "2838: [D loss: 0.688879, acc: 0.548828]  [A loss: 0.764399, acc: 0.378906]\n",
      "2839: [D loss: 0.717866, acc: 0.496094]  [A loss: 0.870799, acc: 0.164062]\n",
      "2840: [D loss: 0.717956, acc: 0.458984]  [A loss: 0.854991, acc: 0.171875]\n",
      "2841: [D loss: 0.700485, acc: 0.500000]  [A loss: 0.777078, acc: 0.304688]\n",
      "2842: [D loss: 0.704693, acc: 0.511719]  [A loss: 0.845319, acc: 0.199219]\n",
      "2843: [D loss: 0.688877, acc: 0.523438]  [A loss: 0.845814, acc: 0.191406]\n",
      "2844: [D loss: 0.699258, acc: 0.513672]  [A loss: 0.881581, acc: 0.179688]\n",
      "2845: [D loss: 0.701064, acc: 0.511719]  [A loss: 0.836054, acc: 0.203125]\n",
      "2846: [D loss: 0.693697, acc: 0.529297]  [A loss: 0.959745, acc: 0.089844]\n",
      "2847: [D loss: 0.687396, acc: 0.535156]  [A loss: 0.784898, acc: 0.308594]\n",
      "2848: [D loss: 0.697477, acc: 0.556641]  [A loss: 0.966230, acc: 0.085938]\n",
      "2849: [D loss: 0.686287, acc: 0.562500]  [A loss: 0.726713, acc: 0.460938]\n",
      "2850: [D loss: 0.714280, acc: 0.533203]  [A loss: 1.071480, acc: 0.039062]\n",
      "2851: [D loss: 0.714789, acc: 0.511719]  [A loss: 0.691247, acc: 0.535156]\n",
      "2852: [D loss: 0.702794, acc: 0.537109]  [A loss: 0.952231, acc: 0.085938]\n",
      "2853: [D loss: 0.689578, acc: 0.525391]  [A loss: 0.743373, acc: 0.394531]\n",
      "2854: [D loss: 0.700385, acc: 0.519531]  [A loss: 0.963422, acc: 0.082031]\n",
      "2855: [D loss: 0.694292, acc: 0.513672]  [A loss: 0.670899, acc: 0.589844]\n",
      "2856: [D loss: 0.728729, acc: 0.509766]  [A loss: 1.005152, acc: 0.082031]\n",
      "2857: [D loss: 0.694219, acc: 0.529297]  [A loss: 0.695803, acc: 0.511719]\n",
      "2858: [D loss: 0.724679, acc: 0.501953]  [A loss: 0.877882, acc: 0.152344]\n",
      "2859: [D loss: 0.687434, acc: 0.558594]  [A loss: 0.770818, acc: 0.335938]\n",
      "2860: [D loss: 0.691122, acc: 0.548828]  [A loss: 0.866042, acc: 0.171875]\n",
      "2861: [D loss: 0.695661, acc: 0.542969]  [A loss: 0.825708, acc: 0.261719]\n",
      "2862: [D loss: 0.694307, acc: 0.544922]  [A loss: 0.852903, acc: 0.191406]\n",
      "2863: [D loss: 0.685648, acc: 0.539062]  [A loss: 0.847331, acc: 0.171875]\n",
      "2864: [D loss: 0.681108, acc: 0.552734]  [A loss: 0.886201, acc: 0.164062]\n",
      "2865: [D loss: 0.703327, acc: 0.498047]  [A loss: 0.777604, acc: 0.347656]\n",
      "2866: [D loss: 0.696484, acc: 0.535156]  [A loss: 1.112083, acc: 0.019531]\n",
      "2867: [D loss: 0.688313, acc: 0.539062]  [A loss: 0.640391, acc: 0.632812]\n",
      "2868: [D loss: 0.719050, acc: 0.513672]  [A loss: 0.969885, acc: 0.101562]\n",
      "2869: [D loss: 0.705346, acc: 0.509766]  [A loss: 0.742226, acc: 0.417969]\n",
      "2870: [D loss: 0.686036, acc: 0.535156]  [A loss: 0.817398, acc: 0.250000]\n",
      "2871: [D loss: 0.697690, acc: 0.535156]  [A loss: 0.884926, acc: 0.140625]\n",
      "2872: [D loss: 0.697686, acc: 0.531250]  [A loss: 0.777192, acc: 0.332031]\n",
      "2873: [D loss: 0.686387, acc: 0.566406]  [A loss: 0.893281, acc: 0.105469]\n",
      "2874: [D loss: 0.679002, acc: 0.544922]  [A loss: 0.762978, acc: 0.347656]\n",
      "2875: [D loss: 0.713503, acc: 0.511719]  [A loss: 0.984065, acc: 0.105469]\n",
      "2876: [D loss: 0.704554, acc: 0.501953]  [A loss: 0.698475, acc: 0.500000]\n",
      "2877: [D loss: 0.708869, acc: 0.535156]  [A loss: 0.967670, acc: 0.074219]\n",
      "2878: [D loss: 0.701148, acc: 0.515625]  [A loss: 0.708665, acc: 0.453125]\n",
      "2879: [D loss: 0.711458, acc: 0.515625]  [A loss: 0.923652, acc: 0.136719]\n",
      "2880: [D loss: 0.697869, acc: 0.486328]  [A loss: 0.714830, acc: 0.503906]\n",
      "2881: [D loss: 0.704654, acc: 0.533203]  [A loss: 0.885899, acc: 0.156250]\n",
      "2882: [D loss: 0.699302, acc: 0.517578]  [A loss: 0.771468, acc: 0.308594]\n",
      "2883: [D loss: 0.707503, acc: 0.519531]  [A loss: 0.900917, acc: 0.156250]\n",
      "2884: [D loss: 0.696146, acc: 0.523438]  [A loss: 0.814807, acc: 0.234375]\n",
      "2885: [D loss: 0.706008, acc: 0.509766]  [A loss: 0.841725, acc: 0.234375]\n",
      "2886: [D loss: 0.721135, acc: 0.476562]  [A loss: 0.767837, acc: 0.375000]\n",
      "2887: [D loss: 0.713825, acc: 0.515625]  [A loss: 0.990353, acc: 0.039062]\n",
      "2888: [D loss: 0.702668, acc: 0.505859]  [A loss: 0.664566, acc: 0.597656]\n",
      "2889: [D loss: 0.712558, acc: 0.496094]  [A loss: 0.908346, acc: 0.109375]\n",
      "2890: [D loss: 0.695772, acc: 0.531250]  [A loss: 0.739299, acc: 0.367188]\n",
      "2891: [D loss: 0.706121, acc: 0.525391]  [A loss: 0.873616, acc: 0.136719]\n",
      "2892: [D loss: 0.689216, acc: 0.529297]  [A loss: 0.742727, acc: 0.406250]\n",
      "2893: [D loss: 0.715276, acc: 0.511719]  [A loss: 0.867020, acc: 0.121094]\n",
      "2894: [D loss: 0.681425, acc: 0.556641]  [A loss: 0.773103, acc: 0.335938]\n",
      "2895: [D loss: 0.696157, acc: 0.541016]  [A loss: 0.918376, acc: 0.093750]\n",
      "2896: [D loss: 0.683753, acc: 0.533203]  [A loss: 0.724384, acc: 0.445312]\n",
      "2897: [D loss: 0.710494, acc: 0.498047]  [A loss: 1.021678, acc: 0.035156]\n",
      "2898: [D loss: 0.699173, acc: 0.535156]  [A loss: 0.682252, acc: 0.574219]\n",
      "2899: [D loss: 0.710950, acc: 0.511719]  [A loss: 0.866975, acc: 0.183594]\n",
      "2900: [D loss: 0.699127, acc: 0.533203]  [A loss: 0.765871, acc: 0.324219]\n",
      "2901: [D loss: 0.698500, acc: 0.523438]  [A loss: 0.862134, acc: 0.183594]\n",
      "2902: [D loss: 0.693780, acc: 0.517578]  [A loss: 0.791961, acc: 0.296875]\n",
      "2903: [D loss: 0.693106, acc: 0.544922]  [A loss: 0.861987, acc: 0.183594]\n",
      "2904: [D loss: 0.694257, acc: 0.515625]  [A loss: 0.760020, acc: 0.367188]\n",
      "2905: [D loss: 0.701014, acc: 0.537109]  [A loss: 0.891505, acc: 0.121094]\n",
      "2906: [D loss: 0.688311, acc: 0.550781]  [A loss: 0.769073, acc: 0.359375]\n",
      "2907: [D loss: 0.704987, acc: 0.515625]  [A loss: 0.880074, acc: 0.160156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2908: [D loss: 0.694217, acc: 0.511719]  [A loss: 0.730969, acc: 0.417969]\n",
      "2909: [D loss: 0.707355, acc: 0.513672]  [A loss: 0.935375, acc: 0.082031]\n",
      "2910: [D loss: 0.690086, acc: 0.542969]  [A loss: 0.716765, acc: 0.457031]\n",
      "2911: [D loss: 0.703781, acc: 0.521484]  [A loss: 0.863967, acc: 0.167969]\n",
      "2912: [D loss: 0.695143, acc: 0.542969]  [A loss: 0.755857, acc: 0.320312]\n",
      "2913: [D loss: 0.695598, acc: 0.544922]  [A loss: 0.912832, acc: 0.128906]\n",
      "2914: [D loss: 0.685088, acc: 0.556641]  [A loss: 0.736782, acc: 0.394531]\n",
      "2915: [D loss: 0.705409, acc: 0.517578]  [A loss: 0.862498, acc: 0.144531]\n",
      "2916: [D loss: 0.678352, acc: 0.558594]  [A loss: 0.818997, acc: 0.250000]\n",
      "2917: [D loss: 0.702819, acc: 0.533203]  [A loss: 0.795745, acc: 0.277344]\n",
      "2918: [D loss: 0.699416, acc: 0.535156]  [A loss: 0.991829, acc: 0.066406]\n",
      "2919: [D loss: 0.701944, acc: 0.503906]  [A loss: 0.673238, acc: 0.539062]\n",
      "2920: [D loss: 0.702949, acc: 0.521484]  [A loss: 0.939225, acc: 0.113281]\n",
      "2921: [D loss: 0.684638, acc: 0.552734]  [A loss: 0.689223, acc: 0.546875]\n",
      "2922: [D loss: 0.708434, acc: 0.517578]  [A loss: 0.911631, acc: 0.093750]\n",
      "2923: [D loss: 0.691004, acc: 0.568359]  [A loss: 0.702740, acc: 0.468750]\n",
      "2924: [D loss: 0.724911, acc: 0.505859]  [A loss: 0.923718, acc: 0.105469]\n",
      "2925: [D loss: 0.692119, acc: 0.539062]  [A loss: 0.705509, acc: 0.484375]\n",
      "2926: [D loss: 0.712368, acc: 0.496094]  [A loss: 0.878504, acc: 0.113281]\n",
      "2927: [D loss: 0.701047, acc: 0.539062]  [A loss: 0.754004, acc: 0.339844]\n",
      "2928: [D loss: 0.715015, acc: 0.488281]  [A loss: 0.872786, acc: 0.160156]\n",
      "2929: [D loss: 0.694643, acc: 0.535156]  [A loss: 0.768131, acc: 0.316406]\n",
      "2930: [D loss: 0.690729, acc: 0.542969]  [A loss: 0.906405, acc: 0.097656]\n",
      "2931: [D loss: 0.683771, acc: 0.564453]  [A loss: 0.752920, acc: 0.332031]\n",
      "2932: [D loss: 0.702170, acc: 0.519531]  [A loss: 0.897464, acc: 0.144531]\n",
      "2933: [D loss: 0.690574, acc: 0.541016]  [A loss: 0.692320, acc: 0.507812]\n",
      "2934: [D loss: 0.721307, acc: 0.505859]  [A loss: 0.983290, acc: 0.062500]\n",
      "2935: [D loss: 0.693769, acc: 0.562500]  [A loss: 0.685544, acc: 0.570312]\n",
      "2936: [D loss: 0.724301, acc: 0.494141]  [A loss: 0.904723, acc: 0.101562]\n",
      "2937: [D loss: 0.698123, acc: 0.517578]  [A loss: 0.747037, acc: 0.367188]\n",
      "2938: [D loss: 0.715583, acc: 0.494141]  [A loss: 0.845101, acc: 0.171875]\n",
      "2939: [D loss: 0.705663, acc: 0.474609]  [A loss: 0.821604, acc: 0.207031]\n",
      "2940: [D loss: 0.699112, acc: 0.544922]  [A loss: 0.811397, acc: 0.238281]\n",
      "2941: [D loss: 0.703434, acc: 0.525391]  [A loss: 0.848680, acc: 0.222656]\n",
      "2942: [D loss: 0.693886, acc: 0.517578]  [A loss: 0.818715, acc: 0.238281]\n",
      "2943: [D loss: 0.702982, acc: 0.523438]  [A loss: 0.756247, acc: 0.363281]\n",
      "2944: [D loss: 0.721945, acc: 0.472656]  [A loss: 0.933372, acc: 0.070312]\n",
      "2945: [D loss: 0.697493, acc: 0.507812]  [A loss: 0.727596, acc: 0.406250]\n",
      "2946: [D loss: 0.703771, acc: 0.509766]  [A loss: 0.865476, acc: 0.148438]\n",
      "2947: [D loss: 0.682577, acc: 0.558594]  [A loss: 0.743348, acc: 0.375000]\n",
      "2948: [D loss: 0.697589, acc: 0.511719]  [A loss: 0.915239, acc: 0.101562]\n",
      "2949: [D loss: 0.698687, acc: 0.529297]  [A loss: 0.754739, acc: 0.343750]\n",
      "2950: [D loss: 0.709418, acc: 0.531250]  [A loss: 0.856477, acc: 0.140625]\n",
      "2951: [D loss: 0.698227, acc: 0.544922]  [A loss: 0.829418, acc: 0.234375]\n",
      "2952: [D loss: 0.698558, acc: 0.542969]  [A loss: 0.830178, acc: 0.210938]\n",
      "2953: [D loss: 0.703763, acc: 0.529297]  [A loss: 0.782781, acc: 0.281250]\n",
      "2954: [D loss: 0.700157, acc: 0.533203]  [A loss: 0.948759, acc: 0.066406]\n",
      "2955: [D loss: 0.689898, acc: 0.550781]  [A loss: 0.711746, acc: 0.488281]\n",
      "2956: [D loss: 0.705320, acc: 0.505859]  [A loss: 0.991427, acc: 0.035156]\n",
      "2957: [D loss: 0.702854, acc: 0.501953]  [A loss: 0.695187, acc: 0.527344]\n",
      "2958: [D loss: 0.692300, acc: 0.511719]  [A loss: 0.909549, acc: 0.109375]\n",
      "2959: [D loss: 0.691130, acc: 0.548828]  [A loss: 0.712057, acc: 0.476562]\n",
      "2960: [D loss: 0.698623, acc: 0.537109]  [A loss: 0.860768, acc: 0.183594]\n",
      "2961: [D loss: 0.702133, acc: 0.484375]  [A loss: 0.774441, acc: 0.355469]\n",
      "2962: [D loss: 0.707159, acc: 0.521484]  [A loss: 0.898317, acc: 0.121094]\n",
      "2963: [D loss: 0.693735, acc: 0.541016]  [A loss: 0.724878, acc: 0.460938]\n",
      "2964: [D loss: 0.704965, acc: 0.527344]  [A loss: 0.884707, acc: 0.164062]\n",
      "2965: [D loss: 0.691393, acc: 0.535156]  [A loss: 0.751667, acc: 0.359375]\n",
      "2966: [D loss: 0.695375, acc: 0.527344]  [A loss: 0.852023, acc: 0.222656]\n",
      "2967: [D loss: 0.713965, acc: 0.521484]  [A loss: 0.806445, acc: 0.226562]\n",
      "2968: [D loss: 0.704165, acc: 0.482422]  [A loss: 0.823795, acc: 0.210938]\n",
      "2969: [D loss: 0.697010, acc: 0.539062]  [A loss: 0.870177, acc: 0.132812]\n",
      "2970: [D loss: 0.684588, acc: 0.564453]  [A loss: 0.750876, acc: 0.414062]\n",
      "2971: [D loss: 0.709594, acc: 0.515625]  [A loss: 0.915257, acc: 0.121094]\n",
      "2972: [D loss: 0.689615, acc: 0.531250]  [A loss: 0.717533, acc: 0.472656]\n",
      "2973: [D loss: 0.713328, acc: 0.525391]  [A loss: 0.896273, acc: 0.148438]\n",
      "2974: [D loss: 0.684735, acc: 0.550781]  [A loss: 0.749359, acc: 0.378906]\n",
      "2975: [D loss: 0.694181, acc: 0.548828]  [A loss: 0.892598, acc: 0.136719]\n",
      "2976: [D loss: 0.685244, acc: 0.560547]  [A loss: 0.698602, acc: 0.550781]\n",
      "2977: [D loss: 0.694834, acc: 0.517578]  [A loss: 0.933645, acc: 0.109375]\n",
      "2978: [D loss: 0.705133, acc: 0.515625]  [A loss: 0.749438, acc: 0.351562]\n",
      "2979: [D loss: 0.700706, acc: 0.541016]  [A loss: 0.864574, acc: 0.191406]\n",
      "2980: [D loss: 0.685085, acc: 0.566406]  [A loss: 0.733002, acc: 0.417969]\n",
      "2981: [D loss: 0.699107, acc: 0.523438]  [A loss: 0.875425, acc: 0.125000]\n",
      "2982: [D loss: 0.681230, acc: 0.560547]  [A loss: 0.788465, acc: 0.316406]\n",
      "2983: [D loss: 0.692464, acc: 0.548828]  [A loss: 0.771692, acc: 0.320312]\n",
      "2984: [D loss: 0.683075, acc: 0.544922]  [A loss: 0.844629, acc: 0.218750]\n",
      "2985: [D loss: 0.701740, acc: 0.500000]  [A loss: 0.805165, acc: 0.265625]\n",
      "2986: [D loss: 0.705960, acc: 0.484375]  [A loss: 0.858916, acc: 0.164062]\n",
      "2987: [D loss: 0.682768, acc: 0.554688]  [A loss: 0.735036, acc: 0.386719]\n",
      "2988: [D loss: 0.692403, acc: 0.542969]  [A loss: 0.918391, acc: 0.097656]\n",
      "2989: [D loss: 0.699125, acc: 0.531250]  [A loss: 0.811019, acc: 0.246094]\n",
      "2990: [D loss: 0.708539, acc: 0.513672]  [A loss: 0.885691, acc: 0.128906]\n",
      "2991: [D loss: 0.710448, acc: 0.496094]  [A loss: 0.880010, acc: 0.160156]\n",
      "2992: [D loss: 0.680002, acc: 0.589844]  [A loss: 0.757191, acc: 0.351562]\n",
      "2993: [D loss: 0.708967, acc: 0.505859]  [A loss: 0.910060, acc: 0.117188]\n",
      "2994: [D loss: 0.687151, acc: 0.533203]  [A loss: 0.755888, acc: 0.359375]\n",
      "2995: [D loss: 0.718278, acc: 0.517578]  [A loss: 1.073397, acc: 0.054688]\n",
      "2996: [D loss: 0.694541, acc: 0.531250]  [A loss: 0.665727, acc: 0.562500]\n",
      "2997: [D loss: 0.718248, acc: 0.519531]  [A loss: 0.931747, acc: 0.113281]\n",
      "2998: [D loss: 0.695232, acc: 0.546875]  [A loss: 0.730428, acc: 0.406250]\n",
      "2999: [D loss: 0.699797, acc: 0.537109]  [A loss: 0.927564, acc: 0.085938]\n",
      "3000: [D loss: 0.691536, acc: 0.531250]  [A loss: 0.729033, acc: 0.417969]\n",
      "3001: [D loss: 0.702976, acc: 0.519531]  [A loss: 0.901917, acc: 0.156250]\n",
      "3002: [D loss: 0.712269, acc: 0.470703]  [A loss: 0.783059, acc: 0.328125]\n",
      "3003: [D loss: 0.699562, acc: 0.527344]  [A loss: 0.880050, acc: 0.140625]\n",
      "3004: [D loss: 0.693057, acc: 0.527344]  [A loss: 0.796460, acc: 0.250000]\n",
      "3005: [D loss: 0.707744, acc: 0.539062]  [A loss: 0.882794, acc: 0.160156]\n",
      "3006: [D loss: 0.693545, acc: 0.537109]  [A loss: 0.750740, acc: 0.363281]\n",
      "3007: [D loss: 0.707198, acc: 0.531250]  [A loss: 0.843326, acc: 0.207031]\n",
      "3008: [D loss: 0.701817, acc: 0.507812]  [A loss: 0.833909, acc: 0.191406]\n",
      "3009: [D loss: 0.692021, acc: 0.535156]  [A loss: 0.843257, acc: 0.195312]\n",
      "3010: [D loss: 0.699958, acc: 0.496094]  [A loss: 0.825203, acc: 0.226562]\n",
      "3011: [D loss: 0.694980, acc: 0.523438]  [A loss: 0.800363, acc: 0.261719]\n",
      "3012: [D loss: 0.697416, acc: 0.513672]  [A loss: 0.816363, acc: 0.246094]\n",
      "3013: [D loss: 0.689615, acc: 0.554688]  [A loss: 0.780650, acc: 0.316406]\n",
      "3014: [D loss: 0.701491, acc: 0.529297]  [A loss: 0.958895, acc: 0.117188]\n",
      "3015: [D loss: 0.692643, acc: 0.525391]  [A loss: 0.686040, acc: 0.531250]\n",
      "3016: [D loss: 0.694667, acc: 0.517578]  [A loss: 0.933363, acc: 0.140625]\n",
      "3017: [D loss: 0.706610, acc: 0.494141]  [A loss: 0.757746, acc: 0.363281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3018: [D loss: 0.703691, acc: 0.515625]  [A loss: 0.951250, acc: 0.066406]\n",
      "3019: [D loss: 0.699797, acc: 0.529297]  [A loss: 0.708902, acc: 0.476562]\n",
      "3020: [D loss: 0.700903, acc: 0.533203]  [A loss: 0.916128, acc: 0.140625]\n",
      "3021: [D loss: 0.693844, acc: 0.519531]  [A loss: 0.730955, acc: 0.453125]\n",
      "3022: [D loss: 0.727676, acc: 0.492188]  [A loss: 0.923425, acc: 0.109375]\n",
      "3023: [D loss: 0.702667, acc: 0.513672]  [A loss: 0.700531, acc: 0.492188]\n",
      "3024: [D loss: 0.721138, acc: 0.517578]  [A loss: 0.927563, acc: 0.070312]\n",
      "3025: [D loss: 0.695605, acc: 0.519531]  [A loss: 0.780243, acc: 0.296875]\n",
      "3026: [D loss: 0.702690, acc: 0.511719]  [A loss: 0.875011, acc: 0.160156]\n",
      "3027: [D loss: 0.681889, acc: 0.570312]  [A loss: 0.761257, acc: 0.332031]\n",
      "3028: [D loss: 0.701148, acc: 0.523438]  [A loss: 0.878368, acc: 0.148438]\n",
      "3029: [D loss: 0.689411, acc: 0.529297]  [A loss: 0.745671, acc: 0.308594]\n",
      "3030: [D loss: 0.712518, acc: 0.498047]  [A loss: 0.949233, acc: 0.105469]\n",
      "3031: [D loss: 0.687338, acc: 0.541016]  [A loss: 0.704425, acc: 0.511719]\n",
      "3032: [D loss: 0.699045, acc: 0.539062]  [A loss: 0.862724, acc: 0.175781]\n",
      "3033: [D loss: 0.692537, acc: 0.529297]  [A loss: 0.750517, acc: 0.386719]\n",
      "3034: [D loss: 0.692217, acc: 0.529297]  [A loss: 0.855918, acc: 0.179688]\n",
      "3035: [D loss: 0.692626, acc: 0.539062]  [A loss: 0.751975, acc: 0.398438]\n",
      "3036: [D loss: 0.707556, acc: 0.515625]  [A loss: 0.890474, acc: 0.164062]\n",
      "3037: [D loss: 0.699499, acc: 0.496094]  [A loss: 0.728694, acc: 0.457031]\n",
      "3038: [D loss: 0.704690, acc: 0.509766]  [A loss: 0.920998, acc: 0.132812]\n",
      "3039: [D loss: 0.696487, acc: 0.537109]  [A loss: 0.764515, acc: 0.355469]\n",
      "3040: [D loss: 0.695452, acc: 0.552734]  [A loss: 0.808489, acc: 0.261719]\n",
      "3041: [D loss: 0.692137, acc: 0.509766]  [A loss: 0.798325, acc: 0.250000]\n",
      "3042: [D loss: 0.692984, acc: 0.533203]  [A loss: 0.802875, acc: 0.257812]\n",
      "3043: [D loss: 0.706992, acc: 0.505859]  [A loss: 0.772713, acc: 0.308594]\n",
      "3044: [D loss: 0.703632, acc: 0.533203]  [A loss: 0.910230, acc: 0.128906]\n",
      "3045: [D loss: 0.705496, acc: 0.509766]  [A loss: 0.752703, acc: 0.390625]\n",
      "3046: [D loss: 0.707436, acc: 0.507812]  [A loss: 0.943101, acc: 0.089844]\n",
      "3047: [D loss: 0.685322, acc: 0.558594]  [A loss: 0.736183, acc: 0.421875]\n",
      "3048: [D loss: 0.701135, acc: 0.525391]  [A loss: 0.918531, acc: 0.136719]\n",
      "3049: [D loss: 0.719958, acc: 0.445312]  [A loss: 0.793995, acc: 0.257812]\n",
      "3050: [D loss: 0.698785, acc: 0.525391]  [A loss: 0.843366, acc: 0.195312]\n",
      "3051: [D loss: 0.697815, acc: 0.521484]  [A loss: 0.823656, acc: 0.230469]\n",
      "3052: [D loss: 0.698425, acc: 0.529297]  [A loss: 0.790444, acc: 0.316406]\n",
      "3053: [D loss: 0.693629, acc: 0.523438]  [A loss: 0.811497, acc: 0.253906]\n",
      "3054: [D loss: 0.696666, acc: 0.523438]  [A loss: 0.749583, acc: 0.367188]\n",
      "3055: [D loss: 0.685568, acc: 0.554688]  [A loss: 0.903387, acc: 0.148438]\n",
      "3056: [D loss: 0.699364, acc: 0.523438]  [A loss: 0.847406, acc: 0.199219]\n",
      "3057: [D loss: 0.702676, acc: 0.529297]  [A loss: 0.820009, acc: 0.242188]\n",
      "3058: [D loss: 0.695403, acc: 0.546875]  [A loss: 0.804383, acc: 0.234375]\n",
      "3059: [D loss: 0.699871, acc: 0.515625]  [A loss: 0.790739, acc: 0.281250]\n",
      "3060: [D loss: 0.685905, acc: 0.544922]  [A loss: 0.788347, acc: 0.320312]\n",
      "3061: [D loss: 0.709823, acc: 0.519531]  [A loss: 0.851501, acc: 0.183594]\n",
      "3062: [D loss: 0.714432, acc: 0.505859]  [A loss: 0.996470, acc: 0.042969]\n",
      "3063: [D loss: 0.685755, acc: 0.566406]  [A loss: 0.671340, acc: 0.578125]\n",
      "3064: [D loss: 0.714954, acc: 0.521484]  [A loss: 0.941274, acc: 0.074219]\n",
      "3065: [D loss: 0.691520, acc: 0.511719]  [A loss: 0.685032, acc: 0.527344]\n",
      "3066: [D loss: 0.708335, acc: 0.515625]  [A loss: 0.930769, acc: 0.125000]\n",
      "3067: [D loss: 0.698528, acc: 0.533203]  [A loss: 0.742872, acc: 0.386719]\n",
      "3068: [D loss: 0.696867, acc: 0.544922]  [A loss: 0.853932, acc: 0.187500]\n",
      "3069: [D loss: 0.695837, acc: 0.531250]  [A loss: 0.759503, acc: 0.371094]\n",
      "3070: [D loss: 0.701262, acc: 0.517578]  [A loss: 0.833264, acc: 0.222656]\n",
      "3071: [D loss: 0.691814, acc: 0.529297]  [A loss: 0.791834, acc: 0.273438]\n",
      "3072: [D loss: 0.698004, acc: 0.496094]  [A loss: 0.863641, acc: 0.164062]\n",
      "3073: [D loss: 0.687676, acc: 0.562500]  [A loss: 0.821858, acc: 0.273438]\n",
      "3074: [D loss: 0.697303, acc: 0.539062]  [A loss: 0.766847, acc: 0.328125]\n",
      "3075: [D loss: 0.692349, acc: 0.527344]  [A loss: 0.856937, acc: 0.179688]\n",
      "3076: [D loss: 0.688326, acc: 0.550781]  [A loss: 0.781426, acc: 0.304688]\n",
      "3077: [D loss: 0.696850, acc: 0.539062]  [A loss: 0.895298, acc: 0.140625]\n",
      "3078: [D loss: 0.687458, acc: 0.552734]  [A loss: 0.705628, acc: 0.457031]\n",
      "3079: [D loss: 0.701636, acc: 0.523438]  [A loss: 0.959670, acc: 0.117188]\n",
      "3080: [D loss: 0.717000, acc: 0.486328]  [A loss: 0.749580, acc: 0.386719]\n",
      "3081: [D loss: 0.687665, acc: 0.552734]  [A loss: 0.920340, acc: 0.125000]\n",
      "3082: [D loss: 0.682183, acc: 0.572266]  [A loss: 0.696631, acc: 0.531250]\n",
      "3083: [D loss: 0.703705, acc: 0.523438]  [A loss: 0.916039, acc: 0.093750]\n",
      "3084: [D loss: 0.679428, acc: 0.544922]  [A loss: 0.772131, acc: 0.343750]\n",
      "3085: [D loss: 0.688220, acc: 0.550781]  [A loss: 0.848316, acc: 0.210938]\n",
      "3086: [D loss: 0.679532, acc: 0.564453]  [A loss: 0.836661, acc: 0.234375]\n",
      "3087: [D loss: 0.697009, acc: 0.527344]  [A loss: 0.889256, acc: 0.156250]\n",
      "3088: [D loss: 0.689609, acc: 0.548828]  [A loss: 0.773282, acc: 0.324219]\n",
      "3089: [D loss: 0.693265, acc: 0.529297]  [A loss: 0.943323, acc: 0.082031]\n",
      "3090: [D loss: 0.688833, acc: 0.531250]  [A loss: 0.848738, acc: 0.207031]\n",
      "3091: [D loss: 0.692071, acc: 0.544922]  [A loss: 0.886153, acc: 0.195312]\n",
      "3092: [D loss: 0.690444, acc: 0.562500]  [A loss: 0.754419, acc: 0.390625]\n",
      "3093: [D loss: 0.684490, acc: 0.578125]  [A loss: 0.918679, acc: 0.148438]\n",
      "3094: [D loss: 0.689651, acc: 0.533203]  [A loss: 0.760842, acc: 0.351562]\n",
      "3095: [D loss: 0.710202, acc: 0.494141]  [A loss: 0.988193, acc: 0.085938]\n",
      "3096: [D loss: 0.705656, acc: 0.505859]  [A loss: 0.651289, acc: 0.652344]\n",
      "3097: [D loss: 0.724040, acc: 0.498047]  [A loss: 0.920656, acc: 0.125000]\n",
      "3098: [D loss: 0.704212, acc: 0.507812]  [A loss: 0.787089, acc: 0.316406]\n",
      "3099: [D loss: 0.712619, acc: 0.503906]  [A loss: 0.827515, acc: 0.253906]\n",
      "3100: [D loss: 0.713711, acc: 0.507812]  [A loss: 0.860363, acc: 0.160156]\n",
      "3101: [D loss: 0.700812, acc: 0.501953]  [A loss: 0.720593, acc: 0.460938]\n",
      "3102: [D loss: 0.711566, acc: 0.492188]  [A loss: 0.847195, acc: 0.203125]\n",
      "3103: [D loss: 0.696214, acc: 0.525391]  [A loss: 0.790850, acc: 0.285156]\n",
      "3104: [D loss: 0.694307, acc: 0.539062]  [A loss: 0.877477, acc: 0.179688]\n",
      "3105: [D loss: 0.687777, acc: 0.525391]  [A loss: 0.742704, acc: 0.378906]\n",
      "3106: [D loss: 0.703373, acc: 0.503906]  [A loss: 0.915200, acc: 0.121094]\n",
      "3107: [D loss: 0.697039, acc: 0.525391]  [A loss: 0.705768, acc: 0.515625]\n",
      "3108: [D loss: 0.696734, acc: 0.556641]  [A loss: 0.874311, acc: 0.160156]\n",
      "3109: [D loss: 0.693408, acc: 0.531250]  [A loss: 0.760497, acc: 0.398438]\n",
      "3110: [D loss: 0.700419, acc: 0.515625]  [A loss: 0.853889, acc: 0.207031]\n",
      "3111: [D loss: 0.689567, acc: 0.527344]  [A loss: 0.808019, acc: 0.289062]\n",
      "3112: [D loss: 0.690854, acc: 0.525391]  [A loss: 0.825824, acc: 0.222656]\n",
      "3113: [D loss: 0.712656, acc: 0.494141]  [A loss: 0.890603, acc: 0.144531]\n",
      "3114: [D loss: 0.680871, acc: 0.552734]  [A loss: 0.715513, acc: 0.480469]\n",
      "3115: [D loss: 0.718029, acc: 0.537109]  [A loss: 0.974651, acc: 0.066406]\n",
      "3116: [D loss: 0.696156, acc: 0.529297]  [A loss: 0.671889, acc: 0.601562]\n",
      "3117: [D loss: 0.711159, acc: 0.513672]  [A loss: 0.937921, acc: 0.093750]\n",
      "3118: [D loss: 0.702277, acc: 0.527344]  [A loss: 0.682077, acc: 0.570312]\n",
      "3119: [D loss: 0.722919, acc: 0.513672]  [A loss: 0.896481, acc: 0.132812]\n",
      "3120: [D loss: 0.702155, acc: 0.486328]  [A loss: 0.771459, acc: 0.335938]\n",
      "3121: [D loss: 0.703795, acc: 0.521484]  [A loss: 0.861524, acc: 0.171875]\n",
      "3122: [D loss: 0.691904, acc: 0.525391]  [A loss: 0.776137, acc: 0.324219]\n",
      "3123: [D loss: 0.696271, acc: 0.564453]  [A loss: 0.902613, acc: 0.121094]\n",
      "3124: [D loss: 0.698603, acc: 0.501953]  [A loss: 0.776217, acc: 0.320312]\n",
      "3125: [D loss: 0.712740, acc: 0.484375]  [A loss: 0.828493, acc: 0.246094]\n",
      "3126: [D loss: 0.707968, acc: 0.482422]  [A loss: 0.724445, acc: 0.492188]\n",
      "3127: [D loss: 0.695316, acc: 0.541016]  [A loss: 0.853531, acc: 0.191406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3128: [D loss: 0.691603, acc: 0.525391]  [A loss: 0.806602, acc: 0.230469]\n",
      "3129: [D loss: 0.692527, acc: 0.541016]  [A loss: 0.824105, acc: 0.234375]\n",
      "3130: [D loss: 0.692263, acc: 0.541016]  [A loss: 0.909688, acc: 0.164062]\n",
      "3131: [D loss: 0.687737, acc: 0.531250]  [A loss: 0.740680, acc: 0.441406]\n",
      "3132: [D loss: 0.712246, acc: 0.503906]  [A loss: 0.875893, acc: 0.152344]\n",
      "3133: [D loss: 0.695856, acc: 0.515625]  [A loss: 0.809821, acc: 0.214844]\n",
      "3134: [D loss: 0.700249, acc: 0.501953]  [A loss: 0.830872, acc: 0.210938]\n",
      "3135: [D loss: 0.707071, acc: 0.486328]  [A loss: 0.836192, acc: 0.214844]\n",
      "3136: [D loss: 0.678634, acc: 0.560547]  [A loss: 0.847903, acc: 0.285156]\n",
      "3137: [D loss: 0.701647, acc: 0.527344]  [A loss: 0.861361, acc: 0.210938]\n",
      "3138: [D loss: 0.701765, acc: 0.513672]  [A loss: 0.821076, acc: 0.226562]\n",
      "3139: [D loss: 0.708591, acc: 0.531250]  [A loss: 0.811954, acc: 0.273438]\n",
      "3140: [D loss: 0.693518, acc: 0.527344]  [A loss: 0.760480, acc: 0.335938]\n",
      "3141: [D loss: 0.703302, acc: 0.535156]  [A loss: 0.891905, acc: 0.207031]\n",
      "3142: [D loss: 0.702969, acc: 0.527344]  [A loss: 0.739607, acc: 0.402344]\n",
      "3143: [D loss: 0.703173, acc: 0.496094]  [A loss: 0.963194, acc: 0.078125]\n",
      "3144: [D loss: 0.684381, acc: 0.541016]  [A loss: 0.680210, acc: 0.542969]\n",
      "3145: [D loss: 0.705189, acc: 0.535156]  [A loss: 0.931187, acc: 0.113281]\n",
      "3146: [D loss: 0.704004, acc: 0.525391]  [A loss: 0.753712, acc: 0.339844]\n",
      "3147: [D loss: 0.689721, acc: 0.521484]  [A loss: 0.814949, acc: 0.261719]\n",
      "3148: [D loss: 0.676538, acc: 0.587891]  [A loss: 0.791882, acc: 0.328125]\n",
      "3149: [D loss: 0.680011, acc: 0.550781]  [A loss: 0.854729, acc: 0.226562]\n",
      "3150: [D loss: 0.699284, acc: 0.517578]  [A loss: 0.760596, acc: 0.375000]\n",
      "3151: [D loss: 0.726417, acc: 0.503906]  [A loss: 0.976091, acc: 0.093750]\n",
      "3152: [D loss: 0.678269, acc: 0.564453]  [A loss: 0.685759, acc: 0.562500]\n",
      "3153: [D loss: 0.700285, acc: 0.541016]  [A loss: 0.860443, acc: 0.175781]\n",
      "3154: [D loss: 0.684108, acc: 0.554688]  [A loss: 0.761186, acc: 0.367188]\n",
      "3155: [D loss: 0.699534, acc: 0.537109]  [A loss: 0.933891, acc: 0.128906]\n",
      "3156: [D loss: 0.687305, acc: 0.537109]  [A loss: 0.688811, acc: 0.531250]\n",
      "3157: [D loss: 0.723834, acc: 0.509766]  [A loss: 0.932890, acc: 0.117188]\n",
      "3158: [D loss: 0.701093, acc: 0.533203]  [A loss: 0.698887, acc: 0.476562]\n",
      "3159: [D loss: 0.718108, acc: 0.492188]  [A loss: 0.864769, acc: 0.171875]\n",
      "3160: [D loss: 0.706973, acc: 0.511719]  [A loss: 0.747359, acc: 0.332031]\n",
      "3161: [D loss: 0.704029, acc: 0.501953]  [A loss: 0.852042, acc: 0.175781]\n",
      "3162: [D loss: 0.696309, acc: 0.517578]  [A loss: 0.732973, acc: 0.457031]\n",
      "3163: [D loss: 0.703769, acc: 0.527344]  [A loss: 0.870640, acc: 0.179688]\n",
      "3164: [D loss: 0.691416, acc: 0.535156]  [A loss: 0.742698, acc: 0.394531]\n",
      "3165: [D loss: 0.728389, acc: 0.517578]  [A loss: 1.008074, acc: 0.039062]\n",
      "3166: [D loss: 0.689093, acc: 0.527344]  [A loss: 0.711020, acc: 0.464844]\n",
      "3167: [D loss: 0.700552, acc: 0.513672]  [A loss: 0.857280, acc: 0.222656]\n",
      "3168: [D loss: 0.704137, acc: 0.500000]  [A loss: 0.830773, acc: 0.250000]\n",
      "3169: [D loss: 0.683794, acc: 0.552734]  [A loss: 0.783841, acc: 0.328125]\n",
      "3170: [D loss: 0.703149, acc: 0.513672]  [A loss: 0.934640, acc: 0.089844]\n",
      "3171: [D loss: 0.683672, acc: 0.548828]  [A loss: 0.745521, acc: 0.375000]\n",
      "3172: [D loss: 0.695133, acc: 0.546875]  [A loss: 0.849265, acc: 0.207031]\n",
      "3173: [D loss: 0.715187, acc: 0.478516]  [A loss: 0.797939, acc: 0.300781]\n",
      "3174: [D loss: 0.710425, acc: 0.529297]  [A loss: 0.921651, acc: 0.097656]\n",
      "3175: [D loss: 0.688167, acc: 0.550781]  [A loss: 0.727756, acc: 0.480469]\n",
      "3176: [D loss: 0.707726, acc: 0.525391]  [A loss: 0.891908, acc: 0.136719]\n",
      "3177: [D loss: 0.690636, acc: 0.546875]  [A loss: 0.793321, acc: 0.320312]\n",
      "3178: [D loss: 0.696329, acc: 0.542969]  [A loss: 0.829276, acc: 0.242188]\n",
      "3179: [D loss: 0.692019, acc: 0.541016]  [A loss: 0.857822, acc: 0.144531]\n",
      "3180: [D loss: 0.680124, acc: 0.570312]  [A loss: 0.787566, acc: 0.324219]\n",
      "3181: [D loss: 0.684812, acc: 0.550781]  [A loss: 0.925644, acc: 0.132812]\n",
      "3182: [D loss: 0.717591, acc: 0.484375]  [A loss: 0.665614, acc: 0.570312]\n",
      "3183: [D loss: 0.737935, acc: 0.513672]  [A loss: 1.054997, acc: 0.019531]\n",
      "3184: [D loss: 0.707194, acc: 0.503906]  [A loss: 0.658950, acc: 0.593750]\n",
      "3185: [D loss: 0.742206, acc: 0.496094]  [A loss: 0.879527, acc: 0.164062]\n",
      "3186: [D loss: 0.691769, acc: 0.546875]  [A loss: 0.788308, acc: 0.285156]\n",
      "3187: [D loss: 0.685803, acc: 0.560547]  [A loss: 0.788229, acc: 0.261719]\n",
      "3188: [D loss: 0.702497, acc: 0.519531]  [A loss: 0.816682, acc: 0.250000]\n",
      "3189: [D loss: 0.699189, acc: 0.550781]  [A loss: 0.839462, acc: 0.195312]\n",
      "3190: [D loss: 0.695977, acc: 0.531250]  [A loss: 0.779766, acc: 0.312500]\n",
      "3191: [D loss: 0.706025, acc: 0.505859]  [A loss: 0.851188, acc: 0.171875]\n",
      "3192: [D loss: 0.692875, acc: 0.525391]  [A loss: 0.807412, acc: 0.289062]\n",
      "3193: [D loss: 0.704397, acc: 0.505859]  [A loss: 0.847691, acc: 0.214844]\n",
      "3194: [D loss: 0.693226, acc: 0.552734]  [A loss: 0.818786, acc: 0.214844]\n",
      "3195: [D loss: 0.689993, acc: 0.533203]  [A loss: 0.867142, acc: 0.199219]\n",
      "3196: [D loss: 0.699800, acc: 0.496094]  [A loss: 0.767672, acc: 0.359375]\n",
      "3197: [D loss: 0.705707, acc: 0.488281]  [A loss: 0.869303, acc: 0.152344]\n",
      "3198: [D loss: 0.695656, acc: 0.533203]  [A loss: 0.732256, acc: 0.453125]\n",
      "3199: [D loss: 0.706984, acc: 0.527344]  [A loss: 0.881864, acc: 0.167969]\n",
      "3200: [D loss: 0.698211, acc: 0.519531]  [A loss: 0.709319, acc: 0.484375]\n",
      "3201: [D loss: 0.705715, acc: 0.527344]  [A loss: 0.894569, acc: 0.156250]\n",
      "3202: [D loss: 0.699892, acc: 0.527344]  [A loss: 0.706976, acc: 0.472656]\n",
      "3203: [D loss: 0.709574, acc: 0.517578]  [A loss: 0.904170, acc: 0.175781]\n",
      "3204: [D loss: 0.687545, acc: 0.552734]  [A loss: 0.734882, acc: 0.410156]\n",
      "3205: [D loss: 0.708652, acc: 0.521484]  [A loss: 0.870353, acc: 0.175781]\n",
      "3206: [D loss: 0.699309, acc: 0.513672]  [A loss: 0.828943, acc: 0.218750]\n",
      "3207: [D loss: 0.690841, acc: 0.537109]  [A loss: 0.742521, acc: 0.414062]\n",
      "3208: [D loss: 0.714426, acc: 0.517578]  [A loss: 0.930275, acc: 0.121094]\n",
      "3209: [D loss: 0.696910, acc: 0.517578]  [A loss: 0.747725, acc: 0.386719]\n",
      "3210: [D loss: 0.718524, acc: 0.509766]  [A loss: 0.932270, acc: 0.117188]\n",
      "3211: [D loss: 0.703312, acc: 0.511719]  [A loss: 0.715968, acc: 0.460938]\n",
      "3212: [D loss: 0.706665, acc: 0.509766]  [A loss: 0.939635, acc: 0.117188]\n",
      "3213: [D loss: 0.684828, acc: 0.572266]  [A loss: 0.739553, acc: 0.402344]\n",
      "3214: [D loss: 0.693230, acc: 0.541016]  [A loss: 0.859364, acc: 0.179688]\n",
      "3215: [D loss: 0.694787, acc: 0.515625]  [A loss: 0.723704, acc: 0.492188]\n",
      "3216: [D loss: 0.702768, acc: 0.539062]  [A loss: 0.882993, acc: 0.187500]\n",
      "3217: [D loss: 0.695857, acc: 0.521484]  [A loss: 0.798500, acc: 0.296875]\n",
      "3218: [D loss: 0.705697, acc: 0.515625]  [A loss: 0.958832, acc: 0.105469]\n",
      "3219: [D loss: 0.696237, acc: 0.517578]  [A loss: 0.687696, acc: 0.539062]\n",
      "3220: [D loss: 0.719512, acc: 0.511719]  [A loss: 0.943525, acc: 0.128906]\n",
      "3221: [D loss: 0.702794, acc: 0.488281]  [A loss: 0.730232, acc: 0.402344]\n",
      "3222: [D loss: 0.713793, acc: 0.515625]  [A loss: 0.871736, acc: 0.179688]\n",
      "3223: [D loss: 0.681542, acc: 0.548828]  [A loss: 0.732751, acc: 0.394531]\n",
      "3224: [D loss: 0.702391, acc: 0.515625]  [A loss: 0.905344, acc: 0.148438]\n",
      "3225: [D loss: 0.688839, acc: 0.539062]  [A loss: 0.710373, acc: 0.519531]\n",
      "3226: [D loss: 0.707530, acc: 0.539062]  [A loss: 0.944983, acc: 0.101562]\n",
      "3227: [D loss: 0.702402, acc: 0.503906]  [A loss: 0.746002, acc: 0.363281]\n",
      "3228: [D loss: 0.710184, acc: 0.501953]  [A loss: 0.885439, acc: 0.132812]\n",
      "3229: [D loss: 0.690164, acc: 0.513672]  [A loss: 0.711659, acc: 0.468750]\n",
      "3230: [D loss: 0.716790, acc: 0.494141]  [A loss: 0.849485, acc: 0.230469]\n",
      "3231: [D loss: 0.709016, acc: 0.496094]  [A loss: 0.769942, acc: 0.332031]\n",
      "3232: [D loss: 0.707024, acc: 0.542969]  [A loss: 0.910358, acc: 0.117188]\n",
      "3233: [D loss: 0.687141, acc: 0.552734]  [A loss: 0.779134, acc: 0.335938]\n",
      "3234: [D loss: 0.713214, acc: 0.484375]  [A loss: 0.821530, acc: 0.246094]\n",
      "3235: [D loss: 0.689682, acc: 0.525391]  [A loss: 0.856106, acc: 0.156250]\n",
      "3236: [D loss: 0.707806, acc: 0.498047]  [A loss: 0.783017, acc: 0.312500]\n",
      "3237: [D loss: 0.705407, acc: 0.535156]  [A loss: 0.864199, acc: 0.136719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238: [D loss: 0.688407, acc: 0.585938]  [A loss: 0.751636, acc: 0.359375]\n",
      "3239: [D loss: 0.698740, acc: 0.562500]  [A loss: 0.924761, acc: 0.125000]\n",
      "3240: [D loss: 0.690811, acc: 0.527344]  [A loss: 0.761334, acc: 0.351562]\n",
      "3241: [D loss: 0.704655, acc: 0.537109]  [A loss: 0.917524, acc: 0.097656]\n",
      "3242: [D loss: 0.688566, acc: 0.556641]  [A loss: 0.784980, acc: 0.328125]\n",
      "3243: [D loss: 0.692694, acc: 0.552734]  [A loss: 0.953478, acc: 0.105469]\n",
      "3244: [D loss: 0.696643, acc: 0.531250]  [A loss: 0.712943, acc: 0.480469]\n",
      "3245: [D loss: 0.704294, acc: 0.544922]  [A loss: 0.901809, acc: 0.140625]\n",
      "3246: [D loss: 0.691087, acc: 0.546875]  [A loss: 0.742336, acc: 0.406250]\n",
      "3247: [D loss: 0.695628, acc: 0.542969]  [A loss: 0.904000, acc: 0.140625]\n",
      "3248: [D loss: 0.685180, acc: 0.605469]  [A loss: 0.780945, acc: 0.300781]\n",
      "3249: [D loss: 0.710397, acc: 0.501953]  [A loss: 0.912293, acc: 0.132812]\n",
      "3250: [D loss: 0.710120, acc: 0.507812]  [A loss: 0.737722, acc: 0.390625]\n",
      "3251: [D loss: 0.709197, acc: 0.519531]  [A loss: 1.006562, acc: 0.058594]\n",
      "3252: [D loss: 0.700096, acc: 0.527344]  [A loss: 0.659542, acc: 0.597656]\n",
      "3253: [D loss: 0.704948, acc: 0.542969]  [A loss: 0.868186, acc: 0.179688]\n",
      "3254: [D loss: 0.680607, acc: 0.568359]  [A loss: 0.743340, acc: 0.410156]\n",
      "3255: [D loss: 0.698863, acc: 0.539062]  [A loss: 0.860030, acc: 0.144531]\n",
      "3256: [D loss: 0.692228, acc: 0.560547]  [A loss: 0.791954, acc: 0.312500]\n",
      "3257: [D loss: 0.694447, acc: 0.531250]  [A loss: 0.789983, acc: 0.332031]\n",
      "3258: [D loss: 0.704885, acc: 0.509766]  [A loss: 0.879950, acc: 0.160156]\n",
      "3259: [D loss: 0.702395, acc: 0.509766]  [A loss: 0.756060, acc: 0.355469]\n",
      "3260: [D loss: 0.701437, acc: 0.517578]  [A loss: 0.910739, acc: 0.113281]\n",
      "3261: [D loss: 0.692133, acc: 0.529297]  [A loss: 0.787745, acc: 0.304688]\n",
      "3262: [D loss: 0.694750, acc: 0.533203]  [A loss: 0.836618, acc: 0.238281]\n",
      "3263: [D loss: 0.702313, acc: 0.507812]  [A loss: 0.775745, acc: 0.316406]\n",
      "3264: [D loss: 0.706974, acc: 0.488281]  [A loss: 1.051377, acc: 0.042969]\n",
      "3265: [D loss: 0.706215, acc: 0.494141]  [A loss: 0.626950, acc: 0.722656]\n",
      "3266: [D loss: 0.750202, acc: 0.501953]  [A loss: 0.978072, acc: 0.054688]\n",
      "3267: [D loss: 0.691728, acc: 0.539062]  [A loss: 0.696785, acc: 0.511719]\n",
      "3268: [D loss: 0.705842, acc: 0.500000]  [A loss: 0.816480, acc: 0.250000]\n",
      "3269: [D loss: 0.693112, acc: 0.535156]  [A loss: 0.772295, acc: 0.339844]\n",
      "3270: [D loss: 0.688057, acc: 0.568359]  [A loss: 0.829863, acc: 0.246094]\n",
      "3271: [D loss: 0.701986, acc: 0.517578]  [A loss: 0.803594, acc: 0.281250]\n",
      "3272: [D loss: 0.681685, acc: 0.546875]  [A loss: 0.799397, acc: 0.253906]\n",
      "3273: [D loss: 0.678124, acc: 0.578125]  [A loss: 0.840618, acc: 0.218750]\n",
      "3274: [D loss: 0.689057, acc: 0.558594]  [A loss: 0.845508, acc: 0.218750]\n",
      "3275: [D loss: 0.697345, acc: 0.521484]  [A loss: 0.890377, acc: 0.121094]\n",
      "3276: [D loss: 0.696508, acc: 0.523438]  [A loss: 0.775393, acc: 0.324219]\n",
      "3277: [D loss: 0.704966, acc: 0.494141]  [A loss: 0.857042, acc: 0.187500]\n",
      "3278: [D loss: 0.690782, acc: 0.552734]  [A loss: 0.794111, acc: 0.277344]\n",
      "3279: [D loss: 0.686687, acc: 0.554688]  [A loss: 0.839878, acc: 0.222656]\n",
      "3280: [D loss: 0.701937, acc: 0.529297]  [A loss: 0.811571, acc: 0.273438]\n",
      "3281: [D loss: 0.710812, acc: 0.496094]  [A loss: 0.827354, acc: 0.226562]\n",
      "3282: [D loss: 0.699406, acc: 0.544922]  [A loss: 0.968423, acc: 0.070312]\n",
      "3283: [D loss: 0.709970, acc: 0.484375]  [A loss: 0.718809, acc: 0.449219]\n",
      "3284: [D loss: 0.723306, acc: 0.478516]  [A loss: 0.941750, acc: 0.082031]\n",
      "3285: [D loss: 0.697550, acc: 0.539062]  [A loss: 0.784783, acc: 0.320312]\n",
      "3286: [D loss: 0.710469, acc: 0.513672]  [A loss: 0.880050, acc: 0.160156]\n",
      "3287: [D loss: 0.688877, acc: 0.548828]  [A loss: 0.790107, acc: 0.296875]\n",
      "3288: [D loss: 0.696925, acc: 0.544922]  [A loss: 0.840226, acc: 0.242188]\n",
      "3289: [D loss: 0.690955, acc: 0.560547]  [A loss: 0.782371, acc: 0.332031]\n",
      "3290: [D loss: 0.717236, acc: 0.498047]  [A loss: 0.867146, acc: 0.187500]\n",
      "3291: [D loss: 0.689312, acc: 0.537109]  [A loss: 0.830210, acc: 0.183594]\n",
      "3292: [D loss: 0.682448, acc: 0.578125]  [A loss: 0.879696, acc: 0.187500]\n",
      "3293: [D loss: 0.693829, acc: 0.539062]  [A loss: 0.843523, acc: 0.226562]\n",
      "3294: [D loss: 0.697864, acc: 0.539062]  [A loss: 1.027514, acc: 0.058594]\n",
      "3295: [D loss: 0.686064, acc: 0.539062]  [A loss: 0.647030, acc: 0.640625]\n",
      "3296: [D loss: 0.736422, acc: 0.509766]  [A loss: 0.951111, acc: 0.097656]\n",
      "3297: [D loss: 0.690175, acc: 0.544922]  [A loss: 0.698127, acc: 0.511719]\n",
      "3298: [D loss: 0.718298, acc: 0.503906]  [A loss: 0.976114, acc: 0.085938]\n",
      "3299: [D loss: 0.704629, acc: 0.517578]  [A loss: 0.702806, acc: 0.480469]\n",
      "3300: [D loss: 0.716046, acc: 0.525391]  [A loss: 0.909015, acc: 0.156250]\n",
      "3301: [D loss: 0.694101, acc: 0.515625]  [A loss: 0.766804, acc: 0.343750]\n",
      "3302: [D loss: 0.715752, acc: 0.486328]  [A loss: 0.849577, acc: 0.199219]\n",
      "3303: [D loss: 0.693042, acc: 0.509766]  [A loss: 0.796388, acc: 0.277344]\n",
      "3304: [D loss: 0.697256, acc: 0.529297]  [A loss: 0.862735, acc: 0.171875]\n",
      "3305: [D loss: 0.695316, acc: 0.542969]  [A loss: 0.794116, acc: 0.273438]\n",
      "3306: [D loss: 0.694827, acc: 0.527344]  [A loss: 0.927912, acc: 0.128906]\n",
      "3307: [D loss: 0.693826, acc: 0.531250]  [A loss: 0.782040, acc: 0.347656]\n",
      "3308: [D loss: 0.705985, acc: 0.511719]  [A loss: 0.969150, acc: 0.117188]\n",
      "3309: [D loss: 0.692999, acc: 0.525391]  [A loss: 0.735121, acc: 0.429688]\n",
      "3310: [D loss: 0.707910, acc: 0.521484]  [A loss: 0.911347, acc: 0.140625]\n",
      "3311: [D loss: 0.710788, acc: 0.509766]  [A loss: 0.741308, acc: 0.410156]\n",
      "3312: [D loss: 0.701070, acc: 0.531250]  [A loss: 0.952424, acc: 0.097656]\n",
      "3313: [D loss: 0.694563, acc: 0.511719]  [A loss: 0.730712, acc: 0.457031]\n",
      "3314: [D loss: 0.717040, acc: 0.507812]  [A loss: 0.995374, acc: 0.066406]\n",
      "3315: [D loss: 0.691923, acc: 0.519531]  [A loss: 0.702418, acc: 0.496094]\n",
      "3316: [D loss: 0.706357, acc: 0.531250]  [A loss: 0.918913, acc: 0.117188]\n",
      "3317: [D loss: 0.693026, acc: 0.531250]  [A loss: 0.785756, acc: 0.289062]\n",
      "3318: [D loss: 0.699967, acc: 0.509766]  [A loss: 0.830572, acc: 0.261719]\n",
      "3319: [D loss: 0.695326, acc: 0.564453]  [A loss: 0.810008, acc: 0.273438]\n",
      "3320: [D loss: 0.686107, acc: 0.562500]  [A loss: 0.877746, acc: 0.183594]\n",
      "3321: [D loss: 0.685117, acc: 0.566406]  [A loss: 0.731494, acc: 0.410156]\n",
      "3322: [D loss: 0.708034, acc: 0.513672]  [A loss: 0.947715, acc: 0.097656]\n",
      "3323: [D loss: 0.693876, acc: 0.548828]  [A loss: 0.690779, acc: 0.511719]\n",
      "3324: [D loss: 0.725286, acc: 0.509766]  [A loss: 0.939666, acc: 0.089844]\n",
      "3325: [D loss: 0.695079, acc: 0.529297]  [A loss: 0.795234, acc: 0.316406]\n",
      "3326: [D loss: 0.702458, acc: 0.519531]  [A loss: 0.824785, acc: 0.218750]\n",
      "3327: [D loss: 0.697579, acc: 0.513672]  [A loss: 0.818561, acc: 0.246094]\n",
      "3328: [D loss: 0.671312, acc: 0.595703]  [A loss: 0.794527, acc: 0.292969]\n",
      "3329: [D loss: 0.708197, acc: 0.542969]  [A loss: 0.851159, acc: 0.250000]\n",
      "3330: [D loss: 0.697918, acc: 0.519531]  [A loss: 0.782961, acc: 0.281250]\n",
      "3331: [D loss: 0.688698, acc: 0.546875]  [A loss: 0.936751, acc: 0.117188]\n",
      "3332: [D loss: 0.681843, acc: 0.554688]  [A loss: 0.750409, acc: 0.386719]\n",
      "3333: [D loss: 0.725838, acc: 0.515625]  [A loss: 0.968549, acc: 0.093750]\n",
      "3334: [D loss: 0.693805, acc: 0.535156]  [A loss: 0.777401, acc: 0.316406]\n",
      "3335: [D loss: 0.697726, acc: 0.523438]  [A loss: 0.860482, acc: 0.191406]\n",
      "3336: [D loss: 0.696572, acc: 0.531250]  [A loss: 0.745723, acc: 0.398438]\n",
      "3337: [D loss: 0.713048, acc: 0.521484]  [A loss: 0.948833, acc: 0.105469]\n",
      "3338: [D loss: 0.700705, acc: 0.478516]  [A loss: 0.666321, acc: 0.550781]\n",
      "3339: [D loss: 0.752037, acc: 0.484375]  [A loss: 1.073191, acc: 0.023438]\n",
      "3340: [D loss: 0.709979, acc: 0.498047]  [A loss: 0.704009, acc: 0.480469]\n",
      "3341: [D loss: 0.727968, acc: 0.535156]  [A loss: 0.804638, acc: 0.277344]\n",
      "3342: [D loss: 0.706838, acc: 0.531250]  [A loss: 0.886423, acc: 0.132812]\n",
      "3343: [D loss: 0.694811, acc: 0.525391]  [A loss: 0.773910, acc: 0.328125]\n",
      "3344: [D loss: 0.703605, acc: 0.541016]  [A loss: 0.799900, acc: 0.265625]\n",
      "3345: [D loss: 0.705490, acc: 0.523438]  [A loss: 0.864223, acc: 0.207031]\n",
      "3346: [D loss: 0.693284, acc: 0.560547]  [A loss: 0.747444, acc: 0.394531]\n",
      "3347: [D loss: 0.703117, acc: 0.515625]  [A loss: 0.843850, acc: 0.250000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3348: [D loss: 0.708663, acc: 0.482422]  [A loss: 0.803385, acc: 0.273438]\n",
      "3349: [D loss: 0.697022, acc: 0.511719]  [A loss: 0.840238, acc: 0.246094]\n",
      "3350: [D loss: 0.697261, acc: 0.541016]  [A loss: 0.839232, acc: 0.214844]\n",
      "3351: [D loss: 0.681458, acc: 0.568359]  [A loss: 0.785544, acc: 0.324219]\n",
      "3352: [D loss: 0.703072, acc: 0.519531]  [A loss: 0.857800, acc: 0.222656]\n",
      "3353: [D loss: 0.687641, acc: 0.542969]  [A loss: 0.832477, acc: 0.199219]\n",
      "3354: [D loss: 0.694862, acc: 0.507812]  [A loss: 0.751247, acc: 0.386719]\n",
      "3355: [D loss: 0.694000, acc: 0.544922]  [A loss: 0.892926, acc: 0.132812]\n",
      "3356: [D loss: 0.698384, acc: 0.535156]  [A loss: 0.802209, acc: 0.265625]\n",
      "3357: [D loss: 0.709473, acc: 0.505859]  [A loss: 0.896117, acc: 0.175781]\n",
      "3358: [D loss: 0.698691, acc: 0.500000]  [A loss: 0.694035, acc: 0.527344]\n",
      "3359: [D loss: 0.702023, acc: 0.535156]  [A loss: 0.977074, acc: 0.078125]\n",
      "3360: [D loss: 0.684659, acc: 0.556641]  [A loss: 0.706611, acc: 0.472656]\n",
      "3361: [D loss: 0.715427, acc: 0.505859]  [A loss: 0.895277, acc: 0.160156]\n",
      "3362: [D loss: 0.701615, acc: 0.517578]  [A loss: 0.771937, acc: 0.328125]\n",
      "3363: [D loss: 0.725509, acc: 0.466797]  [A loss: 0.897338, acc: 0.152344]\n",
      "3364: [D loss: 0.695481, acc: 0.521484]  [A loss: 0.834505, acc: 0.203125]\n",
      "3365: [D loss: 0.701613, acc: 0.535156]  [A loss: 0.905476, acc: 0.128906]\n",
      "3366: [D loss: 0.701953, acc: 0.505859]  [A loss: 0.761315, acc: 0.402344]\n",
      "3367: [D loss: 0.698193, acc: 0.537109]  [A loss: 0.872040, acc: 0.164062]\n",
      "3368: [D loss: 0.702823, acc: 0.535156]  [A loss: 0.757920, acc: 0.367188]\n",
      "3369: [D loss: 0.702021, acc: 0.531250]  [A loss: 0.980675, acc: 0.105469]\n",
      "3370: [D loss: 0.705447, acc: 0.517578]  [A loss: 0.694943, acc: 0.511719]\n",
      "3371: [D loss: 0.736625, acc: 0.478516]  [A loss: 0.972242, acc: 0.089844]\n",
      "3372: [D loss: 0.694840, acc: 0.523438]  [A loss: 0.685389, acc: 0.519531]\n",
      "3373: [D loss: 0.710615, acc: 0.529297]  [A loss: 0.847618, acc: 0.214844]\n",
      "3374: [D loss: 0.707458, acc: 0.517578]  [A loss: 0.851723, acc: 0.175781]\n",
      "3375: [D loss: 0.702472, acc: 0.515625]  [A loss: 0.863268, acc: 0.191406]\n",
      "3376: [D loss: 0.709665, acc: 0.486328]  [A loss: 0.768209, acc: 0.343750]\n",
      "3377: [D loss: 0.708312, acc: 0.531250]  [A loss: 0.907311, acc: 0.101562]\n",
      "3378: [D loss: 0.689408, acc: 0.562500]  [A loss: 0.699488, acc: 0.496094]\n",
      "3379: [D loss: 0.710082, acc: 0.500000]  [A loss: 0.971303, acc: 0.089844]\n",
      "3380: [D loss: 0.691526, acc: 0.513672]  [A loss: 0.719897, acc: 0.425781]\n",
      "3381: [D loss: 0.710246, acc: 0.525391]  [A loss: 0.914608, acc: 0.121094]\n",
      "3382: [D loss: 0.695215, acc: 0.546875]  [A loss: 0.792104, acc: 0.308594]\n",
      "3383: [D loss: 0.696814, acc: 0.535156]  [A loss: 0.826982, acc: 0.238281]\n",
      "3384: [D loss: 0.697856, acc: 0.535156]  [A loss: 0.790105, acc: 0.324219]\n",
      "3385: [D loss: 0.695698, acc: 0.539062]  [A loss: 0.828031, acc: 0.238281]\n",
      "3386: [D loss: 0.707101, acc: 0.527344]  [A loss: 0.809490, acc: 0.253906]\n",
      "3387: [D loss: 0.688237, acc: 0.541016]  [A loss: 0.881878, acc: 0.152344]\n",
      "3388: [D loss: 0.708348, acc: 0.511719]  [A loss: 0.698673, acc: 0.519531]\n",
      "3389: [D loss: 0.719011, acc: 0.507812]  [A loss: 0.971055, acc: 0.113281]\n",
      "3390: [D loss: 0.690053, acc: 0.554688]  [A loss: 0.706972, acc: 0.480469]\n",
      "3391: [D loss: 0.706222, acc: 0.517578]  [A loss: 0.907327, acc: 0.125000]\n",
      "3392: [D loss: 0.702264, acc: 0.498047]  [A loss: 0.715939, acc: 0.460938]\n",
      "3393: [D loss: 0.701580, acc: 0.535156]  [A loss: 0.941659, acc: 0.113281]\n",
      "3394: [D loss: 0.704020, acc: 0.505859]  [A loss: 0.726550, acc: 0.441406]\n",
      "3395: [D loss: 0.720027, acc: 0.500000]  [A loss: 0.912946, acc: 0.167969]\n",
      "3396: [D loss: 0.704237, acc: 0.505859]  [A loss: 0.702615, acc: 0.519531]\n",
      "3397: [D loss: 0.702069, acc: 0.507812]  [A loss: 0.868148, acc: 0.191406]\n",
      "3398: [D loss: 0.698689, acc: 0.519531]  [A loss: 0.785742, acc: 0.324219]\n",
      "3399: [D loss: 0.704180, acc: 0.523438]  [A loss: 0.921954, acc: 0.156250]\n",
      "3400: [D loss: 0.684625, acc: 0.560547]  [A loss: 0.709174, acc: 0.480469]\n",
      "3401: [D loss: 0.708986, acc: 0.519531]  [A loss: 0.917833, acc: 0.109375]\n",
      "3402: [D loss: 0.697362, acc: 0.501953]  [A loss: 0.733223, acc: 0.429688]\n",
      "3403: [D loss: 0.701170, acc: 0.519531]  [A loss: 0.831851, acc: 0.234375]\n",
      "3404: [D loss: 0.691492, acc: 0.535156]  [A loss: 0.839357, acc: 0.226562]\n",
      "3405: [D loss: 0.699974, acc: 0.533203]  [A loss: 0.838912, acc: 0.214844]\n",
      "3406: [D loss: 0.687919, acc: 0.539062]  [A loss: 0.754751, acc: 0.382812]\n",
      "3407: [D loss: 0.693074, acc: 0.529297]  [A loss: 0.907307, acc: 0.113281]\n",
      "3408: [D loss: 0.681344, acc: 0.537109]  [A loss: 0.731320, acc: 0.425781]\n",
      "3409: [D loss: 0.733334, acc: 0.492188]  [A loss: 0.952239, acc: 0.089844]\n",
      "3410: [D loss: 0.681721, acc: 0.548828]  [A loss: 0.682161, acc: 0.554688]\n",
      "3411: [D loss: 0.707356, acc: 0.513672]  [A loss: 0.875654, acc: 0.175781]\n",
      "3412: [D loss: 0.692639, acc: 0.544922]  [A loss: 0.777738, acc: 0.355469]\n",
      "3413: [D loss: 0.702460, acc: 0.511719]  [A loss: 0.885832, acc: 0.187500]\n",
      "3414: [D loss: 0.692433, acc: 0.541016]  [A loss: 0.795431, acc: 0.316406]\n",
      "3415: [D loss: 0.692390, acc: 0.533203]  [A loss: 0.781363, acc: 0.359375]\n",
      "3416: [D loss: 0.703504, acc: 0.527344]  [A loss: 0.869561, acc: 0.167969]\n",
      "3417: [D loss: 0.684036, acc: 0.562500]  [A loss: 0.816392, acc: 0.265625]\n",
      "3418: [D loss: 0.696544, acc: 0.574219]  [A loss: 0.775924, acc: 0.382812]\n",
      "3419: [D loss: 0.714731, acc: 0.513672]  [A loss: 0.939332, acc: 0.105469]\n",
      "3420: [D loss: 0.690030, acc: 0.556641]  [A loss: 0.676509, acc: 0.570312]\n",
      "3421: [D loss: 0.745489, acc: 0.476562]  [A loss: 0.877581, acc: 0.136719]\n",
      "3422: [D loss: 0.694850, acc: 0.513672]  [A loss: 0.755344, acc: 0.367188]\n",
      "3423: [D loss: 0.700986, acc: 0.523438]  [A loss: 0.933658, acc: 0.121094]\n",
      "3424: [D loss: 0.698544, acc: 0.496094]  [A loss: 0.688675, acc: 0.546875]\n",
      "3425: [D loss: 0.719681, acc: 0.531250]  [A loss: 0.888880, acc: 0.132812]\n",
      "3426: [D loss: 0.704129, acc: 0.515625]  [A loss: 0.813782, acc: 0.242188]\n",
      "3427: [D loss: 0.707856, acc: 0.511719]  [A loss: 0.857302, acc: 0.187500]\n",
      "3428: [D loss: 0.692191, acc: 0.533203]  [A loss: 0.747847, acc: 0.394531]\n",
      "3429: [D loss: 0.694866, acc: 0.568359]  [A loss: 0.928100, acc: 0.101562]\n",
      "3430: [D loss: 0.698059, acc: 0.515625]  [A loss: 0.746262, acc: 0.394531]\n",
      "3431: [D loss: 0.690357, acc: 0.544922]  [A loss: 0.895222, acc: 0.183594]\n",
      "3432: [D loss: 0.697527, acc: 0.546875]  [A loss: 0.710144, acc: 0.484375]\n",
      "3433: [D loss: 0.721513, acc: 0.488281]  [A loss: 0.933365, acc: 0.117188]\n",
      "3434: [D loss: 0.691992, acc: 0.519531]  [A loss: 0.675006, acc: 0.539062]\n",
      "3435: [D loss: 0.717672, acc: 0.523438]  [A loss: 1.004604, acc: 0.031250]\n",
      "3436: [D loss: 0.700413, acc: 0.505859]  [A loss: 0.741803, acc: 0.425781]\n",
      "3437: [D loss: 0.701679, acc: 0.521484]  [A loss: 0.849531, acc: 0.195312]\n",
      "3438: [D loss: 0.690230, acc: 0.558594]  [A loss: 0.843203, acc: 0.207031]\n",
      "3439: [D loss: 0.704587, acc: 0.513672]  [A loss: 0.792952, acc: 0.308594]\n",
      "3440: [D loss: 0.693940, acc: 0.515625]  [A loss: 0.823357, acc: 0.265625]\n",
      "3441: [D loss: 0.706404, acc: 0.513672]  [A loss: 0.852797, acc: 0.195312]\n",
      "3442: [D loss: 0.698711, acc: 0.511719]  [A loss: 0.756272, acc: 0.398438]\n",
      "3443: [D loss: 0.701015, acc: 0.535156]  [A loss: 0.905327, acc: 0.128906]\n",
      "3444: [D loss: 0.680669, acc: 0.564453]  [A loss: 0.728501, acc: 0.402344]\n",
      "3445: [D loss: 0.713030, acc: 0.494141]  [A loss: 0.929216, acc: 0.140625]\n",
      "3446: [D loss: 0.686271, acc: 0.533203]  [A loss: 0.710363, acc: 0.472656]\n",
      "3447: [D loss: 0.693876, acc: 0.544922]  [A loss: 0.869882, acc: 0.179688]\n",
      "3448: [D loss: 0.679808, acc: 0.570312]  [A loss: 0.733508, acc: 0.417969]\n",
      "3449: [D loss: 0.714379, acc: 0.500000]  [A loss: 0.844624, acc: 0.203125]\n",
      "3450: [D loss: 0.683601, acc: 0.558594]  [A loss: 0.805882, acc: 0.261719]\n",
      "3451: [D loss: 0.703221, acc: 0.509766]  [A loss: 0.883787, acc: 0.179688]\n",
      "3452: [D loss: 0.710622, acc: 0.476562]  [A loss: 0.800550, acc: 0.285156]\n",
      "3453: [D loss: 0.706568, acc: 0.513672]  [A loss: 0.923494, acc: 0.121094]\n",
      "3454: [D loss: 0.687067, acc: 0.554688]  [A loss: 0.636789, acc: 0.671875]\n",
      "3455: [D loss: 0.736479, acc: 0.500000]  [A loss: 1.063508, acc: 0.078125]\n",
      "3456: [D loss: 0.707345, acc: 0.550781]  [A loss: 0.696902, acc: 0.507812]\n",
      "3457: [D loss: 0.757136, acc: 0.494141]  [A loss: 0.835689, acc: 0.226562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3458: [D loss: 0.712607, acc: 0.509766]  [A loss: 0.902745, acc: 0.093750]\n",
      "3459: [D loss: 0.707237, acc: 0.482422]  [A loss: 0.773305, acc: 0.339844]\n",
      "3460: [D loss: 0.707453, acc: 0.500000]  [A loss: 0.882397, acc: 0.152344]\n",
      "3461: [D loss: 0.680411, acc: 0.541016]  [A loss: 0.763253, acc: 0.367188]\n",
      "3462: [D loss: 0.707484, acc: 0.503906]  [A loss: 0.911751, acc: 0.125000]\n",
      "3463: [D loss: 0.705811, acc: 0.474609]  [A loss: 0.778370, acc: 0.324219]\n",
      "3464: [D loss: 0.715401, acc: 0.498047]  [A loss: 0.921240, acc: 0.089844]\n",
      "3465: [D loss: 0.698879, acc: 0.513672]  [A loss: 0.724989, acc: 0.476562]\n",
      "3466: [D loss: 0.695106, acc: 0.552734]  [A loss: 0.896524, acc: 0.136719]\n",
      "3467: [D loss: 0.693740, acc: 0.521484]  [A loss: 0.735435, acc: 0.390625]\n",
      "3468: [D loss: 0.708141, acc: 0.531250]  [A loss: 0.949997, acc: 0.117188]\n",
      "3469: [D loss: 0.686334, acc: 0.544922]  [A loss: 0.771235, acc: 0.363281]\n",
      "3470: [D loss: 0.701044, acc: 0.542969]  [A loss: 0.793213, acc: 0.292969]\n",
      "3471: [D loss: 0.695424, acc: 0.550781]  [A loss: 0.814115, acc: 0.300781]\n",
      "3472: [D loss: 0.670509, acc: 0.593750]  [A loss: 0.777516, acc: 0.343750]\n",
      "3473: [D loss: 0.714710, acc: 0.509766]  [A loss: 0.832421, acc: 0.207031]\n",
      "3474: [D loss: 0.701591, acc: 0.498047]  [A loss: 0.886411, acc: 0.175781]\n",
      "3475: [D loss: 0.693958, acc: 0.531250]  [A loss: 0.737987, acc: 0.390625]\n",
      "3476: [D loss: 0.719757, acc: 0.503906]  [A loss: 0.973738, acc: 0.070312]\n",
      "3477: [D loss: 0.686273, acc: 0.541016]  [A loss: 0.671366, acc: 0.558594]\n",
      "3478: [D loss: 0.716547, acc: 0.533203]  [A loss: 0.955285, acc: 0.097656]\n",
      "3479: [D loss: 0.707364, acc: 0.523438]  [A loss: 0.720968, acc: 0.437500]\n",
      "3480: [D loss: 0.709431, acc: 0.515625]  [A loss: 0.745157, acc: 0.421875]\n",
      "3481: [D loss: 0.717583, acc: 0.482422]  [A loss: 0.787852, acc: 0.269531]\n",
      "3482: [D loss: 0.694667, acc: 0.546875]  [A loss: 0.832612, acc: 0.207031]\n",
      "3483: [D loss: 0.703246, acc: 0.498047]  [A loss: 0.829344, acc: 0.273438]\n",
      "3484: [D loss: 0.705397, acc: 0.505859]  [A loss: 0.875438, acc: 0.144531]\n",
      "3485: [D loss: 0.707234, acc: 0.488281]  [A loss: 0.847151, acc: 0.199219]\n",
      "3486: [D loss: 0.699609, acc: 0.527344]  [A loss: 0.930035, acc: 0.121094]\n",
      "3487: [D loss: 0.695385, acc: 0.539062]  [A loss: 0.711272, acc: 0.496094]\n",
      "3488: [D loss: 0.712434, acc: 0.507812]  [A loss: 0.906560, acc: 0.148438]\n",
      "3489: [D loss: 0.687751, acc: 0.531250]  [A loss: 0.760203, acc: 0.347656]\n",
      "3490: [D loss: 0.705942, acc: 0.494141]  [A loss: 0.822473, acc: 0.257812]\n",
      "3491: [D loss: 0.711572, acc: 0.500000]  [A loss: 0.960271, acc: 0.082031]\n",
      "3492: [D loss: 0.700558, acc: 0.515625]  [A loss: 0.762258, acc: 0.359375]\n",
      "3493: [D loss: 0.693088, acc: 0.531250]  [A loss: 0.846776, acc: 0.199219]\n",
      "3494: [D loss: 0.684419, acc: 0.566406]  [A loss: 0.768383, acc: 0.367188]\n",
      "3495: [D loss: 0.699048, acc: 0.537109]  [A loss: 0.861475, acc: 0.164062]\n",
      "3496: [D loss: 0.700517, acc: 0.533203]  [A loss: 0.773996, acc: 0.328125]\n",
      "3497: [D loss: 0.696382, acc: 0.535156]  [A loss: 0.895227, acc: 0.128906]\n",
      "3498: [D loss: 0.696900, acc: 0.496094]  [A loss: 0.755040, acc: 0.398438]\n",
      "3499: [D loss: 0.713572, acc: 0.496094]  [A loss: 0.976283, acc: 0.078125]\n",
      "3500: [D loss: 0.699099, acc: 0.527344]  [A loss: 0.666021, acc: 0.613281]\n",
      "3501: [D loss: 0.729831, acc: 0.494141]  [A loss: 0.955052, acc: 0.144531]\n",
      "3502: [D loss: 0.697738, acc: 0.515625]  [A loss: 0.685540, acc: 0.566406]\n",
      "3503: [D loss: 0.748840, acc: 0.470703]  [A loss: 0.929219, acc: 0.136719]\n",
      "3504: [D loss: 0.690929, acc: 0.542969]  [A loss: 0.752704, acc: 0.406250]\n",
      "3505: [D loss: 0.698391, acc: 0.521484]  [A loss: 0.817726, acc: 0.253906]\n",
      "3506: [D loss: 0.713561, acc: 0.496094]  [A loss: 0.767140, acc: 0.339844]\n",
      "3507: [D loss: 0.715790, acc: 0.498047]  [A loss: 0.921021, acc: 0.101562]\n",
      "3508: [D loss: 0.704335, acc: 0.498047]  [A loss: 0.742830, acc: 0.378906]\n",
      "3509: [D loss: 0.692911, acc: 0.564453]  [A loss: 0.844595, acc: 0.226562]\n",
      "3510: [D loss: 0.697437, acc: 0.509766]  [A loss: 0.744212, acc: 0.406250]\n",
      "3511: [D loss: 0.706877, acc: 0.517578]  [A loss: 0.940158, acc: 0.074219]\n",
      "3512: [D loss: 0.701827, acc: 0.531250]  [A loss: 0.693784, acc: 0.519531]\n",
      "3513: [D loss: 0.717651, acc: 0.525391]  [A loss: 0.934543, acc: 0.113281]\n",
      "3514: [D loss: 0.716266, acc: 0.482422]  [A loss: 0.769405, acc: 0.335938]\n",
      "3515: [D loss: 0.708504, acc: 0.496094]  [A loss: 0.871918, acc: 0.171875]\n",
      "3516: [D loss: 0.699469, acc: 0.517578]  [A loss: 0.774983, acc: 0.343750]\n",
      "3517: [D loss: 0.701805, acc: 0.484375]  [A loss: 0.843962, acc: 0.191406]\n",
      "3518: [D loss: 0.691253, acc: 0.517578]  [A loss: 0.759768, acc: 0.343750]\n",
      "3519: [D loss: 0.696188, acc: 0.542969]  [A loss: 0.938916, acc: 0.097656]\n",
      "3520: [D loss: 0.688971, acc: 0.535156]  [A loss: 0.742945, acc: 0.394531]\n",
      "3521: [D loss: 0.716842, acc: 0.498047]  [A loss: 0.923990, acc: 0.101562]\n",
      "3522: [D loss: 0.694462, acc: 0.513672]  [A loss: 0.741503, acc: 0.351562]\n",
      "3523: [D loss: 0.710341, acc: 0.519531]  [A loss: 0.884926, acc: 0.167969]\n",
      "3524: [D loss: 0.690123, acc: 0.556641]  [A loss: 0.712429, acc: 0.468750]\n",
      "3525: [D loss: 0.708850, acc: 0.537109]  [A loss: 0.906335, acc: 0.132812]\n",
      "3526: [D loss: 0.694149, acc: 0.542969]  [A loss: 0.701681, acc: 0.503906]\n",
      "3527: [D loss: 0.728802, acc: 0.498047]  [A loss: 0.927464, acc: 0.148438]\n",
      "3528: [D loss: 0.706459, acc: 0.501953]  [A loss: 0.731633, acc: 0.433594]\n",
      "3529: [D loss: 0.719225, acc: 0.525391]  [A loss: 0.980653, acc: 0.093750]\n",
      "3530: [D loss: 0.703873, acc: 0.515625]  [A loss: 0.693475, acc: 0.523438]\n",
      "3531: [D loss: 0.711561, acc: 0.513672]  [A loss: 0.910739, acc: 0.121094]\n",
      "3532: [D loss: 0.699637, acc: 0.533203]  [A loss: 0.734572, acc: 0.425781]\n",
      "3533: [D loss: 0.727255, acc: 0.482422]  [A loss: 0.837834, acc: 0.183594]\n",
      "3534: [D loss: 0.695137, acc: 0.533203]  [A loss: 0.840635, acc: 0.171875]\n",
      "3535: [D loss: 0.687933, acc: 0.541016]  [A loss: 0.815965, acc: 0.222656]\n",
      "3536: [D loss: 0.690708, acc: 0.537109]  [A loss: 0.833880, acc: 0.210938]\n",
      "3537: [D loss: 0.703877, acc: 0.515625]  [A loss: 0.798398, acc: 0.269531]\n",
      "3538: [D loss: 0.712747, acc: 0.515625]  [A loss: 0.780839, acc: 0.343750]\n",
      "3539: [D loss: 0.707523, acc: 0.537109]  [A loss: 0.906243, acc: 0.152344]\n",
      "3540: [D loss: 0.699371, acc: 0.535156]  [A loss: 0.772908, acc: 0.296875]\n",
      "3541: [D loss: 0.708197, acc: 0.509766]  [A loss: 0.884902, acc: 0.160156]\n",
      "3542: [D loss: 0.702182, acc: 0.513672]  [A loss: 0.750864, acc: 0.402344]\n",
      "3543: [D loss: 0.701047, acc: 0.531250]  [A loss: 0.833245, acc: 0.222656]\n",
      "3544: [D loss: 0.693216, acc: 0.539062]  [A loss: 0.769474, acc: 0.355469]\n",
      "3545: [D loss: 0.699725, acc: 0.511719]  [A loss: 0.824695, acc: 0.222656]\n",
      "3546: [D loss: 0.687744, acc: 0.562500]  [A loss: 0.800107, acc: 0.250000]\n",
      "3547: [D loss: 0.705639, acc: 0.498047]  [A loss: 0.880989, acc: 0.152344]\n",
      "3548: [D loss: 0.684377, acc: 0.542969]  [A loss: 0.748973, acc: 0.394531]\n",
      "3549: [D loss: 0.709245, acc: 0.496094]  [A loss: 0.960640, acc: 0.089844]\n",
      "3550: [D loss: 0.698845, acc: 0.507812]  [A loss: 0.681068, acc: 0.554688]\n",
      "3551: [D loss: 0.717755, acc: 0.507812]  [A loss: 0.900803, acc: 0.136719]\n",
      "3552: [D loss: 0.702541, acc: 0.503906]  [A loss: 0.771074, acc: 0.328125]\n",
      "3553: [D loss: 0.698473, acc: 0.531250]  [A loss: 0.935999, acc: 0.109375]\n",
      "3554: [D loss: 0.698994, acc: 0.517578]  [A loss: 0.778252, acc: 0.316406]\n",
      "3555: [D loss: 0.702736, acc: 0.507812]  [A loss: 0.889462, acc: 0.140625]\n",
      "3556: [D loss: 0.693595, acc: 0.521484]  [A loss: 0.710697, acc: 0.472656]\n",
      "3557: [D loss: 0.728276, acc: 0.509766]  [A loss: 1.058852, acc: 0.074219]\n",
      "3558: [D loss: 0.722459, acc: 0.474609]  [A loss: 0.778600, acc: 0.308594]\n",
      "3559: [D loss: 0.706341, acc: 0.505859]  [A loss: 0.839093, acc: 0.207031]\n",
      "3560: [D loss: 0.692725, acc: 0.527344]  [A loss: 0.810373, acc: 0.218750]\n",
      "3561: [D loss: 0.700356, acc: 0.515625]  [A loss: 0.793551, acc: 0.281250]\n",
      "3562: [D loss: 0.695054, acc: 0.531250]  [A loss: 0.805384, acc: 0.253906]\n",
      "3563: [D loss: 0.701968, acc: 0.523438]  [A loss: 0.864068, acc: 0.164062]\n",
      "3564: [D loss: 0.696464, acc: 0.535156]  [A loss: 0.811127, acc: 0.253906]\n",
      "3565: [D loss: 0.688833, acc: 0.562500]  [A loss: 0.897757, acc: 0.121094]\n",
      "3566: [D loss: 0.693111, acc: 0.548828]  [A loss: 0.800263, acc: 0.281250]\n",
      "3567: [D loss: 0.693379, acc: 0.531250]  [A loss: 0.788848, acc: 0.296875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3568: [D loss: 0.686074, acc: 0.554688]  [A loss: 0.886708, acc: 0.167969]\n",
      "3569: [D loss: 0.691110, acc: 0.537109]  [A loss: 0.728823, acc: 0.437500]\n",
      "3570: [D loss: 0.714522, acc: 0.503906]  [A loss: 0.965140, acc: 0.105469]\n",
      "3571: [D loss: 0.697345, acc: 0.509766]  [A loss: 0.725439, acc: 0.414062]\n",
      "3572: [D loss: 0.716476, acc: 0.498047]  [A loss: 0.930281, acc: 0.132812]\n",
      "3573: [D loss: 0.680327, acc: 0.576172]  [A loss: 0.715028, acc: 0.441406]\n",
      "3574: [D loss: 0.708046, acc: 0.507812]  [A loss: 0.879485, acc: 0.183594]\n",
      "3575: [D loss: 0.705359, acc: 0.517578]  [A loss: 0.800310, acc: 0.292969]\n",
      "3576: [D loss: 0.690472, acc: 0.560547]  [A loss: 0.837361, acc: 0.195312]\n",
      "3577: [D loss: 0.705025, acc: 0.494141]  [A loss: 0.779636, acc: 0.292969]\n",
      "3578: [D loss: 0.716067, acc: 0.505859]  [A loss: 0.905182, acc: 0.132812]\n",
      "3579: [D loss: 0.698223, acc: 0.531250]  [A loss: 0.744838, acc: 0.394531]\n",
      "3580: [D loss: 0.702509, acc: 0.535156]  [A loss: 0.938338, acc: 0.101562]\n",
      "3581: [D loss: 0.686630, acc: 0.539062]  [A loss: 0.667553, acc: 0.589844]\n",
      "3582: [D loss: 0.713162, acc: 0.529297]  [A loss: 0.925108, acc: 0.144531]\n",
      "3583: [D loss: 0.691261, acc: 0.535156]  [A loss: 0.715489, acc: 0.468750]\n",
      "3584: [D loss: 0.709030, acc: 0.531250]  [A loss: 0.876492, acc: 0.179688]\n",
      "3585: [D loss: 0.696755, acc: 0.535156]  [A loss: 0.794670, acc: 0.277344]\n",
      "3586: [D loss: 0.713984, acc: 0.498047]  [A loss: 0.943999, acc: 0.101562]\n",
      "3587: [D loss: 0.700953, acc: 0.542969]  [A loss: 0.747740, acc: 0.378906]\n",
      "3588: [D loss: 0.694483, acc: 0.519531]  [A loss: 0.847090, acc: 0.203125]\n",
      "3589: [D loss: 0.716966, acc: 0.490234]  [A loss: 0.739841, acc: 0.402344]\n",
      "3590: [D loss: 0.724257, acc: 0.515625]  [A loss: 1.010527, acc: 0.058594]\n",
      "3591: [D loss: 0.692291, acc: 0.519531]  [A loss: 0.750736, acc: 0.351562]\n",
      "3592: [D loss: 0.708026, acc: 0.531250]  [A loss: 0.834106, acc: 0.234375]\n",
      "3593: [D loss: 0.703594, acc: 0.498047]  [A loss: 0.866438, acc: 0.195312]\n",
      "3594: [D loss: 0.697742, acc: 0.541016]  [A loss: 0.733225, acc: 0.410156]\n",
      "3595: [D loss: 0.711752, acc: 0.527344]  [A loss: 0.878541, acc: 0.175781]\n",
      "3596: [D loss: 0.686513, acc: 0.541016]  [A loss: 0.730398, acc: 0.453125]\n",
      "3597: [D loss: 0.702958, acc: 0.515625]  [A loss: 0.855577, acc: 0.230469]\n",
      "3598: [D loss: 0.693797, acc: 0.546875]  [A loss: 0.811307, acc: 0.265625]\n",
      "3599: [D loss: 0.686308, acc: 0.531250]  [A loss: 0.813669, acc: 0.257812]\n",
      "3600: [D loss: 0.706176, acc: 0.511719]  [A loss: 0.839570, acc: 0.222656]\n",
      "3601: [D loss: 0.691882, acc: 0.550781]  [A loss: 0.800373, acc: 0.261719]\n",
      "3602: [D loss: 0.706113, acc: 0.501953]  [A loss: 0.787058, acc: 0.304688]\n",
      "3603: [D loss: 0.699251, acc: 0.511719]  [A loss: 0.904091, acc: 0.117188]\n",
      "3604: [D loss: 0.679461, acc: 0.566406]  [A loss: 0.799680, acc: 0.332031]\n",
      "3605: [D loss: 0.701436, acc: 0.533203]  [A loss: 0.917757, acc: 0.105469]\n",
      "3606: [D loss: 0.696951, acc: 0.521484]  [A loss: 0.729173, acc: 0.429688]\n",
      "3607: [D loss: 0.714611, acc: 0.529297]  [A loss: 0.951269, acc: 0.117188]\n",
      "3608: [D loss: 0.712121, acc: 0.498047]  [A loss: 0.692126, acc: 0.523438]\n",
      "3609: [D loss: 0.716702, acc: 0.529297]  [A loss: 0.918337, acc: 0.144531]\n",
      "3610: [D loss: 0.691566, acc: 0.542969]  [A loss: 0.713773, acc: 0.445312]\n",
      "3611: [D loss: 0.715676, acc: 0.519531]  [A loss: 0.938502, acc: 0.125000]\n",
      "3612: [D loss: 0.694508, acc: 0.542969]  [A loss: 0.723584, acc: 0.445312]\n",
      "3613: [D loss: 0.709208, acc: 0.531250]  [A loss: 0.861249, acc: 0.156250]\n",
      "3614: [D loss: 0.696312, acc: 0.529297]  [A loss: 0.762256, acc: 0.355469]\n",
      "3615: [D loss: 0.688404, acc: 0.552734]  [A loss: 0.825011, acc: 0.238281]\n",
      "3616: [D loss: 0.699432, acc: 0.503906]  [A loss: 0.832580, acc: 0.222656]\n",
      "3617: [D loss: 0.703196, acc: 0.527344]  [A loss: 0.874184, acc: 0.222656]\n",
      "3618: [D loss: 0.703164, acc: 0.531250]  [A loss: 0.802010, acc: 0.367188]\n",
      "3619: [D loss: 0.683831, acc: 0.558594]  [A loss: 0.816174, acc: 0.296875]\n",
      "3620: [D loss: 0.700850, acc: 0.527344]  [A loss: 0.773031, acc: 0.332031]\n",
      "3621: [D loss: 0.701869, acc: 0.505859]  [A loss: 0.899348, acc: 0.156250]\n",
      "3622: [D loss: 0.697707, acc: 0.550781]  [A loss: 0.728964, acc: 0.441406]\n",
      "3623: [D loss: 0.716803, acc: 0.505859]  [A loss: 0.898985, acc: 0.101562]\n",
      "3624: [D loss: 0.691691, acc: 0.546875]  [A loss: 0.728489, acc: 0.437500]\n",
      "3625: [D loss: 0.704011, acc: 0.537109]  [A loss: 0.917573, acc: 0.125000]\n",
      "3626: [D loss: 0.706600, acc: 0.513672]  [A loss: 0.704475, acc: 0.511719]\n",
      "3627: [D loss: 0.704992, acc: 0.515625]  [A loss: 0.861069, acc: 0.222656]\n",
      "3628: [D loss: 0.704958, acc: 0.523438]  [A loss: 0.882226, acc: 0.171875]\n",
      "3629: [D loss: 0.724788, acc: 0.490234]  [A loss: 0.776452, acc: 0.351562]\n",
      "3630: [D loss: 0.711264, acc: 0.501953]  [A loss: 0.995686, acc: 0.089844]\n",
      "3631: [D loss: 0.693006, acc: 0.498047]  [A loss: 0.692543, acc: 0.503906]\n",
      "3632: [D loss: 0.719618, acc: 0.498047]  [A loss: 0.888867, acc: 0.132812]\n",
      "3633: [D loss: 0.683965, acc: 0.568359]  [A loss: 0.760393, acc: 0.339844]\n",
      "3634: [D loss: 0.705720, acc: 0.521484]  [A loss: 0.905660, acc: 0.109375]\n",
      "3635: [D loss: 0.708783, acc: 0.503906]  [A loss: 0.740970, acc: 0.425781]\n",
      "3636: [D loss: 0.704301, acc: 0.537109]  [A loss: 0.993669, acc: 0.062500]\n",
      "3637: [D loss: 0.699378, acc: 0.539062]  [A loss: 0.687445, acc: 0.546875]\n",
      "3638: [D loss: 0.718925, acc: 0.511719]  [A loss: 0.838812, acc: 0.203125]\n",
      "3639: [D loss: 0.712938, acc: 0.511719]  [A loss: 0.744328, acc: 0.375000]\n",
      "3640: [D loss: 0.701878, acc: 0.515625]  [A loss: 0.830986, acc: 0.234375]\n",
      "3641: [D loss: 0.685734, acc: 0.556641]  [A loss: 0.814459, acc: 0.230469]\n",
      "3642: [D loss: 0.694038, acc: 0.542969]  [A loss: 0.865138, acc: 0.148438]\n",
      "3643: [D loss: 0.691786, acc: 0.529297]  [A loss: 0.747192, acc: 0.394531]\n",
      "3644: [D loss: 0.716412, acc: 0.501953]  [A loss: 0.964044, acc: 0.085938]\n",
      "3645: [D loss: 0.693590, acc: 0.533203]  [A loss: 0.708560, acc: 0.476562]\n",
      "3646: [D loss: 0.731268, acc: 0.509766]  [A loss: 0.938890, acc: 0.128906]\n",
      "3647: [D loss: 0.693551, acc: 0.564453]  [A loss: 0.736249, acc: 0.425781]\n",
      "3648: [D loss: 0.704886, acc: 0.515625]  [A loss: 0.825731, acc: 0.214844]\n",
      "3649: [D loss: 0.698919, acc: 0.535156]  [A loss: 0.762534, acc: 0.367188]\n",
      "3650: [D loss: 0.711496, acc: 0.501953]  [A loss: 0.924565, acc: 0.105469]\n",
      "3651: [D loss: 0.702602, acc: 0.521484]  [A loss: 0.741508, acc: 0.398438]\n",
      "3652: [D loss: 0.729777, acc: 0.488281]  [A loss: 0.926969, acc: 0.105469]\n",
      "3653: [D loss: 0.692686, acc: 0.546875]  [A loss: 0.699338, acc: 0.539062]\n",
      "3654: [D loss: 0.697095, acc: 0.531250]  [A loss: 0.850052, acc: 0.234375]\n",
      "3655: [D loss: 0.701798, acc: 0.519531]  [A loss: 0.766277, acc: 0.339844]\n",
      "3656: [D loss: 0.717351, acc: 0.533203]  [A loss: 0.921457, acc: 0.085938]\n",
      "3657: [D loss: 0.693830, acc: 0.521484]  [A loss: 0.717107, acc: 0.457031]\n",
      "3658: [D loss: 0.700848, acc: 0.523438]  [A loss: 0.902965, acc: 0.152344]\n",
      "3659: [D loss: 0.687745, acc: 0.560547]  [A loss: 0.708379, acc: 0.500000]\n",
      "3660: [D loss: 0.713622, acc: 0.509766]  [A loss: 0.969967, acc: 0.074219]\n",
      "3661: [D loss: 0.701081, acc: 0.513672]  [A loss: 0.727834, acc: 0.417969]\n",
      "3662: [D loss: 0.722717, acc: 0.500000]  [A loss: 0.822742, acc: 0.226562]\n",
      "3663: [D loss: 0.691318, acc: 0.566406]  [A loss: 0.763638, acc: 0.339844]\n",
      "3664: [D loss: 0.706271, acc: 0.525391]  [A loss: 0.849139, acc: 0.199219]\n",
      "3665: [D loss: 0.681315, acc: 0.583984]  [A loss: 0.736720, acc: 0.390625]\n",
      "3666: [D loss: 0.708774, acc: 0.523438]  [A loss: 0.854244, acc: 0.160156]\n",
      "3667: [D loss: 0.706907, acc: 0.500000]  [A loss: 0.747803, acc: 0.355469]\n",
      "3668: [D loss: 0.699158, acc: 0.513672]  [A loss: 0.859465, acc: 0.175781]\n",
      "3669: [D loss: 0.701037, acc: 0.505859]  [A loss: 0.769437, acc: 0.363281]\n",
      "3670: [D loss: 0.708456, acc: 0.523438]  [A loss: 0.836068, acc: 0.222656]\n",
      "3671: [D loss: 0.691313, acc: 0.535156]  [A loss: 0.773764, acc: 0.316406]\n",
      "3672: [D loss: 0.703078, acc: 0.513672]  [A loss: 0.829063, acc: 0.253906]\n",
      "3673: [D loss: 0.693419, acc: 0.564453]  [A loss: 0.790796, acc: 0.292969]\n",
      "3674: [D loss: 0.692580, acc: 0.541016]  [A loss: 0.847062, acc: 0.210938]\n",
      "3675: [D loss: 0.694691, acc: 0.525391]  [A loss: 0.813641, acc: 0.265625]\n",
      "3676: [D loss: 0.708376, acc: 0.519531]  [A loss: 0.905358, acc: 0.117188]\n",
      "3677: [D loss: 0.687422, acc: 0.556641]  [A loss: 0.720863, acc: 0.445312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3678: [D loss: 0.713071, acc: 0.527344]  [A loss: 0.997835, acc: 0.089844]\n",
      "3679: [D loss: 0.707052, acc: 0.500000]  [A loss: 0.684989, acc: 0.535156]\n",
      "3680: [D loss: 0.704619, acc: 0.542969]  [A loss: 0.892236, acc: 0.164062]\n",
      "3681: [D loss: 0.701607, acc: 0.541016]  [A loss: 0.796528, acc: 0.316406]\n",
      "3682: [D loss: 0.695999, acc: 0.531250]  [A loss: 0.836009, acc: 0.238281]\n",
      "3683: [D loss: 0.691633, acc: 0.558594]  [A loss: 0.845597, acc: 0.253906]\n",
      "3684: [D loss: 0.709743, acc: 0.509766]  [A loss: 0.766223, acc: 0.355469]\n",
      "3685: [D loss: 0.703028, acc: 0.556641]  [A loss: 0.938702, acc: 0.136719]\n",
      "3686: [D loss: 0.685448, acc: 0.529297]  [A loss: 0.730156, acc: 0.453125]\n",
      "3687: [D loss: 0.702385, acc: 0.501953]  [A loss: 0.892091, acc: 0.171875]\n",
      "3688: [D loss: 0.702514, acc: 0.529297]  [A loss: 0.748816, acc: 0.382812]\n",
      "3689: [D loss: 0.696207, acc: 0.529297]  [A loss: 0.923863, acc: 0.144531]\n",
      "3690: [D loss: 0.699821, acc: 0.533203]  [A loss: 0.718467, acc: 0.453125]\n",
      "3691: [D loss: 0.719532, acc: 0.517578]  [A loss: 0.985094, acc: 0.097656]\n",
      "3692: [D loss: 0.692715, acc: 0.519531]  [A loss: 0.728136, acc: 0.425781]\n",
      "3693: [D loss: 0.717729, acc: 0.484375]  [A loss: 0.849990, acc: 0.203125]\n",
      "3694: [D loss: 0.684808, acc: 0.570312]  [A loss: 0.803124, acc: 0.273438]\n",
      "3695: [D loss: 0.694924, acc: 0.529297]  [A loss: 0.869894, acc: 0.191406]\n",
      "3696: [D loss: 0.708614, acc: 0.511719]  [A loss: 0.755065, acc: 0.386719]\n",
      "3697: [D loss: 0.693333, acc: 0.537109]  [A loss: 0.858178, acc: 0.195312]\n",
      "3698: [D loss: 0.681671, acc: 0.554688]  [A loss: 0.750801, acc: 0.402344]\n",
      "3699: [D loss: 0.709358, acc: 0.511719]  [A loss: 0.868415, acc: 0.191406]\n",
      "3700: [D loss: 0.703577, acc: 0.533203]  [A loss: 0.741926, acc: 0.410156]\n",
      "3701: [D loss: 0.709826, acc: 0.490234]  [A loss: 0.961255, acc: 0.085938]\n",
      "3702: [D loss: 0.695564, acc: 0.541016]  [A loss: 0.685895, acc: 0.519531]\n",
      "3703: [D loss: 0.700469, acc: 0.539062]  [A loss: 0.877962, acc: 0.191406]\n",
      "3704: [D loss: 0.675931, acc: 0.580078]  [A loss: 0.754927, acc: 0.375000]\n",
      "3705: [D loss: 0.708445, acc: 0.519531]  [A loss: 0.877266, acc: 0.183594]\n",
      "3706: [D loss: 0.686215, acc: 0.541016]  [A loss: 0.821317, acc: 0.250000]\n",
      "3707: [D loss: 0.696494, acc: 0.523438]  [A loss: 0.830556, acc: 0.222656]\n",
      "3708: [D loss: 0.705802, acc: 0.482422]  [A loss: 0.814146, acc: 0.261719]\n",
      "3709: [D loss: 0.714671, acc: 0.494141]  [A loss: 0.825734, acc: 0.246094]\n",
      "3710: [D loss: 0.682838, acc: 0.542969]  [A loss: 0.763984, acc: 0.382812]\n",
      "3711: [D loss: 0.701461, acc: 0.533203]  [A loss: 0.865027, acc: 0.175781]\n",
      "3712: [D loss: 0.691967, acc: 0.535156]  [A loss: 0.764343, acc: 0.324219]\n",
      "3713: [D loss: 0.699681, acc: 0.511719]  [A loss: 0.901562, acc: 0.121094]\n",
      "3714: [D loss: 0.687989, acc: 0.523438]  [A loss: 0.709060, acc: 0.503906]\n",
      "3715: [D loss: 0.721022, acc: 0.492188]  [A loss: 0.853628, acc: 0.179688]\n",
      "3716: [D loss: 0.697883, acc: 0.525391]  [A loss: 0.731684, acc: 0.425781]\n",
      "3717: [D loss: 0.711182, acc: 0.507812]  [A loss: 0.874025, acc: 0.156250]\n",
      "3718: [D loss: 0.711577, acc: 0.494141]  [A loss: 0.712909, acc: 0.484375]\n",
      "3719: [D loss: 0.709871, acc: 0.511719]  [A loss: 0.985379, acc: 0.097656]\n",
      "3720: [D loss: 0.703942, acc: 0.505859]  [A loss: 0.712595, acc: 0.460938]\n",
      "3721: [D loss: 0.711151, acc: 0.498047]  [A loss: 0.841251, acc: 0.238281]\n",
      "3722: [D loss: 0.703164, acc: 0.525391]  [A loss: 0.834610, acc: 0.210938]\n",
      "3723: [D loss: 0.711008, acc: 0.539062]  [A loss: 0.942853, acc: 0.058594]\n",
      "3724: [D loss: 0.692540, acc: 0.537109]  [A loss: 0.696429, acc: 0.496094]\n",
      "3725: [D loss: 0.723207, acc: 0.505859]  [A loss: 0.962824, acc: 0.125000]\n",
      "3726: [D loss: 0.698323, acc: 0.515625]  [A loss: 0.706297, acc: 0.488281]\n",
      "3727: [D loss: 0.710424, acc: 0.537109]  [A loss: 0.934795, acc: 0.117188]\n",
      "3728: [D loss: 0.692433, acc: 0.527344]  [A loss: 0.741923, acc: 0.417969]\n",
      "3729: [D loss: 0.705728, acc: 0.501953]  [A loss: 0.870525, acc: 0.195312]\n",
      "3730: [D loss: 0.709095, acc: 0.482422]  [A loss: 0.736426, acc: 0.390625]\n",
      "3731: [D loss: 0.702644, acc: 0.511719]  [A loss: 0.823940, acc: 0.238281]\n",
      "3732: [D loss: 0.701727, acc: 0.523438]  [A loss: 0.786823, acc: 0.296875]\n",
      "3733: [D loss: 0.713754, acc: 0.509766]  [A loss: 0.865604, acc: 0.160156]\n",
      "3734: [D loss: 0.701648, acc: 0.500000]  [A loss: 0.744286, acc: 0.347656]\n",
      "3735: [D loss: 0.704382, acc: 0.525391]  [A loss: 0.903406, acc: 0.132812]\n",
      "3736: [D loss: 0.697213, acc: 0.525391]  [A loss: 0.787827, acc: 0.300781]\n",
      "3737: [D loss: 0.701809, acc: 0.533203]  [A loss: 0.834998, acc: 0.187500]\n",
      "3738: [D loss: 0.708250, acc: 0.470703]  [A loss: 0.731323, acc: 0.441406]\n",
      "3739: [D loss: 0.714703, acc: 0.521484]  [A loss: 0.924567, acc: 0.097656]\n",
      "3740: [D loss: 0.702183, acc: 0.542969]  [A loss: 0.757296, acc: 0.347656]\n",
      "3741: [D loss: 0.701215, acc: 0.525391]  [A loss: 0.928471, acc: 0.078125]\n",
      "3742: [D loss: 0.705753, acc: 0.503906]  [A loss: 0.728006, acc: 0.410156]\n",
      "3743: [D loss: 0.710662, acc: 0.521484]  [A loss: 0.884365, acc: 0.164062]\n",
      "3744: [D loss: 0.694707, acc: 0.521484]  [A loss: 0.745529, acc: 0.394531]\n",
      "3745: [D loss: 0.699782, acc: 0.509766]  [A loss: 0.860606, acc: 0.199219]\n",
      "3746: [D loss: 0.719571, acc: 0.488281]  [A loss: 0.712077, acc: 0.488281]\n",
      "3747: [D loss: 0.749037, acc: 0.501953]  [A loss: 1.093267, acc: 0.007812]\n",
      "3748: [D loss: 0.701693, acc: 0.527344]  [A loss: 0.713527, acc: 0.507812]\n",
      "3749: [D loss: 0.716186, acc: 0.503906]  [A loss: 0.812666, acc: 0.277344]\n",
      "3750: [D loss: 0.691908, acc: 0.548828]  [A loss: 0.767536, acc: 0.304688]\n",
      "3751: [D loss: 0.698889, acc: 0.529297]  [A loss: 0.792504, acc: 0.296875]\n",
      "3752: [D loss: 0.690776, acc: 0.511719]  [A loss: 0.822824, acc: 0.238281]\n",
      "3753: [D loss: 0.690369, acc: 0.544922]  [A loss: 0.734971, acc: 0.414062]\n",
      "3754: [D loss: 0.707839, acc: 0.507812]  [A loss: 0.896269, acc: 0.140625]\n",
      "3755: [D loss: 0.687811, acc: 0.560547]  [A loss: 0.742107, acc: 0.402344]\n",
      "3756: [D loss: 0.720514, acc: 0.492188]  [A loss: 0.949205, acc: 0.101562]\n",
      "3757: [D loss: 0.701246, acc: 0.517578]  [A loss: 0.729544, acc: 0.394531]\n",
      "3758: [D loss: 0.688772, acc: 0.550781]  [A loss: 0.818659, acc: 0.234375]\n",
      "3759: [D loss: 0.704199, acc: 0.539062]  [A loss: 0.732972, acc: 0.417969]\n",
      "3760: [D loss: 0.699701, acc: 0.513672]  [A loss: 0.878132, acc: 0.183594]\n",
      "3761: [D loss: 0.694980, acc: 0.515625]  [A loss: 0.769605, acc: 0.300781]\n",
      "3762: [D loss: 0.701848, acc: 0.544922]  [A loss: 0.868008, acc: 0.152344]\n",
      "3763: [D loss: 0.704460, acc: 0.509766]  [A loss: 0.806805, acc: 0.273438]\n",
      "3764: [D loss: 0.694033, acc: 0.544922]  [A loss: 0.796632, acc: 0.292969]\n",
      "3765: [D loss: 0.701026, acc: 0.513672]  [A loss: 0.802774, acc: 0.312500]\n",
      "3766: [D loss: 0.697299, acc: 0.535156]  [A loss: 0.803153, acc: 0.250000]\n",
      "3767: [D loss: 0.689487, acc: 0.533203]  [A loss: 0.818819, acc: 0.265625]\n",
      "3768: [D loss: 0.700469, acc: 0.537109]  [A loss: 0.814825, acc: 0.250000]\n",
      "3769: [D loss: 0.696445, acc: 0.535156]  [A loss: 0.837886, acc: 0.234375]\n",
      "3770: [D loss: 0.700661, acc: 0.511719]  [A loss: 0.853070, acc: 0.187500]\n",
      "3771: [D loss: 0.708910, acc: 0.511719]  [A loss: 0.870542, acc: 0.214844]\n",
      "3772: [D loss: 0.700670, acc: 0.531250]  [A loss: 0.808641, acc: 0.273438]\n",
      "3773: [D loss: 0.695407, acc: 0.548828]  [A loss: 0.953996, acc: 0.125000]\n",
      "3774: [D loss: 0.689304, acc: 0.546875]  [A loss: 0.718096, acc: 0.460938]\n",
      "3775: [D loss: 0.702458, acc: 0.533203]  [A loss: 0.920273, acc: 0.156250]\n",
      "3776: [D loss: 0.711165, acc: 0.494141]  [A loss: 0.779655, acc: 0.332031]\n",
      "3777: [D loss: 0.707021, acc: 0.533203]  [A loss: 0.944379, acc: 0.121094]\n",
      "3778: [D loss: 0.706525, acc: 0.492188]  [A loss: 0.727933, acc: 0.417969]\n",
      "3779: [D loss: 0.713468, acc: 0.533203]  [A loss: 0.935219, acc: 0.113281]\n",
      "3780: [D loss: 0.686515, acc: 0.560547]  [A loss: 0.746486, acc: 0.406250]\n",
      "3781: [D loss: 0.707649, acc: 0.554688]  [A loss: 0.879483, acc: 0.203125]\n",
      "3782: [D loss: 0.702130, acc: 0.523438]  [A loss: 0.758817, acc: 0.378906]\n",
      "3783: [D loss: 0.706251, acc: 0.511719]  [A loss: 0.936600, acc: 0.136719]\n",
      "3784: [D loss: 0.689265, acc: 0.550781]  [A loss: 0.723849, acc: 0.437500]\n",
      "3785: [D loss: 0.695754, acc: 0.552734]  [A loss: 0.864109, acc: 0.222656]\n",
      "3786: [D loss: 0.694683, acc: 0.544922]  [A loss: 0.774872, acc: 0.347656]\n",
      "3787: [D loss: 0.695432, acc: 0.562500]  [A loss: 0.904494, acc: 0.160156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3788: [D loss: 0.698611, acc: 0.527344]  [A loss: 0.759791, acc: 0.367188]\n",
      "3789: [D loss: 0.716769, acc: 0.519531]  [A loss: 0.883364, acc: 0.195312]\n",
      "3790: [D loss: 0.693961, acc: 0.525391]  [A loss: 0.791539, acc: 0.304688]\n",
      "3791: [D loss: 0.694462, acc: 0.527344]  [A loss: 0.903475, acc: 0.121094]\n",
      "3792: [D loss: 0.679418, acc: 0.572266]  [A loss: 0.694621, acc: 0.542969]\n",
      "3793: [D loss: 0.718034, acc: 0.529297]  [A loss: 0.987291, acc: 0.109375]\n",
      "3794: [D loss: 0.706189, acc: 0.523438]  [A loss: 0.790856, acc: 0.289062]\n",
      "3795: [D loss: 0.695477, acc: 0.548828]  [A loss: 0.739556, acc: 0.402344]\n",
      "3796: [D loss: 0.705497, acc: 0.523438]  [A loss: 0.915929, acc: 0.175781]\n",
      "3797: [D loss: 0.693547, acc: 0.521484]  [A loss: 0.766274, acc: 0.324219]\n",
      "3798: [D loss: 0.705351, acc: 0.527344]  [A loss: 0.945563, acc: 0.117188]\n",
      "3799: [D loss: 0.688781, acc: 0.537109]  [A loss: 0.691478, acc: 0.496094]\n",
      "3800: [D loss: 0.708340, acc: 0.519531]  [A loss: 0.870211, acc: 0.210938]\n",
      "3801: [D loss: 0.689909, acc: 0.562500]  [A loss: 0.747161, acc: 0.371094]\n",
      "3802: [D loss: 0.718777, acc: 0.515625]  [A loss: 0.917197, acc: 0.179688]\n",
      "3803: [D loss: 0.698811, acc: 0.515625]  [A loss: 0.736929, acc: 0.460938]\n",
      "3804: [D loss: 0.703999, acc: 0.541016]  [A loss: 0.853879, acc: 0.187500]\n",
      "3805: [D loss: 0.696497, acc: 0.492188]  [A loss: 0.754068, acc: 0.437500]\n",
      "3806: [D loss: 0.703876, acc: 0.533203]  [A loss: 0.824314, acc: 0.257812]\n",
      "3807: [D loss: 0.693530, acc: 0.529297]  [A loss: 0.784561, acc: 0.316406]\n",
      "3808: [D loss: 0.708130, acc: 0.523438]  [A loss: 0.868548, acc: 0.203125]\n",
      "3809: [D loss: 0.701000, acc: 0.519531]  [A loss: 0.809592, acc: 0.253906]\n",
      "3810: [D loss: 0.710606, acc: 0.498047]  [A loss: 0.834224, acc: 0.230469]\n",
      "3811: [D loss: 0.711433, acc: 0.541016]  [A loss: 0.883756, acc: 0.199219]\n",
      "3812: [D loss: 0.685128, acc: 0.554688]  [A loss: 0.801176, acc: 0.273438]\n",
      "3813: [D loss: 0.699988, acc: 0.542969]  [A loss: 0.863110, acc: 0.167969]\n",
      "3814: [D loss: 0.703891, acc: 0.488281]  [A loss: 0.762216, acc: 0.398438]\n",
      "3815: [D loss: 0.718373, acc: 0.517578]  [A loss: 1.029994, acc: 0.085938]\n",
      "3816: [D loss: 0.709046, acc: 0.513672]  [A loss: 0.735170, acc: 0.433594]\n",
      "3817: [D loss: 0.709050, acc: 0.541016]  [A loss: 0.955168, acc: 0.097656]\n",
      "3818: [D loss: 0.686109, acc: 0.539062]  [A loss: 0.715865, acc: 0.503906]\n",
      "3819: [D loss: 0.718719, acc: 0.509766]  [A loss: 0.911558, acc: 0.140625]\n",
      "3820: [D loss: 0.699478, acc: 0.517578]  [A loss: 0.685265, acc: 0.546875]\n",
      "3821: [D loss: 0.724840, acc: 0.507812]  [A loss: 0.983522, acc: 0.105469]\n",
      "3822: [D loss: 0.699884, acc: 0.519531]  [A loss: 0.779844, acc: 0.312500]\n",
      "3823: [D loss: 0.709801, acc: 0.521484]  [A loss: 0.809017, acc: 0.289062]\n",
      "3824: [D loss: 0.707805, acc: 0.498047]  [A loss: 0.829257, acc: 0.230469]\n",
      "3825: [D loss: 0.701160, acc: 0.515625]  [A loss: 0.786050, acc: 0.343750]\n",
      "3826: [D loss: 0.701038, acc: 0.511719]  [A loss: 0.892449, acc: 0.136719]\n",
      "3827: [D loss: 0.703114, acc: 0.525391]  [A loss: 0.777348, acc: 0.312500]\n",
      "3828: [D loss: 0.711743, acc: 0.529297]  [A loss: 0.893668, acc: 0.195312]\n",
      "3829: [D loss: 0.688408, acc: 0.531250]  [A loss: 0.773109, acc: 0.343750]\n",
      "3830: [D loss: 0.704230, acc: 0.500000]  [A loss: 0.878831, acc: 0.203125]\n",
      "3831: [D loss: 0.707886, acc: 0.500000]  [A loss: 0.752216, acc: 0.378906]\n",
      "3832: [D loss: 0.707818, acc: 0.517578]  [A loss: 0.869268, acc: 0.203125]\n",
      "3833: [D loss: 0.696367, acc: 0.531250]  [A loss: 0.823180, acc: 0.269531]\n",
      "3834: [D loss: 0.707223, acc: 0.513672]  [A loss: 0.842734, acc: 0.226562]\n",
      "3835: [D loss: 0.693042, acc: 0.527344]  [A loss: 0.811517, acc: 0.261719]\n",
      "3836: [D loss: 0.705617, acc: 0.515625]  [A loss: 0.895428, acc: 0.148438]\n",
      "3837: [D loss: 0.706518, acc: 0.507812]  [A loss: 0.810906, acc: 0.253906]\n",
      "3838: [D loss: 0.694543, acc: 0.552734]  [A loss: 0.808923, acc: 0.281250]\n",
      "3839: [D loss: 0.709398, acc: 0.505859]  [A loss: 0.864693, acc: 0.191406]\n",
      "3840: [D loss: 0.699595, acc: 0.494141]  [A loss: 0.810708, acc: 0.273438]\n",
      "3841: [D loss: 0.692111, acc: 0.539062]  [A loss: 0.857116, acc: 0.179688]\n",
      "3842: [D loss: 0.707427, acc: 0.525391]  [A loss: 0.799593, acc: 0.308594]\n",
      "3843: [D loss: 0.685162, acc: 0.531250]  [A loss: 0.911615, acc: 0.156250]\n",
      "3844: [D loss: 0.700752, acc: 0.511719]  [A loss: 0.731826, acc: 0.410156]\n",
      "3845: [D loss: 0.714893, acc: 0.503906]  [A loss: 1.047657, acc: 0.058594]\n",
      "3846: [D loss: 0.712892, acc: 0.523438]  [A loss: 0.705366, acc: 0.503906]\n",
      "3847: [D loss: 0.750482, acc: 0.470703]  [A loss: 0.851746, acc: 0.199219]\n",
      "3848: [D loss: 0.725272, acc: 0.486328]  [A loss: 0.969292, acc: 0.097656]\n",
      "3849: [D loss: 0.698006, acc: 0.529297]  [A loss: 0.737246, acc: 0.410156]\n",
      "3850: [D loss: 0.710690, acc: 0.507812]  [A loss: 0.941604, acc: 0.097656]\n",
      "3851: [D loss: 0.689532, acc: 0.541016]  [A loss: 0.736243, acc: 0.414062]\n",
      "3852: [D loss: 0.710709, acc: 0.523438]  [A loss: 0.969211, acc: 0.074219]\n",
      "3853: [D loss: 0.691775, acc: 0.544922]  [A loss: 0.721150, acc: 0.445312]\n",
      "3854: [D loss: 0.707240, acc: 0.525391]  [A loss: 0.846547, acc: 0.214844]\n",
      "3855: [D loss: 0.699475, acc: 0.511719]  [A loss: 0.771258, acc: 0.363281]\n",
      "3856: [D loss: 0.709659, acc: 0.519531]  [A loss: 0.813543, acc: 0.300781]\n",
      "3857: [D loss: 0.705203, acc: 0.529297]  [A loss: 0.836788, acc: 0.207031]\n",
      "3858: [D loss: 0.695396, acc: 0.523438]  [A loss: 0.815115, acc: 0.285156]\n",
      "3859: [D loss: 0.705618, acc: 0.519531]  [A loss: 0.867016, acc: 0.156250]\n",
      "3860: [D loss: 0.703598, acc: 0.519531]  [A loss: 0.887727, acc: 0.152344]\n",
      "3861: [D loss: 0.685513, acc: 0.578125]  [A loss: 0.770439, acc: 0.367188]\n",
      "3862: [D loss: 0.706001, acc: 0.519531]  [A loss: 0.931715, acc: 0.132812]\n",
      "3863: [D loss: 0.696727, acc: 0.527344]  [A loss: 0.741960, acc: 0.425781]\n",
      "3864: [D loss: 0.730208, acc: 0.507812]  [A loss: 1.041831, acc: 0.046875]\n",
      "3865: [D loss: 0.694869, acc: 0.527344]  [A loss: 0.663040, acc: 0.597656]\n",
      "3866: [D loss: 0.745674, acc: 0.488281]  [A loss: 0.925503, acc: 0.144531]\n",
      "3867: [D loss: 0.694164, acc: 0.548828]  [A loss: 0.749017, acc: 0.406250]\n",
      "3868: [D loss: 0.715366, acc: 0.500000]  [A loss: 0.886274, acc: 0.187500]\n",
      "3869: [D loss: 0.692470, acc: 0.546875]  [A loss: 0.706128, acc: 0.476562]\n",
      "3870: [D loss: 0.733201, acc: 0.468750]  [A loss: 0.974696, acc: 0.089844]\n",
      "3871: [D loss: 0.698967, acc: 0.507812]  [A loss: 0.697995, acc: 0.500000]\n",
      "3872: [D loss: 0.698961, acc: 0.531250]  [A loss: 0.836910, acc: 0.246094]\n",
      "3873: [D loss: 0.703723, acc: 0.527344]  [A loss: 0.779438, acc: 0.339844]\n",
      "3874: [D loss: 0.710936, acc: 0.527344]  [A loss: 0.852146, acc: 0.203125]\n",
      "3875: [D loss: 0.698881, acc: 0.533203]  [A loss: 0.719269, acc: 0.480469]\n",
      "3876: [D loss: 0.716291, acc: 0.492188]  [A loss: 0.879944, acc: 0.183594]\n",
      "3877: [D loss: 0.707697, acc: 0.490234]  [A loss: 0.686212, acc: 0.511719]\n",
      "3878: [D loss: 0.728672, acc: 0.494141]  [A loss: 0.952413, acc: 0.089844]\n",
      "3879: [D loss: 0.696031, acc: 0.525391]  [A loss: 0.720299, acc: 0.480469]\n",
      "3880: [D loss: 0.713783, acc: 0.496094]  [A loss: 0.868800, acc: 0.175781]\n",
      "3881: [D loss: 0.697696, acc: 0.533203]  [A loss: 0.809820, acc: 0.273438]\n",
      "3882: [D loss: 0.687380, acc: 0.556641]  [A loss: 0.875163, acc: 0.179688]\n",
      "3883: [D loss: 0.690906, acc: 0.554688]  [A loss: 0.803927, acc: 0.269531]\n",
      "3884: [D loss: 0.701119, acc: 0.521484]  [A loss: 0.831299, acc: 0.242188]\n",
      "3885: [D loss: 0.703543, acc: 0.492188]  [A loss: 0.871502, acc: 0.164062]\n",
      "3886: [D loss: 0.705520, acc: 0.507812]  [A loss: 0.795143, acc: 0.246094]\n",
      "3887: [D loss: 0.698359, acc: 0.550781]  [A loss: 0.815745, acc: 0.234375]\n",
      "3888: [D loss: 0.703325, acc: 0.505859]  [A loss: 0.798626, acc: 0.292969]\n",
      "3889: [D loss: 0.707810, acc: 0.478516]  [A loss: 0.882227, acc: 0.187500]\n",
      "3890: [D loss: 0.699485, acc: 0.533203]  [A loss: 0.741702, acc: 0.433594]\n",
      "3891: [D loss: 0.718644, acc: 0.498047]  [A loss: 1.046536, acc: 0.042969]\n",
      "3892: [D loss: 0.719117, acc: 0.517578]  [A loss: 0.728919, acc: 0.421875]\n",
      "3893: [D loss: 0.711790, acc: 0.503906]  [A loss: 0.875515, acc: 0.179688]\n",
      "3894: [D loss: 0.694115, acc: 0.515625]  [A loss: 0.798814, acc: 0.292969]\n",
      "3895: [D loss: 0.706649, acc: 0.523438]  [A loss: 0.852586, acc: 0.210938]\n",
      "3896: [D loss: 0.699211, acc: 0.523438]  [A loss: 0.806790, acc: 0.316406]\n",
      "3897: [D loss: 0.702210, acc: 0.509766]  [A loss: 0.827433, acc: 0.234375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3898: [D loss: 0.697410, acc: 0.533203]  [A loss: 0.843128, acc: 0.234375]\n",
      "3899: [D loss: 0.704480, acc: 0.503906]  [A loss: 0.830510, acc: 0.222656]\n",
      "3900: [D loss: 0.706603, acc: 0.517578]  [A loss: 0.968831, acc: 0.093750]\n",
      "3901: [D loss: 0.699821, acc: 0.507812]  [A loss: 0.718538, acc: 0.464844]\n",
      "3902: [D loss: 0.712462, acc: 0.505859]  [A loss: 0.894871, acc: 0.187500]\n",
      "3903: [D loss: 0.694376, acc: 0.541016]  [A loss: 0.749258, acc: 0.398438]\n",
      "3904: [D loss: 0.700693, acc: 0.550781]  [A loss: 0.848044, acc: 0.203125]\n",
      "3905: [D loss: 0.701121, acc: 0.533203]  [A loss: 0.835176, acc: 0.214844]\n",
      "3906: [D loss: 0.680152, acc: 0.550781]  [A loss: 0.841488, acc: 0.210938]\n",
      "3907: [D loss: 0.702747, acc: 0.521484]  [A loss: 0.760958, acc: 0.398438]\n",
      "3908: [D loss: 0.696624, acc: 0.529297]  [A loss: 0.912284, acc: 0.152344]\n",
      "3909: [D loss: 0.706183, acc: 0.507812]  [A loss: 0.742011, acc: 0.421875]\n",
      "3910: [D loss: 0.714495, acc: 0.509766]  [A loss: 1.021154, acc: 0.062500]\n",
      "3911: [D loss: 0.705907, acc: 0.509766]  [A loss: 0.668946, acc: 0.578125]\n",
      "3912: [D loss: 0.692730, acc: 0.550781]  [A loss: 0.822997, acc: 0.226562]\n",
      "3913: [D loss: 0.701552, acc: 0.517578]  [A loss: 0.773345, acc: 0.347656]\n",
      "3914: [D loss: 0.708649, acc: 0.509766]  [A loss: 0.871457, acc: 0.160156]\n",
      "3915: [D loss: 0.713944, acc: 0.488281]  [A loss: 0.813914, acc: 0.277344]\n",
      "3916: [D loss: 0.699585, acc: 0.511719]  [A loss: 0.924831, acc: 0.136719]\n",
      "3917: [D loss: 0.695795, acc: 0.511719]  [A loss: 0.751738, acc: 0.402344]\n",
      "3918: [D loss: 0.695529, acc: 0.539062]  [A loss: 0.877572, acc: 0.164062]\n",
      "3919: [D loss: 0.684501, acc: 0.566406]  [A loss: 0.800935, acc: 0.339844]\n",
      "3920: [D loss: 0.705317, acc: 0.533203]  [A loss: 0.935595, acc: 0.121094]\n",
      "3921: [D loss: 0.696662, acc: 0.517578]  [A loss: 0.737834, acc: 0.402344]\n",
      "3922: [D loss: 0.703600, acc: 0.537109]  [A loss: 0.835728, acc: 0.234375]\n",
      "3923: [D loss: 0.689477, acc: 0.542969]  [A loss: 0.778440, acc: 0.304688]\n",
      "3924: [D loss: 0.696671, acc: 0.546875]  [A loss: 0.923750, acc: 0.121094]\n",
      "3925: [D loss: 0.697400, acc: 0.507812]  [A loss: 0.660947, acc: 0.597656]\n",
      "3926: [D loss: 0.736902, acc: 0.533203]  [A loss: 1.071053, acc: 0.058594]\n",
      "3927: [D loss: 0.712771, acc: 0.515625]  [A loss: 0.702108, acc: 0.535156]\n",
      "3928: [D loss: 0.708372, acc: 0.511719]  [A loss: 0.808936, acc: 0.289062]\n",
      "3929: [D loss: 0.702299, acc: 0.507812]  [A loss: 0.746138, acc: 0.367188]\n",
      "3930: [D loss: 0.706342, acc: 0.503906]  [A loss: 0.833590, acc: 0.222656]\n",
      "3931: [D loss: 0.696710, acc: 0.544922]  [A loss: 0.783082, acc: 0.320312]\n",
      "3932: [D loss: 0.694648, acc: 0.509766]  [A loss: 0.824610, acc: 0.250000]\n",
      "3933: [D loss: 0.700136, acc: 0.519531]  [A loss: 0.725979, acc: 0.410156]\n",
      "3934: [D loss: 0.708106, acc: 0.525391]  [A loss: 0.909855, acc: 0.140625]\n",
      "3935: [D loss: 0.682750, acc: 0.560547]  [A loss: 0.741607, acc: 0.445312]\n",
      "3936: [D loss: 0.703972, acc: 0.529297]  [A loss: 0.924684, acc: 0.128906]\n",
      "3937: [D loss: 0.692879, acc: 0.515625]  [A loss: 0.737958, acc: 0.417969]\n",
      "3938: [D loss: 0.703360, acc: 0.525391]  [A loss: 0.870278, acc: 0.222656]\n",
      "3939: [D loss: 0.703094, acc: 0.509766]  [A loss: 0.764361, acc: 0.355469]\n",
      "3940: [D loss: 0.700852, acc: 0.498047]  [A loss: 0.912245, acc: 0.160156]\n",
      "3941: [D loss: 0.691982, acc: 0.523438]  [A loss: 0.699402, acc: 0.488281]\n",
      "3942: [D loss: 0.716461, acc: 0.503906]  [A loss: 1.026414, acc: 0.050781]\n",
      "3943: [D loss: 0.709816, acc: 0.503906]  [A loss: 0.716833, acc: 0.472656]\n",
      "3944: [D loss: 0.714241, acc: 0.517578]  [A loss: 0.805160, acc: 0.269531]\n",
      "3945: [D loss: 0.688585, acc: 0.550781]  [A loss: 0.739135, acc: 0.414062]\n",
      "3946: [D loss: 0.707114, acc: 0.498047]  [A loss: 0.854287, acc: 0.226562]\n",
      "3947: [D loss: 0.699210, acc: 0.503906]  [A loss: 0.759205, acc: 0.367188]\n",
      "3948: [D loss: 0.692693, acc: 0.558594]  [A loss: 0.912602, acc: 0.109375]\n",
      "3949: [D loss: 0.694324, acc: 0.515625]  [A loss: 0.704197, acc: 0.492188]\n",
      "3950: [D loss: 0.718650, acc: 0.525391]  [A loss: 0.952029, acc: 0.109375]\n",
      "3951: [D loss: 0.708494, acc: 0.515625]  [A loss: 0.735065, acc: 0.375000]\n",
      "3952: [D loss: 0.696583, acc: 0.533203]  [A loss: 0.856298, acc: 0.195312]\n",
      "3953: [D loss: 0.691778, acc: 0.537109]  [A loss: 0.763789, acc: 0.347656]\n",
      "3954: [D loss: 0.715995, acc: 0.531250]  [A loss: 0.947634, acc: 0.097656]\n",
      "3955: [D loss: 0.699252, acc: 0.531250]  [A loss: 0.677273, acc: 0.562500]\n",
      "3956: [D loss: 0.733979, acc: 0.498047]  [A loss: 0.898313, acc: 0.140625]\n",
      "3957: [D loss: 0.693609, acc: 0.515625]  [A loss: 0.736371, acc: 0.433594]\n",
      "3958: [D loss: 0.705224, acc: 0.539062]  [A loss: 0.836311, acc: 0.238281]\n",
      "3959: [D loss: 0.705951, acc: 0.501953]  [A loss: 0.772334, acc: 0.359375]\n",
      "3960: [D loss: 0.698230, acc: 0.544922]  [A loss: 0.804470, acc: 0.281250]\n",
      "3961: [D loss: 0.694842, acc: 0.531250]  [A loss: 0.768455, acc: 0.371094]\n",
      "3962: [D loss: 0.698493, acc: 0.533203]  [A loss: 0.865344, acc: 0.195312]\n",
      "3963: [D loss: 0.703546, acc: 0.501953]  [A loss: 0.778473, acc: 0.335938]\n",
      "3964: [D loss: 0.711087, acc: 0.486328]  [A loss: 0.890731, acc: 0.144531]\n",
      "3965: [D loss: 0.692316, acc: 0.527344]  [A loss: 0.744882, acc: 0.410156]\n",
      "3966: [D loss: 0.703305, acc: 0.546875]  [A loss: 0.808030, acc: 0.253906]\n",
      "3967: [D loss: 0.694084, acc: 0.558594]  [A loss: 0.842238, acc: 0.242188]\n",
      "3968: [D loss: 0.711113, acc: 0.515625]  [A loss: 0.873310, acc: 0.179688]\n",
      "3969: [D loss: 0.689340, acc: 0.539062]  [A loss: 0.761889, acc: 0.359375]\n",
      "3970: [D loss: 0.716669, acc: 0.517578]  [A loss: 1.036001, acc: 0.082031]\n",
      "3971: [D loss: 0.709390, acc: 0.503906]  [A loss: 0.695766, acc: 0.523438]\n",
      "3972: [D loss: 0.715674, acc: 0.505859]  [A loss: 0.831098, acc: 0.226562]\n",
      "3973: [D loss: 0.696939, acc: 0.533203]  [A loss: 0.777625, acc: 0.351562]\n",
      "3974: [D loss: 0.712206, acc: 0.509766]  [A loss: 0.867202, acc: 0.167969]\n",
      "3975: [D loss: 0.686149, acc: 0.560547]  [A loss: 0.765092, acc: 0.355469]\n",
      "3976: [D loss: 0.710327, acc: 0.496094]  [A loss: 0.910440, acc: 0.132812]\n",
      "3977: [D loss: 0.697762, acc: 0.542969]  [A loss: 0.685528, acc: 0.546875]\n",
      "3978: [D loss: 0.743178, acc: 0.505859]  [A loss: 1.086836, acc: 0.042969]\n",
      "3979: [D loss: 0.700970, acc: 0.523438]  [A loss: 0.748754, acc: 0.386719]\n",
      "3980: [D loss: 0.707794, acc: 0.509766]  [A loss: 0.813398, acc: 0.257812]\n",
      "3981: [D loss: 0.701264, acc: 0.513672]  [A loss: 0.800841, acc: 0.277344]\n",
      "3982: [D loss: 0.710152, acc: 0.525391]  [A loss: 0.888988, acc: 0.164062]\n",
      "3983: [D loss: 0.695000, acc: 0.515625]  [A loss: 0.702903, acc: 0.515625]\n",
      "3984: [D loss: 0.701574, acc: 0.533203]  [A loss: 0.919843, acc: 0.140625]\n",
      "3985: [D loss: 0.711945, acc: 0.476562]  [A loss: 0.705098, acc: 0.460938]\n",
      "3986: [D loss: 0.715185, acc: 0.488281]  [A loss: 0.904787, acc: 0.109375]\n",
      "3987: [D loss: 0.681701, acc: 0.564453]  [A loss: 0.703486, acc: 0.507812]\n",
      "3988: [D loss: 0.720421, acc: 0.501953]  [A loss: 0.866193, acc: 0.179688]\n",
      "3989: [D loss: 0.694434, acc: 0.533203]  [A loss: 0.783809, acc: 0.343750]\n",
      "3990: [D loss: 0.689546, acc: 0.533203]  [A loss: 0.861003, acc: 0.195312]\n",
      "3991: [D loss: 0.705765, acc: 0.507812]  [A loss: 0.772668, acc: 0.335938]\n",
      "3992: [D loss: 0.690122, acc: 0.552734]  [A loss: 0.810191, acc: 0.300781]\n",
      "3993: [D loss: 0.683142, acc: 0.566406]  [A loss: 0.748574, acc: 0.414062]\n",
      "3994: [D loss: 0.710488, acc: 0.503906]  [A loss: 0.854476, acc: 0.222656]\n",
      "3995: [D loss: 0.698388, acc: 0.517578]  [A loss: 0.714969, acc: 0.449219]\n",
      "3996: [D loss: 0.712252, acc: 0.498047]  [A loss: 0.858131, acc: 0.203125]\n",
      "3997: [D loss: 0.693403, acc: 0.525391]  [A loss: 0.782138, acc: 0.320312]\n",
      "3998: [D loss: 0.711669, acc: 0.507812]  [A loss: 0.836040, acc: 0.281250]\n",
      "3999: [D loss: 0.694132, acc: 0.531250]  [A loss: 0.808815, acc: 0.277344]\n",
      "4000: [D loss: 0.702377, acc: 0.539062]  [A loss: 0.843142, acc: 0.207031]\n",
      "4001: [D loss: 0.701367, acc: 0.507812]  [A loss: 0.818768, acc: 0.289062]\n",
      "4002: [D loss: 0.711813, acc: 0.484375]  [A loss: 0.782588, acc: 0.339844]\n",
      "4003: [D loss: 0.688674, acc: 0.574219]  [A loss: 0.882161, acc: 0.183594]\n",
      "4004: [D loss: 0.712521, acc: 0.500000]  [A loss: 0.721396, acc: 0.433594]\n",
      "4005: [D loss: 0.717334, acc: 0.507812]  [A loss: 0.935136, acc: 0.167969]\n",
      "4006: [D loss: 0.721319, acc: 0.470703]  [A loss: 0.799159, acc: 0.273438]\n",
      "4007: [D loss: 0.701779, acc: 0.527344]  [A loss: 0.995177, acc: 0.042969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4008: [D loss: 0.698519, acc: 0.539062]  [A loss: 0.690871, acc: 0.539062]\n",
      "4009: [D loss: 0.708569, acc: 0.511719]  [A loss: 0.888996, acc: 0.179688]\n",
      "4010: [D loss: 0.703608, acc: 0.500000]  [A loss: 0.693922, acc: 0.507812]\n",
      "4011: [D loss: 0.704419, acc: 0.507812]  [A loss: 0.926248, acc: 0.132812]\n",
      "4012: [D loss: 0.708657, acc: 0.500000]  [A loss: 0.732065, acc: 0.425781]\n",
      "4013: [D loss: 0.713769, acc: 0.507812]  [A loss: 0.864651, acc: 0.203125]\n",
      "4014: [D loss: 0.699410, acc: 0.537109]  [A loss: 0.743469, acc: 0.371094]\n",
      "4015: [D loss: 0.714110, acc: 0.507812]  [A loss: 0.913924, acc: 0.109375]\n",
      "4016: [D loss: 0.682322, acc: 0.572266]  [A loss: 0.696957, acc: 0.527344]\n",
      "4017: [D loss: 0.739986, acc: 0.503906]  [A loss: 0.953127, acc: 0.105469]\n",
      "4018: [D loss: 0.700720, acc: 0.505859]  [A loss: 0.768747, acc: 0.386719]\n",
      "4019: [D loss: 0.708038, acc: 0.509766]  [A loss: 0.849827, acc: 0.234375]\n",
      "4020: [D loss: 0.709385, acc: 0.507812]  [A loss: 0.820383, acc: 0.246094]\n",
      "4021: [D loss: 0.724790, acc: 0.468750]  [A loss: 0.735329, acc: 0.433594]\n",
      "4022: [D loss: 0.704742, acc: 0.501953]  [A loss: 0.853551, acc: 0.246094]\n",
      "4023: [D loss: 0.692325, acc: 0.558594]  [A loss: 0.795839, acc: 0.316406]\n",
      "4024: [D loss: 0.716685, acc: 0.503906]  [A loss: 0.813032, acc: 0.265625]\n",
      "4025: [D loss: 0.707949, acc: 0.505859]  [A loss: 0.832540, acc: 0.234375]\n",
      "4026: [D loss: 0.695010, acc: 0.517578]  [A loss: 0.801987, acc: 0.285156]\n",
      "4027: [D loss: 0.699956, acc: 0.533203]  [A loss: 0.773997, acc: 0.363281]\n",
      "4028: [D loss: 0.703438, acc: 0.521484]  [A loss: 0.827541, acc: 0.238281]\n",
      "4029: [D loss: 0.698982, acc: 0.515625]  [A loss: 0.831620, acc: 0.238281]\n",
      "4030: [D loss: 0.707950, acc: 0.496094]  [A loss: 0.804052, acc: 0.253906]\n",
      "4031: [D loss: 0.713506, acc: 0.507812]  [A loss: 0.869254, acc: 0.175781]\n",
      "4032: [D loss: 0.696706, acc: 0.537109]  [A loss: 0.829468, acc: 0.261719]\n",
      "4033: [D loss: 0.690500, acc: 0.537109]  [A loss: 0.813767, acc: 0.257812]\n",
      "4034: [D loss: 0.697445, acc: 0.546875]  [A loss: 0.816420, acc: 0.269531]\n",
      "4035: [D loss: 0.701367, acc: 0.542969]  [A loss: 0.891410, acc: 0.160156]\n",
      "4036: [D loss: 0.674262, acc: 0.578125]  [A loss: 0.782489, acc: 0.351562]\n",
      "4037: [D loss: 0.701709, acc: 0.535156]  [A loss: 0.940885, acc: 0.136719]\n",
      "4038: [D loss: 0.705183, acc: 0.505859]  [A loss: 0.730524, acc: 0.425781]\n",
      "4039: [D loss: 0.716297, acc: 0.517578]  [A loss: 0.910342, acc: 0.171875]\n",
      "4040: [D loss: 0.704548, acc: 0.519531]  [A loss: 0.702306, acc: 0.503906]\n",
      "4041: [D loss: 0.713835, acc: 0.501953]  [A loss: 0.895310, acc: 0.171875]\n",
      "4042: [D loss: 0.698229, acc: 0.517578]  [A loss: 0.740231, acc: 0.445312]\n",
      "4043: [D loss: 0.720117, acc: 0.513672]  [A loss: 0.922179, acc: 0.144531]\n",
      "4044: [D loss: 0.691709, acc: 0.533203]  [A loss: 0.732528, acc: 0.414062]\n",
      "4045: [D loss: 0.716976, acc: 0.513672]  [A loss: 0.942388, acc: 0.140625]\n",
      "4046: [D loss: 0.718198, acc: 0.505859]  [A loss: 0.760985, acc: 0.375000]\n",
      "4047: [D loss: 0.722498, acc: 0.519531]  [A loss: 0.922646, acc: 0.148438]\n",
      "4048: [D loss: 0.697552, acc: 0.517578]  [A loss: 0.752626, acc: 0.378906]\n",
      "4049: [D loss: 0.718178, acc: 0.517578]  [A loss: 0.850129, acc: 0.218750]\n",
      "4050: [D loss: 0.702172, acc: 0.500000]  [A loss: 0.804464, acc: 0.308594]\n",
      "4051: [D loss: 0.701850, acc: 0.509766]  [A loss: 0.760372, acc: 0.378906]\n",
      "4052: [D loss: 0.706908, acc: 0.505859]  [A loss: 0.844395, acc: 0.238281]\n",
      "4053: [D loss: 0.692198, acc: 0.535156]  [A loss: 0.776323, acc: 0.351562]\n",
      "4054: [D loss: 0.709083, acc: 0.544922]  [A loss: 0.894199, acc: 0.140625]\n",
      "4055: [D loss: 0.706296, acc: 0.505859]  [A loss: 0.763852, acc: 0.335938]\n",
      "4056: [D loss: 0.713404, acc: 0.525391]  [A loss: 0.871747, acc: 0.214844]\n",
      "4057: [D loss: 0.692422, acc: 0.521484]  [A loss: 0.803748, acc: 0.285156]\n",
      "4058: [D loss: 0.716537, acc: 0.462891]  [A loss: 0.836830, acc: 0.214844]\n",
      "4059: [D loss: 0.701208, acc: 0.552734]  [A loss: 0.764520, acc: 0.363281]\n",
      "4060: [D loss: 0.715677, acc: 0.503906]  [A loss: 0.886364, acc: 0.187500]\n",
      "4061: [D loss: 0.694706, acc: 0.558594]  [A loss: 0.771247, acc: 0.335938]\n",
      "4062: [D loss: 0.691761, acc: 0.533203]  [A loss: 0.864863, acc: 0.160156]\n",
      "4063: [D loss: 0.689129, acc: 0.535156]  [A loss: 0.711373, acc: 0.480469]\n",
      "4064: [D loss: 0.733828, acc: 0.505859]  [A loss: 1.001805, acc: 0.105469]\n",
      "4065: [D loss: 0.675913, acc: 0.578125]  [A loss: 0.749570, acc: 0.445312]\n",
      "4066: [D loss: 0.735211, acc: 0.482422]  [A loss: 0.870948, acc: 0.160156]\n",
      "4067: [D loss: 0.698348, acc: 0.537109]  [A loss: 0.761768, acc: 0.378906]\n",
      "4068: [D loss: 0.710174, acc: 0.533203]  [A loss: 0.858021, acc: 0.191406]\n",
      "4069: [D loss: 0.687769, acc: 0.544922]  [A loss: 0.777641, acc: 0.359375]\n",
      "4070: [D loss: 0.706644, acc: 0.494141]  [A loss: 0.881700, acc: 0.191406]\n",
      "4071: [D loss: 0.695804, acc: 0.527344]  [A loss: 0.731024, acc: 0.441406]\n",
      "4072: [D loss: 0.715395, acc: 0.509766]  [A loss: 0.901626, acc: 0.136719]\n",
      "4073: [D loss: 0.706190, acc: 0.505859]  [A loss: 0.738748, acc: 0.414062]\n",
      "4074: [D loss: 0.718187, acc: 0.513672]  [A loss: 0.966704, acc: 0.101562]\n",
      "4075: [D loss: 0.702124, acc: 0.503906]  [A loss: 0.695774, acc: 0.542969]\n",
      "4076: [D loss: 0.705360, acc: 0.521484]  [A loss: 0.916975, acc: 0.148438]\n",
      "4077: [D loss: 0.694926, acc: 0.527344]  [A loss: 0.776834, acc: 0.328125]\n",
      "4078: [D loss: 0.678914, acc: 0.570312]  [A loss: 0.836609, acc: 0.207031]\n",
      "4079: [D loss: 0.702890, acc: 0.519531]  [A loss: 0.759590, acc: 0.406250]\n",
      "4080: [D loss: 0.720488, acc: 0.507812]  [A loss: 0.917811, acc: 0.148438]\n",
      "4081: [D loss: 0.691343, acc: 0.541016]  [A loss: 0.704741, acc: 0.511719]\n",
      "4082: [D loss: 0.712144, acc: 0.523438]  [A loss: 0.840453, acc: 0.199219]\n",
      "4083: [D loss: 0.696306, acc: 0.529297]  [A loss: 0.774589, acc: 0.335938]\n",
      "4084: [D loss: 0.704078, acc: 0.509766]  [A loss: 0.878122, acc: 0.195312]\n",
      "4085: [D loss: 0.697869, acc: 0.523438]  [A loss: 0.784992, acc: 0.308594]\n",
      "4086: [D loss: 0.716161, acc: 0.503906]  [A loss: 0.888344, acc: 0.136719]\n",
      "4087: [D loss: 0.690337, acc: 0.537109]  [A loss: 0.770821, acc: 0.347656]\n",
      "4088: [D loss: 0.721202, acc: 0.492188]  [A loss: 0.906318, acc: 0.144531]\n",
      "4089: [D loss: 0.698049, acc: 0.517578]  [A loss: 0.713941, acc: 0.445312]\n",
      "4090: [D loss: 0.704089, acc: 0.552734]  [A loss: 0.937079, acc: 0.125000]\n",
      "4091: [D loss: 0.688624, acc: 0.539062]  [A loss: 0.776433, acc: 0.335938]\n",
      "4092: [D loss: 0.699117, acc: 0.523438]  [A loss: 0.897702, acc: 0.144531]\n",
      "4093: [D loss: 0.689672, acc: 0.535156]  [A loss: 0.751234, acc: 0.375000]\n",
      "4094: [D loss: 0.719739, acc: 0.484375]  [A loss: 0.883074, acc: 0.183594]\n",
      "4095: [D loss: 0.692877, acc: 0.554688]  [A loss: 0.718440, acc: 0.453125]\n",
      "4096: [D loss: 0.715549, acc: 0.500000]  [A loss: 0.962850, acc: 0.132812]\n",
      "4097: [D loss: 0.696607, acc: 0.525391]  [A loss: 0.703325, acc: 0.496094]\n",
      "4098: [D loss: 0.703840, acc: 0.517578]  [A loss: 0.875971, acc: 0.179688]\n",
      "4099: [D loss: 0.693434, acc: 0.515625]  [A loss: 0.815606, acc: 0.292969]\n",
      "4100: [D loss: 0.695715, acc: 0.544922]  [A loss: 0.793525, acc: 0.308594]\n",
      "4101: [D loss: 0.692691, acc: 0.533203]  [A loss: 0.835396, acc: 0.230469]\n",
      "4102: [D loss: 0.697435, acc: 0.544922]  [A loss: 0.771635, acc: 0.359375]\n",
      "4103: [D loss: 0.695892, acc: 0.531250]  [A loss: 0.824340, acc: 0.277344]\n",
      "4104: [D loss: 0.671418, acc: 0.605469]  [A loss: 0.853043, acc: 0.207031]\n",
      "4105: [D loss: 0.686716, acc: 0.562500]  [A loss: 0.691660, acc: 0.527344]\n",
      "4106: [D loss: 0.735603, acc: 0.529297]  [A loss: 1.054681, acc: 0.054688]\n",
      "4107: [D loss: 0.698832, acc: 0.529297]  [A loss: 0.694171, acc: 0.519531]\n",
      "4108: [D loss: 0.727280, acc: 0.513672]  [A loss: 0.757003, acc: 0.410156]\n",
      "4109: [D loss: 0.706776, acc: 0.523438]  [A loss: 0.874427, acc: 0.183594]\n",
      "4110: [D loss: 0.687790, acc: 0.541016]  [A loss: 0.728452, acc: 0.417969]\n",
      "4111: [D loss: 0.714791, acc: 0.490234]  [A loss: 0.832848, acc: 0.230469]\n",
      "4112: [D loss: 0.690072, acc: 0.546875]  [A loss: 0.821279, acc: 0.230469]\n",
      "4113: [D loss: 0.703690, acc: 0.535156]  [A loss: 0.808303, acc: 0.289062]\n",
      "4114: [D loss: 0.689370, acc: 0.554688]  [A loss: 0.839314, acc: 0.222656]\n",
      "4115: [D loss: 0.692075, acc: 0.552734]  [A loss: 0.780528, acc: 0.343750]\n",
      "4116: [D loss: 0.709597, acc: 0.513672]  [A loss: 0.825915, acc: 0.234375]\n",
      "4117: [D loss: 0.691197, acc: 0.531250]  [A loss: 0.825896, acc: 0.246094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4118: [D loss: 0.695913, acc: 0.548828]  [A loss: 0.851755, acc: 0.242188]\n",
      "4119: [D loss: 0.684790, acc: 0.542969]  [A loss: 0.797593, acc: 0.308594]\n",
      "4120: [D loss: 0.699641, acc: 0.525391]  [A loss: 0.829342, acc: 0.257812]\n",
      "4121: [D loss: 0.717928, acc: 0.486328]  [A loss: 0.934134, acc: 0.089844]\n",
      "4122: [D loss: 0.689568, acc: 0.550781]  [A loss: 0.713402, acc: 0.519531]\n",
      "4123: [D loss: 0.714156, acc: 0.523438]  [A loss: 0.925179, acc: 0.132812]\n",
      "4124: [D loss: 0.690226, acc: 0.552734]  [A loss: 0.773854, acc: 0.390625]\n",
      "4125: [D loss: 0.721289, acc: 0.482422]  [A loss: 0.827570, acc: 0.289062]\n",
      "4126: [D loss: 0.703508, acc: 0.509766]  [A loss: 0.868654, acc: 0.179688]\n",
      "4127: [D loss: 0.686649, acc: 0.537109]  [A loss: 0.746119, acc: 0.437500]\n",
      "4128: [D loss: 0.706335, acc: 0.513672]  [A loss: 0.949397, acc: 0.117188]\n",
      "4129: [D loss: 0.689649, acc: 0.521484]  [A loss: 0.682188, acc: 0.554688]\n",
      "4130: [D loss: 0.692918, acc: 0.541016]  [A loss: 0.890485, acc: 0.152344]\n",
      "4131: [D loss: 0.701118, acc: 0.531250]  [A loss: 0.757206, acc: 0.417969]\n",
      "4132: [D loss: 0.726593, acc: 0.466797]  [A loss: 0.864796, acc: 0.191406]\n",
      "4133: [D loss: 0.693022, acc: 0.537109]  [A loss: 0.795736, acc: 0.304688]\n",
      "4134: [D loss: 0.699857, acc: 0.550781]  [A loss: 0.845203, acc: 0.246094]\n",
      "4135: [D loss: 0.702123, acc: 0.544922]  [A loss: 0.774690, acc: 0.355469]\n",
      "4136: [D loss: 0.714274, acc: 0.523438]  [A loss: 0.850260, acc: 0.171875]\n",
      "4137: [D loss: 0.704987, acc: 0.513672]  [A loss: 0.758973, acc: 0.375000]\n",
      "4138: [D loss: 0.711044, acc: 0.509766]  [A loss: 0.974196, acc: 0.113281]\n",
      "4139: [D loss: 0.696943, acc: 0.511719]  [A loss: 0.741829, acc: 0.433594]\n",
      "4140: [D loss: 0.709805, acc: 0.541016]  [A loss: 0.842494, acc: 0.214844]\n",
      "4141: [D loss: 0.699898, acc: 0.537109]  [A loss: 0.801161, acc: 0.289062]\n",
      "4142: [D loss: 0.711047, acc: 0.501953]  [A loss: 0.942435, acc: 0.128906]\n",
      "4143: [D loss: 0.697024, acc: 0.513672]  [A loss: 0.713512, acc: 0.480469]\n",
      "4144: [D loss: 0.711391, acc: 0.515625]  [A loss: 0.949105, acc: 0.066406]\n",
      "4145: [D loss: 0.710704, acc: 0.498047]  [A loss: 0.763865, acc: 0.347656]\n",
      "4146: [D loss: 0.719020, acc: 0.517578]  [A loss: 0.986293, acc: 0.062500]\n",
      "4147: [D loss: 0.714810, acc: 0.492188]  [A loss: 0.708811, acc: 0.480469]\n",
      "4148: [D loss: 0.733774, acc: 0.490234]  [A loss: 0.943712, acc: 0.089844]\n",
      "4149: [D loss: 0.708558, acc: 0.517578]  [A loss: 0.744906, acc: 0.414062]\n",
      "4150: [D loss: 0.714527, acc: 0.505859]  [A loss: 0.832481, acc: 0.210938]\n",
      "4151: [D loss: 0.699238, acc: 0.529297]  [A loss: 0.775056, acc: 0.343750]\n",
      "4152: [D loss: 0.707568, acc: 0.517578]  [A loss: 0.909367, acc: 0.148438]\n",
      "4153: [D loss: 0.696683, acc: 0.541016]  [A loss: 0.790136, acc: 0.273438]\n",
      "4154: [D loss: 0.713545, acc: 0.515625]  [A loss: 0.870606, acc: 0.187500]\n",
      "4155: [D loss: 0.686469, acc: 0.560547]  [A loss: 0.749857, acc: 0.390625]\n",
      "4156: [D loss: 0.716897, acc: 0.509766]  [A loss: 0.924487, acc: 0.152344]\n",
      "4157: [D loss: 0.712058, acc: 0.484375]  [A loss: 0.796094, acc: 0.320312]\n",
      "4158: [D loss: 0.704173, acc: 0.498047]  [A loss: 0.853091, acc: 0.214844]\n",
      "4159: [D loss: 0.687862, acc: 0.542969]  [A loss: 0.786361, acc: 0.312500]\n",
      "4160: [D loss: 0.707388, acc: 0.523438]  [A loss: 0.899662, acc: 0.191406]\n",
      "4161: [D loss: 0.695207, acc: 0.535156]  [A loss: 0.798508, acc: 0.300781]\n",
      "4162: [D loss: 0.704867, acc: 0.544922]  [A loss: 0.839400, acc: 0.226562]\n",
      "4163: [D loss: 0.702601, acc: 0.507812]  [A loss: 0.804928, acc: 0.289062]\n",
      "4164: [D loss: 0.686146, acc: 0.542969]  [A loss: 0.817381, acc: 0.250000]\n",
      "4165: [D loss: 0.701531, acc: 0.515625]  [A loss: 0.896985, acc: 0.128906]\n",
      "4166: [D loss: 0.690320, acc: 0.537109]  [A loss: 0.701476, acc: 0.546875]\n",
      "4167: [D loss: 0.709921, acc: 0.531250]  [A loss: 0.981142, acc: 0.101562]\n",
      "4168: [D loss: 0.702370, acc: 0.521484]  [A loss: 0.791829, acc: 0.328125]\n",
      "4169: [D loss: 0.697578, acc: 0.544922]  [A loss: 0.821205, acc: 0.234375]\n",
      "4170: [D loss: 0.692102, acc: 0.558594]  [A loss: 0.786199, acc: 0.300781]\n",
      "4171: [D loss: 0.684897, acc: 0.570312]  [A loss: 0.912736, acc: 0.156250]\n",
      "4172: [D loss: 0.724989, acc: 0.466797]  [A loss: 0.689960, acc: 0.562500]\n",
      "4173: [D loss: 0.726435, acc: 0.496094]  [A loss: 1.038429, acc: 0.058594]\n",
      "4174: [D loss: 0.701188, acc: 0.511719]  [A loss: 0.667464, acc: 0.582031]\n",
      "4175: [D loss: 0.724910, acc: 0.519531]  [A loss: 0.985693, acc: 0.058594]\n",
      "4176: [D loss: 0.688951, acc: 0.546875]  [A loss: 0.702873, acc: 0.507812]\n",
      "4177: [D loss: 0.730095, acc: 0.521484]  [A loss: 0.886711, acc: 0.171875]\n",
      "4178: [D loss: 0.697338, acc: 0.539062]  [A loss: 0.751871, acc: 0.375000]\n",
      "4179: [D loss: 0.700137, acc: 0.519531]  [A loss: 0.836060, acc: 0.210938]\n",
      "4180: [D loss: 0.697614, acc: 0.537109]  [A loss: 0.863011, acc: 0.183594]\n",
      "4181: [D loss: 0.693074, acc: 0.529297]  [A loss: 0.763178, acc: 0.335938]\n",
      "4182: [D loss: 0.702155, acc: 0.525391]  [A loss: 0.865394, acc: 0.210938]\n",
      "4183: [D loss: 0.697536, acc: 0.527344]  [A loss: 0.835248, acc: 0.222656]\n",
      "4184: [D loss: 0.686948, acc: 0.542969]  [A loss: 0.800497, acc: 0.300781]\n",
      "4185: [D loss: 0.689335, acc: 0.552734]  [A loss: 0.896871, acc: 0.148438]\n",
      "4186: [D loss: 0.698313, acc: 0.539062]  [A loss: 0.762289, acc: 0.375000]\n",
      "4187: [D loss: 0.718442, acc: 0.523438]  [A loss: 0.982812, acc: 0.109375]\n",
      "4188: [D loss: 0.687599, acc: 0.552734]  [A loss: 0.734849, acc: 0.410156]\n",
      "4189: [D loss: 0.705551, acc: 0.517578]  [A loss: 0.816256, acc: 0.269531]\n",
      "4190: [D loss: 0.705127, acc: 0.490234]  [A loss: 0.928039, acc: 0.148438]\n",
      "4191: [D loss: 0.696363, acc: 0.541016]  [A loss: 0.761738, acc: 0.371094]\n",
      "4192: [D loss: 0.695122, acc: 0.562500]  [A loss: 0.829918, acc: 0.257812]\n",
      "4193: [D loss: 0.708068, acc: 0.525391]  [A loss: 0.913672, acc: 0.156250]\n",
      "4194: [D loss: 0.695293, acc: 0.537109]  [A loss: 0.744994, acc: 0.390625]\n",
      "4195: [D loss: 0.696348, acc: 0.552734]  [A loss: 0.925045, acc: 0.125000]\n",
      "4196: [D loss: 0.701017, acc: 0.511719]  [A loss: 0.681343, acc: 0.554688]\n",
      "4197: [D loss: 0.719200, acc: 0.537109]  [A loss: 0.930789, acc: 0.152344]\n",
      "4198: [D loss: 0.702661, acc: 0.519531]  [A loss: 0.750535, acc: 0.421875]\n",
      "4199: [D loss: 0.686000, acc: 0.548828]  [A loss: 0.869824, acc: 0.183594]\n",
      "4200: [D loss: 0.691893, acc: 0.527344]  [A loss: 0.767270, acc: 0.335938]\n",
      "4201: [D loss: 0.719194, acc: 0.494141]  [A loss: 0.892299, acc: 0.191406]\n",
      "4202: [D loss: 0.695612, acc: 0.521484]  [A loss: 0.747794, acc: 0.398438]\n",
      "4203: [D loss: 0.705557, acc: 0.505859]  [A loss: 0.934181, acc: 0.113281]\n",
      "4204: [D loss: 0.705738, acc: 0.472656]  [A loss: 0.761448, acc: 0.386719]\n",
      "4205: [D loss: 0.708233, acc: 0.521484]  [A loss: 0.944691, acc: 0.125000]\n",
      "4206: [D loss: 0.707532, acc: 0.509766]  [A loss: 0.695136, acc: 0.539062]\n",
      "4207: [D loss: 0.698396, acc: 0.542969]  [A loss: 0.978290, acc: 0.097656]\n",
      "4208: [D loss: 0.707966, acc: 0.494141]  [A loss: 0.701872, acc: 0.468750]\n",
      "4209: [D loss: 0.714169, acc: 0.519531]  [A loss: 0.958841, acc: 0.101562]\n",
      "4210: [D loss: 0.688616, acc: 0.548828]  [A loss: 0.684974, acc: 0.546875]\n",
      "4211: [D loss: 0.713384, acc: 0.525391]  [A loss: 0.839522, acc: 0.253906]\n",
      "4212: [D loss: 0.700830, acc: 0.505859]  [A loss: 0.779690, acc: 0.332031]\n",
      "4213: [D loss: 0.692548, acc: 0.552734]  [A loss: 0.826234, acc: 0.253906]\n",
      "4214: [D loss: 0.686997, acc: 0.548828]  [A loss: 0.794094, acc: 0.343750]\n",
      "4215: [D loss: 0.704549, acc: 0.517578]  [A loss: 0.825135, acc: 0.273438]\n",
      "4216: [D loss: 0.697129, acc: 0.539062]  [A loss: 0.822243, acc: 0.261719]\n",
      "4217: [D loss: 0.705862, acc: 0.494141]  [A loss: 0.823318, acc: 0.273438]\n",
      "4218: [D loss: 0.705017, acc: 0.517578]  [A loss: 0.941650, acc: 0.089844]\n",
      "4219: [D loss: 0.689966, acc: 0.550781]  [A loss: 0.681483, acc: 0.554688]\n",
      "4220: [D loss: 0.731950, acc: 0.501953]  [A loss: 1.012664, acc: 0.078125]\n",
      "4221: [D loss: 0.714657, acc: 0.498047]  [A loss: 0.743148, acc: 0.425781]\n",
      "4222: [D loss: 0.713446, acc: 0.515625]  [A loss: 0.782636, acc: 0.324219]\n",
      "4223: [D loss: 0.697999, acc: 0.542969]  [A loss: 0.881497, acc: 0.183594]\n",
      "4224: [D loss: 0.693838, acc: 0.515625]  [A loss: 0.784465, acc: 0.328125]\n",
      "4225: [D loss: 0.701318, acc: 0.519531]  [A loss: 0.911989, acc: 0.160156]\n",
      "4226: [D loss: 0.705437, acc: 0.511719]  [A loss: 0.714257, acc: 0.519531]\n",
      "4227: [D loss: 0.706305, acc: 0.541016]  [A loss: 0.797312, acc: 0.328125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4228: [D loss: 0.693636, acc: 0.562500]  [A loss: 0.815063, acc: 0.320312]\n",
      "4229: [D loss: 0.710858, acc: 0.492188]  [A loss: 0.816473, acc: 0.281250]\n",
      "4230: [D loss: 0.701558, acc: 0.531250]  [A loss: 0.819680, acc: 0.261719]\n",
      "4231: [D loss: 0.700967, acc: 0.537109]  [A loss: 0.898431, acc: 0.175781]\n",
      "4232: [D loss: 0.711407, acc: 0.509766]  [A loss: 0.753855, acc: 0.367188]\n",
      "4233: [D loss: 0.712419, acc: 0.521484]  [A loss: 0.945535, acc: 0.105469]\n",
      "4234: [D loss: 0.707201, acc: 0.507812]  [A loss: 0.682857, acc: 0.570312]\n",
      "4235: [D loss: 0.707978, acc: 0.501953]  [A loss: 0.927156, acc: 0.187500]\n",
      "4236: [D loss: 0.716859, acc: 0.484375]  [A loss: 0.785966, acc: 0.316406]\n",
      "4237: [D loss: 0.734795, acc: 0.494141]  [A loss: 0.944827, acc: 0.144531]\n",
      "4238: [D loss: 0.695584, acc: 0.519531]  [A loss: 0.730524, acc: 0.437500]\n",
      "4239: [D loss: 0.722263, acc: 0.507812]  [A loss: 0.964943, acc: 0.156250]\n",
      "4240: [D loss: 0.699826, acc: 0.539062]  [A loss: 0.783168, acc: 0.343750]\n",
      "4241: [D loss: 0.709400, acc: 0.496094]  [A loss: 0.865696, acc: 0.218750]\n",
      "4242: [D loss: 0.699426, acc: 0.513672]  [A loss: 0.735142, acc: 0.414062]\n",
      "4243: [D loss: 0.708317, acc: 0.507812]  [A loss: 0.920155, acc: 0.140625]\n",
      "4244: [D loss: 0.698431, acc: 0.533203]  [A loss: 0.751453, acc: 0.390625]\n",
      "4245: [D loss: 0.702707, acc: 0.541016]  [A loss: 0.853933, acc: 0.207031]\n",
      "4246: [D loss: 0.704811, acc: 0.507812]  [A loss: 0.758810, acc: 0.382812]\n",
      "4247: [D loss: 0.710438, acc: 0.519531]  [A loss: 0.939093, acc: 0.132812]\n",
      "4248: [D loss: 0.697477, acc: 0.531250]  [A loss: 0.772707, acc: 0.324219]\n",
      "4249: [D loss: 0.716388, acc: 0.533203]  [A loss: 0.963426, acc: 0.093750]\n",
      "4250: [D loss: 0.692346, acc: 0.537109]  [A loss: 0.701240, acc: 0.515625]\n",
      "4251: [D loss: 0.711569, acc: 0.529297]  [A loss: 0.824650, acc: 0.277344]\n",
      "4252: [D loss: 0.692594, acc: 0.525391]  [A loss: 0.754309, acc: 0.386719]\n",
      "4253: [D loss: 0.723184, acc: 0.505859]  [A loss: 0.911463, acc: 0.187500]\n",
      "4254: [D loss: 0.701244, acc: 0.529297]  [A loss: 0.736131, acc: 0.433594]\n",
      "4255: [D loss: 0.718969, acc: 0.492188]  [A loss: 0.848192, acc: 0.207031]\n",
      "4256: [D loss: 0.694436, acc: 0.529297]  [A loss: 0.758247, acc: 0.371094]\n",
      "4257: [D loss: 0.704427, acc: 0.521484]  [A loss: 0.800426, acc: 0.300781]\n",
      "4258: [D loss: 0.697010, acc: 0.525391]  [A loss: 0.805675, acc: 0.320312]\n",
      "4259: [D loss: 0.704920, acc: 0.503906]  [A loss: 0.875455, acc: 0.214844]\n",
      "4260: [D loss: 0.716975, acc: 0.494141]  [A loss: 0.774310, acc: 0.355469]\n",
      "4261: [D loss: 0.700291, acc: 0.515625]  [A loss: 0.835834, acc: 0.242188]\n",
      "4262: [D loss: 0.704893, acc: 0.521484]  [A loss: 0.746777, acc: 0.414062]\n",
      "4263: [D loss: 0.717798, acc: 0.519531]  [A loss: 0.916662, acc: 0.117188]\n",
      "4264: [D loss: 0.696364, acc: 0.505859]  [A loss: 0.796630, acc: 0.308594]\n",
      "4265: [D loss: 0.712173, acc: 0.509766]  [A loss: 0.957214, acc: 0.113281]\n",
      "4266: [D loss: 0.686999, acc: 0.517578]  [A loss: 0.761529, acc: 0.382812]\n",
      "4267: [D loss: 0.707864, acc: 0.521484]  [A loss: 0.934118, acc: 0.140625]\n",
      "4268: [D loss: 0.689328, acc: 0.550781]  [A loss: 0.728697, acc: 0.464844]\n",
      "4269: [D loss: 0.725368, acc: 0.523438]  [A loss: 0.966008, acc: 0.093750]\n",
      "4270: [D loss: 0.710124, acc: 0.501953]  [A loss: 0.766137, acc: 0.363281]\n",
      "4271: [D loss: 0.708278, acc: 0.519531]  [A loss: 0.802590, acc: 0.296875]\n",
      "4272: [D loss: 0.703060, acc: 0.525391]  [A loss: 1.038615, acc: 0.046875]\n",
      "4273: [D loss: 0.694707, acc: 0.542969]  [A loss: 0.717858, acc: 0.445312]\n",
      "4274: [D loss: 0.718438, acc: 0.511719]  [A loss: 0.867299, acc: 0.179688]\n",
      "4275: [D loss: 0.693607, acc: 0.546875]  [A loss: 0.745444, acc: 0.402344]\n",
      "4276: [D loss: 0.705295, acc: 0.525391]  [A loss: 0.844125, acc: 0.230469]\n",
      "4277: [D loss: 0.706340, acc: 0.507812]  [A loss: 0.810756, acc: 0.292969]\n",
      "4278: [D loss: 0.718977, acc: 0.482422]  [A loss: 0.865541, acc: 0.175781]\n",
      "4279: [D loss: 0.699826, acc: 0.517578]  [A loss: 0.847541, acc: 0.226562]\n",
      "4280: [D loss: 0.695404, acc: 0.525391]  [A loss: 0.898426, acc: 0.156250]\n",
      "4281: [D loss: 0.690082, acc: 0.550781]  [A loss: 0.764439, acc: 0.363281]\n",
      "4282: [D loss: 0.715590, acc: 0.523438]  [A loss: 0.930182, acc: 0.164062]\n",
      "4283: [D loss: 0.699753, acc: 0.541016]  [A loss: 0.743492, acc: 0.417969]\n",
      "4284: [D loss: 0.735002, acc: 0.496094]  [A loss: 1.026972, acc: 0.062500]\n",
      "4285: [D loss: 0.692288, acc: 0.558594]  [A loss: 0.678828, acc: 0.554688]\n",
      "4286: [D loss: 0.741355, acc: 0.505859]  [A loss: 0.934425, acc: 0.132812]\n",
      "4287: [D loss: 0.695843, acc: 0.533203]  [A loss: 0.734103, acc: 0.453125]\n",
      "4288: [D loss: 0.714299, acc: 0.482422]  [A loss: 0.779138, acc: 0.347656]\n",
      "4289: [D loss: 0.689818, acc: 0.542969]  [A loss: 0.789463, acc: 0.339844]\n",
      "4290: [D loss: 0.695069, acc: 0.546875]  [A loss: 0.788739, acc: 0.351562]\n",
      "4291: [D loss: 0.706836, acc: 0.515625]  [A loss: 0.840494, acc: 0.250000]\n",
      "4292: [D loss: 0.690940, acc: 0.550781]  [A loss: 0.820869, acc: 0.289062]\n",
      "4293: [D loss: 0.704331, acc: 0.513672]  [A loss: 0.807703, acc: 0.269531]\n",
      "4294: [D loss: 0.686307, acc: 0.556641]  [A loss: 0.912849, acc: 0.183594]\n",
      "4295: [D loss: 0.697181, acc: 0.539062]  [A loss: 0.758438, acc: 0.359375]\n",
      "4296: [D loss: 0.690873, acc: 0.525391]  [A loss: 0.955420, acc: 0.109375]\n",
      "4297: [D loss: 0.708315, acc: 0.509766]  [A loss: 0.686592, acc: 0.546875]\n",
      "4298: [D loss: 0.711218, acc: 0.511719]  [A loss: 0.940140, acc: 0.144531]\n",
      "4299: [D loss: 0.705429, acc: 0.505859]  [A loss: 0.768890, acc: 0.328125]\n",
      "4300: [D loss: 0.705949, acc: 0.494141]  [A loss: 0.855060, acc: 0.234375]\n",
      "4301: [D loss: 0.708544, acc: 0.490234]  [A loss: 0.826213, acc: 0.238281]\n",
      "4302: [D loss: 0.699829, acc: 0.509766]  [A loss: 0.803730, acc: 0.285156]\n",
      "4303: [D loss: 0.706627, acc: 0.523438]  [A loss: 0.896988, acc: 0.136719]\n",
      "4304: [D loss: 0.694896, acc: 0.523438]  [A loss: 0.798923, acc: 0.316406]\n",
      "4305: [D loss: 0.692944, acc: 0.546875]  [A loss: 0.910520, acc: 0.179688]\n",
      "4306: [D loss: 0.702695, acc: 0.527344]  [A loss: 0.732947, acc: 0.421875]\n",
      "4307: [D loss: 0.709505, acc: 0.498047]  [A loss: 0.983992, acc: 0.078125]\n",
      "4308: [D loss: 0.699622, acc: 0.515625]  [A loss: 0.703417, acc: 0.511719]\n",
      "4309: [D loss: 0.725722, acc: 0.498047]  [A loss: 0.979246, acc: 0.113281]\n",
      "4310: [D loss: 0.703396, acc: 0.517578]  [A loss: 0.736190, acc: 0.480469]\n",
      "4311: [D loss: 0.710136, acc: 0.529297]  [A loss: 0.841530, acc: 0.207031]\n",
      "4312: [D loss: 0.691373, acc: 0.539062]  [A loss: 0.860385, acc: 0.199219]\n",
      "4313: [D loss: 0.690355, acc: 0.533203]  [A loss: 0.790522, acc: 0.371094]\n",
      "4314: [D loss: 0.711796, acc: 0.525391]  [A loss: 0.792634, acc: 0.328125]\n",
      "4315: [D loss: 0.703319, acc: 0.507812]  [A loss: 0.822946, acc: 0.273438]\n",
      "4316: [D loss: 0.707599, acc: 0.519531]  [A loss: 0.825907, acc: 0.242188]\n",
      "4317: [D loss: 0.706860, acc: 0.503906]  [A loss: 0.869500, acc: 0.187500]\n",
      "4318: [D loss: 0.687035, acc: 0.558594]  [A loss: 0.780504, acc: 0.343750]\n",
      "4319: [D loss: 0.724011, acc: 0.496094]  [A loss: 1.039632, acc: 0.039062]\n",
      "4320: [D loss: 0.707102, acc: 0.519531]  [A loss: 0.617706, acc: 0.644531]\n",
      "4321: [D loss: 0.747097, acc: 0.515625]  [A loss: 0.924263, acc: 0.105469]\n",
      "4322: [D loss: 0.691239, acc: 0.519531]  [A loss: 0.742408, acc: 0.437500]\n",
      "4323: [D loss: 0.696316, acc: 0.500000]  [A loss: 0.832501, acc: 0.269531]\n",
      "4324: [D loss: 0.710909, acc: 0.501953]  [A loss: 0.818635, acc: 0.281250]\n",
      "4325: [D loss: 0.713933, acc: 0.501953]  [A loss: 0.848453, acc: 0.242188]\n",
      "4326: [D loss: 0.692283, acc: 0.541016]  [A loss: 0.763416, acc: 0.339844]\n",
      "4327: [D loss: 0.701242, acc: 0.544922]  [A loss: 0.888746, acc: 0.179688]\n",
      "4328: [D loss: 0.707784, acc: 0.498047]  [A loss: 0.775531, acc: 0.367188]\n",
      "4329: [D loss: 0.721246, acc: 0.496094]  [A loss: 0.972775, acc: 0.089844]\n",
      "4330: [D loss: 0.702714, acc: 0.505859]  [A loss: 0.709881, acc: 0.460938]\n",
      "4331: [D loss: 0.746048, acc: 0.503906]  [A loss: 1.034970, acc: 0.050781]\n",
      "4332: [D loss: 0.703532, acc: 0.541016]  [A loss: 0.677024, acc: 0.554688]\n",
      "4333: [D loss: 0.706462, acc: 0.541016]  [A loss: 0.789449, acc: 0.335938]\n",
      "4334: [D loss: 0.705699, acc: 0.513672]  [A loss: 0.792553, acc: 0.335938]\n",
      "4335: [D loss: 0.719106, acc: 0.498047]  [A loss: 0.856441, acc: 0.222656]\n",
      "4336: [D loss: 0.695607, acc: 0.535156]  [A loss: 0.804720, acc: 0.292969]\n",
      "4337: [D loss: 0.705919, acc: 0.498047]  [A loss: 0.927105, acc: 0.109375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4338: [D loss: 0.697049, acc: 0.531250]  [A loss: 0.755272, acc: 0.394531]\n",
      "4339: [D loss: 0.713316, acc: 0.511719]  [A loss: 0.856990, acc: 0.191406]\n",
      "4340: [D loss: 0.687158, acc: 0.542969]  [A loss: 0.751607, acc: 0.378906]\n",
      "4341: [D loss: 0.707996, acc: 0.535156]  [A loss: 0.857080, acc: 0.222656]\n",
      "4342: [D loss: 0.682347, acc: 0.599609]  [A loss: 0.775288, acc: 0.390625]\n",
      "4343: [D loss: 0.701223, acc: 0.529297]  [A loss: 0.833230, acc: 0.265625]\n",
      "4344: [D loss: 0.694222, acc: 0.546875]  [A loss: 0.796465, acc: 0.320312]\n",
      "4345: [D loss: 0.694004, acc: 0.548828]  [A loss: 0.859250, acc: 0.246094]\n",
      "4346: [D loss: 0.704047, acc: 0.503906]  [A loss: 0.772804, acc: 0.386719]\n",
      "4347: [D loss: 0.704801, acc: 0.517578]  [A loss: 0.854993, acc: 0.214844]\n",
      "4348: [D loss: 0.701065, acc: 0.513672]  [A loss: 0.713559, acc: 0.484375]\n",
      "4349: [D loss: 0.725261, acc: 0.515625]  [A loss: 0.951776, acc: 0.132812]\n",
      "4350: [D loss: 0.739983, acc: 0.453125]  [A loss: 0.838519, acc: 0.234375]\n",
      "4351: [D loss: 0.704216, acc: 0.556641]  [A loss: 0.878686, acc: 0.140625]\n",
      "4352: [D loss: 0.693878, acc: 0.527344]  [A loss: 0.833925, acc: 0.250000]\n",
      "4353: [D loss: 0.708472, acc: 0.523438]  [A loss: 0.859965, acc: 0.250000]\n",
      "4354: [D loss: 0.694182, acc: 0.525391]  [A loss: 0.741708, acc: 0.437500]\n",
      "4355: [D loss: 0.708180, acc: 0.529297]  [A loss: 0.972616, acc: 0.109375]\n",
      "4356: [D loss: 0.693824, acc: 0.523438]  [A loss: 0.703570, acc: 0.488281]\n",
      "4357: [D loss: 0.702468, acc: 0.523438]  [A loss: 0.930768, acc: 0.160156]\n",
      "4358: [D loss: 0.703035, acc: 0.544922]  [A loss: 0.756842, acc: 0.402344]\n",
      "4359: [D loss: 0.726358, acc: 0.515625]  [A loss: 0.851194, acc: 0.218750]\n",
      "4360: [D loss: 0.687386, acc: 0.560547]  [A loss: 0.780925, acc: 0.367188]\n",
      "4361: [D loss: 0.714400, acc: 0.498047]  [A loss: 0.923893, acc: 0.152344]\n",
      "4362: [D loss: 0.700552, acc: 0.496094]  [A loss: 0.746577, acc: 0.421875]\n",
      "4363: [D loss: 0.720648, acc: 0.492188]  [A loss: 0.989116, acc: 0.097656]\n",
      "4364: [D loss: 0.710091, acc: 0.517578]  [A loss: 0.698812, acc: 0.500000]\n",
      "4365: [D loss: 0.726105, acc: 0.503906]  [A loss: 0.968825, acc: 0.121094]\n",
      "4366: [D loss: 0.701365, acc: 0.515625]  [A loss: 0.720669, acc: 0.449219]\n",
      "4367: [D loss: 0.722787, acc: 0.496094]  [A loss: 0.829893, acc: 0.261719]\n",
      "4368: [D loss: 0.712957, acc: 0.494141]  [A loss: 0.801400, acc: 0.320312]\n",
      "4369: [D loss: 0.714058, acc: 0.496094]  [A loss: 0.846579, acc: 0.234375]\n",
      "4370: [D loss: 0.697819, acc: 0.511719]  [A loss: 0.799074, acc: 0.324219]\n",
      "4371: [D loss: 0.694167, acc: 0.541016]  [A loss: 0.847422, acc: 0.242188]\n",
      "4372: [D loss: 0.698169, acc: 0.507812]  [A loss: 0.729697, acc: 0.437500]\n",
      "4373: [D loss: 0.710665, acc: 0.513672]  [A loss: 1.014623, acc: 0.074219]\n",
      "4374: [D loss: 0.703072, acc: 0.503906]  [A loss: 0.702422, acc: 0.507812]\n",
      "4375: [D loss: 0.743505, acc: 0.505859]  [A loss: 0.944066, acc: 0.121094]\n",
      "4376: [D loss: 0.693251, acc: 0.521484]  [A loss: 0.745729, acc: 0.402344]\n",
      "4377: [D loss: 0.712279, acc: 0.521484]  [A loss: 0.836476, acc: 0.226562]\n",
      "4378: [D loss: 0.695947, acc: 0.544922]  [A loss: 0.786251, acc: 0.343750]\n",
      "4379: [D loss: 0.706057, acc: 0.529297]  [A loss: 0.866261, acc: 0.195312]\n",
      "4380: [D loss: 0.691396, acc: 0.525391]  [A loss: 0.783081, acc: 0.347656]\n",
      "4381: [D loss: 0.704962, acc: 0.515625]  [A loss: 0.879123, acc: 0.203125]\n",
      "4382: [D loss: 0.685104, acc: 0.578125]  [A loss: 0.756021, acc: 0.355469]\n",
      "4383: [D loss: 0.704997, acc: 0.515625]  [A loss: 0.876310, acc: 0.191406]\n",
      "4384: [D loss: 0.706101, acc: 0.509766]  [A loss: 0.723931, acc: 0.464844]\n",
      "4385: [D loss: 0.743619, acc: 0.505859]  [A loss: 1.067320, acc: 0.093750]\n",
      "4386: [D loss: 0.721471, acc: 0.490234]  [A loss: 0.749557, acc: 0.414062]\n",
      "4387: [D loss: 0.705464, acc: 0.525391]  [A loss: 0.800822, acc: 0.277344]\n",
      "4388: [D loss: 0.694021, acc: 0.556641]  [A loss: 0.850508, acc: 0.222656]\n",
      "4389: [D loss: 0.706802, acc: 0.531250]  [A loss: 0.814281, acc: 0.281250]\n",
      "4390: [D loss: 0.702943, acc: 0.509766]  [A loss: 0.822075, acc: 0.253906]\n",
      "4391: [D loss: 0.710557, acc: 0.519531]  [A loss: 0.827651, acc: 0.246094]\n",
      "4392: [D loss: 0.699805, acc: 0.517578]  [A loss: 0.826328, acc: 0.242188]\n",
      "4393: [D loss: 0.688678, acc: 0.529297]  [A loss: 0.807860, acc: 0.281250]\n",
      "4394: [D loss: 0.701161, acc: 0.535156]  [A loss: 0.948593, acc: 0.078125]\n",
      "4395: [D loss: 0.687953, acc: 0.554688]  [A loss: 0.671589, acc: 0.593750]\n",
      "4396: [D loss: 0.724096, acc: 0.498047]  [A loss: 0.991472, acc: 0.097656]\n",
      "4397: [D loss: 0.691102, acc: 0.541016]  [A loss: 0.729218, acc: 0.449219]\n",
      "4398: [D loss: 0.716127, acc: 0.517578]  [A loss: 0.859102, acc: 0.187500]\n",
      "4399: [D loss: 0.713342, acc: 0.486328]  [A loss: 0.728545, acc: 0.460938]\n",
      "4400: [D loss: 0.735719, acc: 0.505859]  [A loss: 0.988127, acc: 0.082031]\n",
      "4401: [D loss: 0.698663, acc: 0.513672]  [A loss: 0.716633, acc: 0.464844]\n",
      "4402: [D loss: 0.723825, acc: 0.494141]  [A loss: 0.817683, acc: 0.250000]\n",
      "4403: [D loss: 0.699816, acc: 0.523438]  [A loss: 0.789778, acc: 0.335938]\n",
      "4404: [D loss: 0.701300, acc: 0.533203]  [A loss: 0.877941, acc: 0.183594]\n",
      "4405: [D loss: 0.684977, acc: 0.560547]  [A loss: 0.794231, acc: 0.324219]\n",
      "4406: [D loss: 0.715283, acc: 0.529297]  [A loss: 0.808505, acc: 0.324219]\n",
      "4407: [D loss: 0.701303, acc: 0.509766]  [A loss: 0.837067, acc: 0.250000]\n",
      "4408: [D loss: 0.713618, acc: 0.513672]  [A loss: 0.839783, acc: 0.265625]\n",
      "4409: [D loss: 0.699021, acc: 0.527344]  [A loss: 0.803129, acc: 0.289062]\n",
      "4410: [D loss: 0.696308, acc: 0.541016]  [A loss: 0.827801, acc: 0.242188]\n",
      "4411: [D loss: 0.712841, acc: 0.507812]  [A loss: 0.829362, acc: 0.246094]\n",
      "4412: [D loss: 0.695788, acc: 0.511719]  [A loss: 0.865801, acc: 0.207031]\n",
      "4413: [D loss: 0.677930, acc: 0.568359]  [A loss: 0.713787, acc: 0.523438]\n",
      "4414: [D loss: 0.714816, acc: 0.527344]  [A loss: 1.012690, acc: 0.078125]\n",
      "4415: [D loss: 0.713606, acc: 0.533203]  [A loss: 0.708811, acc: 0.484375]\n",
      "4416: [D loss: 0.721165, acc: 0.513672]  [A loss: 0.810649, acc: 0.300781]\n",
      "4417: [D loss: 0.695948, acc: 0.527344]  [A loss: 0.866482, acc: 0.203125]\n",
      "4418: [D loss: 0.686042, acc: 0.541016]  [A loss: 0.813537, acc: 0.277344]\n",
      "4419: [D loss: 0.701334, acc: 0.570312]  [A loss: 0.833312, acc: 0.257812]\n",
      "4420: [D loss: 0.693155, acc: 0.535156]  [A loss: 0.858806, acc: 0.195312]\n",
      "4421: [D loss: 0.689198, acc: 0.546875]  [A loss: 0.886368, acc: 0.195312]\n",
      "4422: [D loss: 0.694361, acc: 0.544922]  [A loss: 0.736072, acc: 0.410156]\n",
      "4423: [D loss: 0.733382, acc: 0.503906]  [A loss: 1.011631, acc: 0.074219]\n",
      "4424: [D loss: 0.692722, acc: 0.550781]  [A loss: 0.774352, acc: 0.339844]\n",
      "4425: [D loss: 0.718124, acc: 0.496094]  [A loss: 0.828135, acc: 0.285156]\n",
      "4426: [D loss: 0.685532, acc: 0.541016]  [A loss: 0.755448, acc: 0.390625]\n",
      "4427: [D loss: 0.709298, acc: 0.525391]  [A loss: 0.863110, acc: 0.214844]\n",
      "4428: [D loss: 0.703328, acc: 0.509766]  [A loss: 0.748746, acc: 0.464844]\n",
      "4429: [D loss: 0.715018, acc: 0.503906]  [A loss: 0.897835, acc: 0.207031]\n",
      "4430: [D loss: 0.699992, acc: 0.509766]  [A loss: 0.748319, acc: 0.410156]\n",
      "4431: [D loss: 0.717113, acc: 0.496094]  [A loss: 0.922051, acc: 0.140625]\n",
      "4432: [D loss: 0.698365, acc: 0.523438]  [A loss: 0.736084, acc: 0.437500]\n",
      "4433: [D loss: 0.717610, acc: 0.501953]  [A loss: 1.041255, acc: 0.054688]\n",
      "4434: [D loss: 0.698135, acc: 0.556641]  [A loss: 0.729581, acc: 0.441406]\n",
      "4435: [D loss: 0.723094, acc: 0.484375]  [A loss: 0.843288, acc: 0.250000]\n",
      "4436: [D loss: 0.703781, acc: 0.509766]  [A loss: 0.763727, acc: 0.414062]\n",
      "4437: [D loss: 0.712455, acc: 0.523438]  [A loss: 0.849588, acc: 0.199219]\n",
      "4438: [D loss: 0.692161, acc: 0.539062]  [A loss: 0.749495, acc: 0.371094]\n",
      "4439: [D loss: 0.693419, acc: 0.539062]  [A loss: 0.807919, acc: 0.261719]\n",
      "4440: [D loss: 0.713339, acc: 0.515625]  [A loss: 0.867239, acc: 0.210938]\n",
      "4441: [D loss: 0.704002, acc: 0.503906]  [A loss: 0.769227, acc: 0.386719]\n",
      "4442: [D loss: 0.706665, acc: 0.533203]  [A loss: 0.923826, acc: 0.152344]\n",
      "4443: [D loss: 0.687922, acc: 0.531250]  [A loss: 0.689156, acc: 0.523438]\n",
      "4444: [D loss: 0.727028, acc: 0.505859]  [A loss: 0.998918, acc: 0.070312]\n",
      "4445: [D loss: 0.711595, acc: 0.525391]  [A loss: 0.725597, acc: 0.402344]\n",
      "4446: [D loss: 0.702925, acc: 0.550781]  [A loss: 0.839800, acc: 0.226562]\n",
      "4447: [D loss: 0.698108, acc: 0.500000]  [A loss: 0.804754, acc: 0.292969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4448: [D loss: 0.702644, acc: 0.539062]  [A loss: 0.820538, acc: 0.257812]\n",
      "4449: [D loss: 0.689873, acc: 0.548828]  [A loss: 0.829789, acc: 0.210938]\n",
      "4450: [D loss: 0.697455, acc: 0.529297]  [A loss: 0.792916, acc: 0.347656]\n",
      "4451: [D loss: 0.711396, acc: 0.509766]  [A loss: 0.816363, acc: 0.246094]\n",
      "4452: [D loss: 0.711016, acc: 0.503906]  [A loss: 0.871669, acc: 0.191406]\n",
      "4453: [D loss: 0.697047, acc: 0.484375]  [A loss: 0.783449, acc: 0.335938]\n",
      "4454: [D loss: 0.708168, acc: 0.521484]  [A loss: 0.936850, acc: 0.121094]\n",
      "4455: [D loss: 0.696736, acc: 0.511719]  [A loss: 0.755960, acc: 0.390625]\n",
      "4456: [D loss: 0.722602, acc: 0.494141]  [A loss: 0.966876, acc: 0.109375]\n",
      "4457: [D loss: 0.694715, acc: 0.533203]  [A loss: 0.730369, acc: 0.417969]\n",
      "4458: [D loss: 0.702876, acc: 0.525391]  [A loss: 0.885178, acc: 0.207031]\n",
      "4459: [D loss: 0.704432, acc: 0.496094]  [A loss: 0.751756, acc: 0.386719]\n",
      "4460: [D loss: 0.698842, acc: 0.546875]  [A loss: 0.844636, acc: 0.238281]\n",
      "4461: [D loss: 0.687538, acc: 0.537109]  [A loss: 0.762130, acc: 0.343750]\n",
      "4462: [D loss: 0.717742, acc: 0.486328]  [A loss: 0.935156, acc: 0.128906]\n",
      "4463: [D loss: 0.703721, acc: 0.492188]  [A loss: 0.774910, acc: 0.351562]\n",
      "4464: [D loss: 0.702055, acc: 0.527344]  [A loss: 0.946787, acc: 0.085938]\n",
      "4465: [D loss: 0.709365, acc: 0.496094]  [A loss: 0.708256, acc: 0.460938]\n",
      "4466: [D loss: 0.733520, acc: 0.500000]  [A loss: 1.090510, acc: 0.066406]\n",
      "4467: [D loss: 0.722661, acc: 0.486328]  [A loss: 0.752612, acc: 0.390625]\n",
      "4468: [D loss: 0.724548, acc: 0.505859]  [A loss: 0.823457, acc: 0.269531]\n",
      "4469: [D loss: 0.700026, acc: 0.515625]  [A loss: 0.764348, acc: 0.371094]\n",
      "4470: [D loss: 0.709772, acc: 0.535156]  [A loss: 0.870061, acc: 0.167969]\n",
      "4471: [D loss: 0.705958, acc: 0.517578]  [A loss: 0.801859, acc: 0.292969]\n",
      "4472: [D loss: 0.706077, acc: 0.525391]  [A loss: 0.781051, acc: 0.332031]\n",
      "4473: [D loss: 0.700341, acc: 0.533203]  [A loss: 0.815540, acc: 0.265625]\n",
      "4474: [D loss: 0.696731, acc: 0.533203]  [A loss: 0.890826, acc: 0.148438]\n",
      "4475: [D loss: 0.690972, acc: 0.560547]  [A loss: 0.863844, acc: 0.183594]\n",
      "4476: [D loss: 0.724811, acc: 0.470703]  [A loss: 0.826154, acc: 0.261719]\n",
      "4477: [D loss: 0.707122, acc: 0.490234]  [A loss: 0.867089, acc: 0.156250]\n",
      "4478: [D loss: 0.713708, acc: 0.486328]  [A loss: 0.781524, acc: 0.316406]\n",
      "4479: [D loss: 0.700658, acc: 0.500000]  [A loss: 0.886798, acc: 0.167969]\n",
      "4480: [D loss: 0.695989, acc: 0.546875]  [A loss: 0.729981, acc: 0.425781]\n",
      "4481: [D loss: 0.715538, acc: 0.517578]  [A loss: 0.904126, acc: 0.199219]\n",
      "4482: [D loss: 0.705346, acc: 0.505859]  [A loss: 0.736278, acc: 0.414062]\n",
      "4483: [D loss: 0.715221, acc: 0.511719]  [A loss: 0.916987, acc: 0.128906]\n",
      "4484: [D loss: 0.702110, acc: 0.503906]  [A loss: 0.768892, acc: 0.339844]\n",
      "4485: [D loss: 0.707887, acc: 0.542969]  [A loss: 0.959482, acc: 0.113281]\n",
      "4486: [D loss: 0.700868, acc: 0.492188]  [A loss: 0.728625, acc: 0.449219]\n",
      "4487: [D loss: 0.717297, acc: 0.501953]  [A loss: 0.885205, acc: 0.226562]\n",
      "4488: [D loss: 0.700422, acc: 0.523438]  [A loss: 0.738149, acc: 0.414062]\n",
      "4489: [D loss: 0.703501, acc: 0.527344]  [A loss: 0.868882, acc: 0.167969]\n",
      "4490: [D loss: 0.689840, acc: 0.572266]  [A loss: 0.753625, acc: 0.343750]\n",
      "4491: [D loss: 0.718379, acc: 0.519531]  [A loss: 0.927881, acc: 0.113281]\n",
      "4492: [D loss: 0.698383, acc: 0.500000]  [A loss: 0.690578, acc: 0.519531]\n",
      "4493: [D loss: 0.739619, acc: 0.496094]  [A loss: 1.060159, acc: 0.070312]\n",
      "4494: [D loss: 0.718319, acc: 0.519531]  [A loss: 0.748183, acc: 0.414062]\n",
      "4495: [D loss: 0.710993, acc: 0.521484]  [A loss: 0.809044, acc: 0.289062]\n",
      "4496: [D loss: 0.714196, acc: 0.500000]  [A loss: 0.737996, acc: 0.402344]\n",
      "4497: [D loss: 0.708769, acc: 0.517578]  [A loss: 0.929046, acc: 0.132812]\n",
      "4498: [D loss: 0.699624, acc: 0.515625]  [A loss: 0.708329, acc: 0.472656]\n",
      "4499: [D loss: 0.715586, acc: 0.501953]  [A loss: 0.841711, acc: 0.222656]\n",
      "4500: [D loss: 0.697522, acc: 0.533203]  [A loss: 0.872610, acc: 0.210938]\n",
      "4501: [D loss: 0.700618, acc: 0.519531]  [A loss: 0.767470, acc: 0.386719]\n",
      "4502: [D loss: 0.707392, acc: 0.494141]  [A loss: 0.852736, acc: 0.214844]\n",
      "4503: [D loss: 0.707428, acc: 0.496094]  [A loss: 0.742755, acc: 0.417969]\n",
      "4504: [D loss: 0.711607, acc: 0.515625]  [A loss: 0.911853, acc: 0.144531]\n",
      "4505: [D loss: 0.675492, acc: 0.578125]  [A loss: 0.740435, acc: 0.449219]\n",
      "4506: [D loss: 0.729404, acc: 0.494141]  [A loss: 0.915425, acc: 0.140625]\n",
      "4507: [D loss: 0.709722, acc: 0.480469]  [A loss: 0.727094, acc: 0.437500]\n",
      "4508: [D loss: 0.693099, acc: 0.513672]  [A loss: 0.902462, acc: 0.136719]\n",
      "4509: [D loss: 0.699355, acc: 0.527344]  [A loss: 0.767787, acc: 0.378906]\n",
      "4510: [D loss: 0.691052, acc: 0.533203]  [A loss: 0.836193, acc: 0.222656]\n",
      "4511: [D loss: 0.683546, acc: 0.544922]  [A loss: 0.735707, acc: 0.421875]\n",
      "4512: [D loss: 0.697541, acc: 0.542969]  [A loss: 0.948867, acc: 0.160156]\n",
      "4513: [D loss: 0.693933, acc: 0.552734]  [A loss: 0.704512, acc: 0.449219]\n",
      "4514: [D loss: 0.725422, acc: 0.513672]  [A loss: 0.922426, acc: 0.156250]\n",
      "4515: [D loss: 0.704373, acc: 0.517578]  [A loss: 0.756331, acc: 0.375000]\n",
      "4516: [D loss: 0.708372, acc: 0.509766]  [A loss: 0.857529, acc: 0.195312]\n",
      "4517: [D loss: 0.683075, acc: 0.554688]  [A loss: 0.783444, acc: 0.355469]\n",
      "4518: [D loss: 0.704863, acc: 0.515625]  [A loss: 0.883832, acc: 0.160156]\n",
      "4519: [D loss: 0.694777, acc: 0.533203]  [A loss: 0.721786, acc: 0.417969]\n",
      "4520: [D loss: 0.703578, acc: 0.513672]  [A loss: 0.909343, acc: 0.191406]\n",
      "4521: [D loss: 0.702754, acc: 0.523438]  [A loss: 0.749315, acc: 0.359375]\n",
      "4522: [D loss: 0.716498, acc: 0.517578]  [A loss: 0.939668, acc: 0.125000]\n",
      "4523: [D loss: 0.702786, acc: 0.507812]  [A loss: 0.714137, acc: 0.484375]\n",
      "4524: [D loss: 0.712917, acc: 0.519531]  [A loss: 0.870269, acc: 0.191406]\n",
      "4525: [D loss: 0.701312, acc: 0.517578]  [A loss: 0.712512, acc: 0.464844]\n",
      "4526: [D loss: 0.701994, acc: 0.529297]  [A loss: 0.861639, acc: 0.218750]\n",
      "4527: [D loss: 0.694349, acc: 0.531250]  [A loss: 0.700368, acc: 0.500000]\n",
      "4528: [D loss: 0.716576, acc: 0.521484]  [A loss: 0.960251, acc: 0.128906]\n",
      "4529: [D loss: 0.693534, acc: 0.531250]  [A loss: 0.738579, acc: 0.425781]\n",
      "4530: [D loss: 0.721816, acc: 0.535156]  [A loss: 0.900995, acc: 0.160156]\n",
      "4531: [D loss: 0.695238, acc: 0.525391]  [A loss: 0.806093, acc: 0.250000]\n",
      "4532: [D loss: 0.697866, acc: 0.525391]  [A loss: 0.940800, acc: 0.125000]\n",
      "4533: [D loss: 0.694214, acc: 0.546875]  [A loss: 0.773510, acc: 0.343750]\n",
      "4534: [D loss: 0.696539, acc: 0.548828]  [A loss: 0.955844, acc: 0.132812]\n",
      "4535: [D loss: 0.711645, acc: 0.468750]  [A loss: 0.693360, acc: 0.492188]\n",
      "4536: [D loss: 0.707854, acc: 0.515625]  [A loss: 0.860574, acc: 0.183594]\n",
      "4537: [D loss: 0.697988, acc: 0.523438]  [A loss: 0.731285, acc: 0.437500]\n",
      "4538: [D loss: 0.714972, acc: 0.511719]  [A loss: 0.908814, acc: 0.167969]\n",
      "4539: [D loss: 0.693696, acc: 0.517578]  [A loss: 0.708291, acc: 0.523438]\n",
      "4540: [D loss: 0.726949, acc: 0.503906]  [A loss: 0.937207, acc: 0.140625]\n",
      "4541: [D loss: 0.699552, acc: 0.531250]  [A loss: 0.782116, acc: 0.320312]\n",
      "4542: [D loss: 0.710093, acc: 0.507812]  [A loss: 0.830451, acc: 0.281250]\n",
      "4543: [D loss: 0.690849, acc: 0.503906]  [A loss: 0.804775, acc: 0.304688]\n",
      "4544: [D loss: 0.700752, acc: 0.535156]  [A loss: 0.823712, acc: 0.269531]\n",
      "4545: [D loss: 0.713909, acc: 0.476562]  [A loss: 0.811018, acc: 0.261719]\n",
      "4546: [D loss: 0.697267, acc: 0.527344]  [A loss: 0.923954, acc: 0.136719]\n",
      "4547: [D loss: 0.706077, acc: 0.486328]  [A loss: 0.786044, acc: 0.296875]\n",
      "4548: [D loss: 0.690319, acc: 0.554688]  [A loss: 0.877892, acc: 0.207031]\n",
      "4549: [D loss: 0.689230, acc: 0.570312]  [A loss: 0.761386, acc: 0.386719]\n",
      "4550: [D loss: 0.720255, acc: 0.498047]  [A loss: 0.932633, acc: 0.148438]\n",
      "4551: [D loss: 0.703403, acc: 0.519531]  [A loss: 0.766404, acc: 0.328125]\n",
      "4552: [D loss: 0.710241, acc: 0.498047]  [A loss: 0.951621, acc: 0.144531]\n",
      "4553: [D loss: 0.688226, acc: 0.541016]  [A loss: 0.694210, acc: 0.503906]\n",
      "4554: [D loss: 0.701387, acc: 0.511719]  [A loss: 0.891482, acc: 0.179688]\n",
      "4555: [D loss: 0.699320, acc: 0.533203]  [A loss: 0.718548, acc: 0.457031]\n",
      "4556: [D loss: 0.709298, acc: 0.521484]  [A loss: 0.974528, acc: 0.113281]\n",
      "4557: [D loss: 0.686668, acc: 0.539062]  [A loss: 0.670762, acc: 0.585938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4558: [D loss: 0.718829, acc: 0.535156]  [A loss: 0.867121, acc: 0.207031]\n",
      "4559: [D loss: 0.697979, acc: 0.527344]  [A loss: 0.771689, acc: 0.324219]\n",
      "4560: [D loss: 0.708117, acc: 0.519531]  [A loss: 0.890439, acc: 0.183594]\n",
      "4561: [D loss: 0.688058, acc: 0.542969]  [A loss: 0.820482, acc: 0.281250]\n",
      "4562: [D loss: 0.724497, acc: 0.490234]  [A loss: 0.823978, acc: 0.285156]\n",
      "4563: [D loss: 0.696551, acc: 0.546875]  [A loss: 0.788835, acc: 0.316406]\n",
      "4564: [D loss: 0.707321, acc: 0.501953]  [A loss: 0.887953, acc: 0.210938]\n",
      "4565: [D loss: 0.702626, acc: 0.517578]  [A loss: 0.790839, acc: 0.312500]\n",
      "4566: [D loss: 0.692867, acc: 0.552734]  [A loss: 0.894536, acc: 0.152344]\n",
      "4567: [D loss: 0.695866, acc: 0.519531]  [A loss: 0.783738, acc: 0.308594]\n",
      "4568: [D loss: 0.708483, acc: 0.539062]  [A loss: 1.030946, acc: 0.070312]\n",
      "4569: [D loss: 0.694954, acc: 0.531250]  [A loss: 0.706744, acc: 0.492188]\n",
      "4570: [D loss: 0.721702, acc: 0.511719]  [A loss: 0.855570, acc: 0.203125]\n",
      "4571: [D loss: 0.699088, acc: 0.539062]  [A loss: 0.771406, acc: 0.402344]\n",
      "4572: [D loss: 0.704766, acc: 0.535156]  [A loss: 0.836473, acc: 0.242188]\n",
      "4573: [D loss: 0.697680, acc: 0.535156]  [A loss: 0.845586, acc: 0.226562]\n",
      "4574: [D loss: 0.690335, acc: 0.550781]  [A loss: 0.828550, acc: 0.250000]\n",
      "4575: [D loss: 0.705142, acc: 0.492188]  [A loss: 0.797163, acc: 0.312500]\n",
      "4576: [D loss: 0.705821, acc: 0.529297]  [A loss: 0.806619, acc: 0.257812]\n",
      "4577: [D loss: 0.718703, acc: 0.498047]  [A loss: 0.941072, acc: 0.132812]\n",
      "4578: [D loss: 0.686396, acc: 0.537109]  [A loss: 0.722669, acc: 0.503906]\n",
      "4579: [D loss: 0.702547, acc: 0.519531]  [A loss: 0.889399, acc: 0.164062]\n",
      "4580: [D loss: 0.688542, acc: 0.554688]  [A loss: 0.724130, acc: 0.468750]\n",
      "4581: [D loss: 0.715572, acc: 0.527344]  [A loss: 0.981398, acc: 0.125000]\n",
      "4582: [D loss: 0.697234, acc: 0.527344]  [A loss: 0.812267, acc: 0.277344]\n",
      "4583: [D loss: 0.693665, acc: 0.501953]  [A loss: 0.779724, acc: 0.328125]\n",
      "4584: [D loss: 0.711935, acc: 0.519531]  [A loss: 0.821436, acc: 0.242188]\n",
      "4585: [D loss: 0.714077, acc: 0.503906]  [A loss: 0.821176, acc: 0.238281]\n",
      "4586: [D loss: 0.698726, acc: 0.542969]  [A loss: 0.832196, acc: 0.277344]\n",
      "4587: [D loss: 0.690664, acc: 0.533203]  [A loss: 0.787025, acc: 0.304688]\n",
      "4588: [D loss: 0.704394, acc: 0.523438]  [A loss: 0.873866, acc: 0.214844]\n",
      "4589: [D loss: 0.716398, acc: 0.505859]  [A loss: 0.780394, acc: 0.335938]\n",
      "4590: [D loss: 0.703345, acc: 0.511719]  [A loss: 0.915111, acc: 0.152344]\n",
      "4591: [D loss: 0.698264, acc: 0.558594]  [A loss: 0.796956, acc: 0.308594]\n",
      "4592: [D loss: 0.700766, acc: 0.558594]  [A loss: 0.889702, acc: 0.164062]\n",
      "4593: [D loss: 0.700427, acc: 0.523438]  [A loss: 0.842598, acc: 0.226562]\n",
      "4594: [D loss: 0.694292, acc: 0.539062]  [A loss: 0.932398, acc: 0.148438]\n",
      "4595: [D loss: 0.691052, acc: 0.539062]  [A loss: 0.666185, acc: 0.613281]\n",
      "4596: [D loss: 0.728090, acc: 0.507812]  [A loss: 0.987134, acc: 0.121094]\n",
      "4597: [D loss: 0.706567, acc: 0.507812]  [A loss: 0.754589, acc: 0.378906]\n",
      "4598: [D loss: 0.707749, acc: 0.513672]  [A loss: 0.789606, acc: 0.300781]\n",
      "4599: [D loss: 0.700397, acc: 0.548828]  [A loss: 0.818033, acc: 0.253906]\n",
      "4600: [D loss: 0.702883, acc: 0.519531]  [A loss: 0.877748, acc: 0.167969]\n",
      "4601: [D loss: 0.698183, acc: 0.517578]  [A loss: 0.778716, acc: 0.386719]\n",
      "4602: [D loss: 0.709263, acc: 0.546875]  [A loss: 0.932243, acc: 0.113281]\n",
      "4603: [D loss: 0.705266, acc: 0.521484]  [A loss: 0.670790, acc: 0.613281]\n",
      "4604: [D loss: 0.715174, acc: 0.517578]  [A loss: 0.923862, acc: 0.179688]\n",
      "4605: [D loss: 0.701647, acc: 0.546875]  [A loss: 0.685895, acc: 0.515625]\n",
      "4606: [D loss: 0.730732, acc: 0.496094]  [A loss: 0.829857, acc: 0.253906]\n",
      "4607: [D loss: 0.703010, acc: 0.525391]  [A loss: 0.807916, acc: 0.281250]\n",
      "4608: [D loss: 0.687571, acc: 0.560547]  [A loss: 0.798692, acc: 0.292969]\n",
      "4609: [D loss: 0.702367, acc: 0.523438]  [A loss: 0.887780, acc: 0.199219]\n",
      "4610: [D loss: 0.695993, acc: 0.533203]  [A loss: 0.773576, acc: 0.335938]\n",
      "4611: [D loss: 0.715183, acc: 0.519531]  [A loss: 0.933820, acc: 0.105469]\n",
      "4612: [D loss: 0.708606, acc: 0.500000]  [A loss: 0.698026, acc: 0.507812]\n",
      "4613: [D loss: 0.734374, acc: 0.496094]  [A loss: 1.016009, acc: 0.101562]\n",
      "4614: [D loss: 0.725479, acc: 0.474609]  [A loss: 0.831614, acc: 0.292969]\n",
      "4615: [D loss: 0.718678, acc: 0.531250]  [A loss: 0.830945, acc: 0.230469]\n",
      "4616: [D loss: 0.690690, acc: 0.576172]  [A loss: 0.831803, acc: 0.238281]\n",
      "4617: [D loss: 0.699886, acc: 0.527344]  [A loss: 0.796846, acc: 0.324219]\n",
      "4618: [D loss: 0.703544, acc: 0.521484]  [A loss: 0.819772, acc: 0.296875]\n",
      "4619: [D loss: 0.703100, acc: 0.513672]  [A loss: 0.810049, acc: 0.300781]\n",
      "4620: [D loss: 0.695536, acc: 0.552734]  [A loss: 0.873057, acc: 0.191406]\n",
      "4621: [D loss: 0.703168, acc: 0.539062]  [A loss: 0.772945, acc: 0.300781]\n",
      "4622: [D loss: 0.719852, acc: 0.498047]  [A loss: 0.954580, acc: 0.132812]\n",
      "4623: [D loss: 0.690036, acc: 0.533203]  [A loss: 0.687977, acc: 0.539062]\n",
      "4624: [D loss: 0.724720, acc: 0.498047]  [A loss: 0.927364, acc: 0.132812]\n",
      "4625: [D loss: 0.718432, acc: 0.488281]  [A loss: 0.756548, acc: 0.382812]\n",
      "4626: [D loss: 0.714252, acc: 0.525391]  [A loss: 0.810125, acc: 0.304688]\n",
      "4627: [D loss: 0.692571, acc: 0.552734]  [A loss: 0.761860, acc: 0.390625]\n",
      "4628: [D loss: 0.710730, acc: 0.496094]  [A loss: 0.890742, acc: 0.171875]\n",
      "4629: [D loss: 0.700219, acc: 0.533203]  [A loss: 0.749228, acc: 0.421875]\n",
      "4630: [D loss: 0.703950, acc: 0.539062]  [A loss: 0.849035, acc: 0.222656]\n",
      "4631: [D loss: 0.709932, acc: 0.527344]  [A loss: 0.824430, acc: 0.246094]\n",
      "4632: [D loss: 0.701649, acc: 0.533203]  [A loss: 0.877212, acc: 0.171875]\n",
      "4633: [D loss: 0.688887, acc: 0.552734]  [A loss: 0.743761, acc: 0.406250]\n",
      "4634: [D loss: 0.702218, acc: 0.519531]  [A loss: 0.951167, acc: 0.109375]\n",
      "4635: [D loss: 0.700815, acc: 0.550781]  [A loss: 0.724477, acc: 0.457031]\n",
      "4636: [D loss: 0.708622, acc: 0.525391]  [A loss: 0.904316, acc: 0.183594]\n",
      "4637: [D loss: 0.695028, acc: 0.544922]  [A loss: 0.767384, acc: 0.363281]\n",
      "4638: [D loss: 0.690055, acc: 0.552734]  [A loss: 0.817021, acc: 0.265625]\n",
      "4639: [D loss: 0.698992, acc: 0.546875]  [A loss: 0.802350, acc: 0.312500]\n",
      "4640: [D loss: 0.696766, acc: 0.546875]  [A loss: 0.763753, acc: 0.378906]\n",
      "4641: [D loss: 0.702550, acc: 0.523438]  [A loss: 0.958155, acc: 0.109375]\n",
      "4642: [D loss: 0.677343, acc: 0.566406]  [A loss: 0.783271, acc: 0.316406]\n",
      "4643: [D loss: 0.703433, acc: 0.533203]  [A loss: 0.913319, acc: 0.156250]\n",
      "4644: [D loss: 0.691728, acc: 0.523438]  [A loss: 0.727578, acc: 0.406250]\n",
      "4645: [D loss: 0.735517, acc: 0.494141]  [A loss: 1.072945, acc: 0.093750]\n",
      "4646: [D loss: 0.717243, acc: 0.523438]  [A loss: 0.759254, acc: 0.406250]\n",
      "4647: [D loss: 0.723829, acc: 0.519531]  [A loss: 0.864266, acc: 0.214844]\n",
      "4648: [D loss: 0.697226, acc: 0.509766]  [A loss: 0.815458, acc: 0.261719]\n",
      "4649: [D loss: 0.696870, acc: 0.525391]  [A loss: 0.906778, acc: 0.175781]\n",
      "4650: [D loss: 0.700565, acc: 0.523438]  [A loss: 0.766893, acc: 0.371094]\n",
      "4651: [D loss: 0.706619, acc: 0.539062]  [A loss: 0.970319, acc: 0.093750]\n",
      "4652: [D loss: 0.692579, acc: 0.535156]  [A loss: 0.691098, acc: 0.582031]\n",
      "4653: [D loss: 0.727563, acc: 0.509766]  [A loss: 0.981712, acc: 0.093750]\n",
      "4654: [D loss: 0.703379, acc: 0.523438]  [A loss: 0.768599, acc: 0.343750]\n",
      "4655: [D loss: 0.696952, acc: 0.548828]  [A loss: 0.817512, acc: 0.296875]\n",
      "4656: [D loss: 0.689801, acc: 0.527344]  [A loss: 0.763581, acc: 0.371094]\n",
      "4657: [D loss: 0.709247, acc: 0.494141]  [A loss: 0.832079, acc: 0.253906]\n",
      "4658: [D loss: 0.690498, acc: 0.525391]  [A loss: 0.736630, acc: 0.445312]\n",
      "4659: [D loss: 0.714776, acc: 0.507812]  [A loss: 0.788160, acc: 0.320312]\n",
      "4660: [D loss: 0.713145, acc: 0.501953]  [A loss: 0.855424, acc: 0.210938]\n",
      "4661: [D loss: 0.687997, acc: 0.541016]  [A loss: 0.796958, acc: 0.308594]\n",
      "4662: [D loss: 0.724927, acc: 0.482422]  [A loss: 0.961196, acc: 0.109375]\n",
      "4663: [D loss: 0.695980, acc: 0.539062]  [A loss: 0.668026, acc: 0.566406]\n",
      "4664: [D loss: 0.738726, acc: 0.507812]  [A loss: 1.010532, acc: 0.117188]\n",
      "4665: [D loss: 0.709285, acc: 0.503906]  [A loss: 0.746385, acc: 0.390625]\n",
      "4666: [D loss: 0.704607, acc: 0.505859]  [A loss: 0.873040, acc: 0.187500]\n",
      "4667: [D loss: 0.699932, acc: 0.539062]  [A loss: 0.778160, acc: 0.328125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4668: [D loss: 0.717910, acc: 0.515625]  [A loss: 0.936908, acc: 0.132812]\n",
      "4669: [D loss: 0.705938, acc: 0.531250]  [A loss: 0.708710, acc: 0.511719]\n",
      "4670: [D loss: 0.727238, acc: 0.498047]  [A loss: 0.927768, acc: 0.128906]\n",
      "4671: [D loss: 0.697991, acc: 0.531250]  [A loss: 0.718225, acc: 0.484375]\n",
      "4672: [D loss: 0.707943, acc: 0.527344]  [A loss: 0.837066, acc: 0.238281]\n",
      "4673: [D loss: 0.707175, acc: 0.501953]  [A loss: 0.785378, acc: 0.343750]\n",
      "4674: [D loss: 0.707824, acc: 0.513672]  [A loss: 0.884822, acc: 0.210938]\n",
      "4675: [D loss: 0.700489, acc: 0.539062]  [A loss: 0.772010, acc: 0.343750]\n",
      "4676: [D loss: 0.706844, acc: 0.511719]  [A loss: 0.817543, acc: 0.300781]\n",
      "4677: [D loss: 0.695854, acc: 0.515625]  [A loss: 0.829807, acc: 0.257812]\n",
      "4678: [D loss: 0.701044, acc: 0.517578]  [A loss: 0.840428, acc: 0.253906]\n",
      "4679: [D loss: 0.696450, acc: 0.541016]  [A loss: 0.802173, acc: 0.320312]\n",
      "4680: [D loss: 0.703301, acc: 0.509766]  [A loss: 0.803741, acc: 0.332031]\n",
      "4681: [D loss: 0.681205, acc: 0.568359]  [A loss: 0.837921, acc: 0.253906]\n",
      "4682: [D loss: 0.711225, acc: 0.500000]  [A loss: 0.799709, acc: 0.304688]\n",
      "4683: [D loss: 0.706823, acc: 0.535156]  [A loss: 0.970819, acc: 0.113281]\n",
      "4684: [D loss: 0.697174, acc: 0.503906]  [A loss: 0.645785, acc: 0.617188]\n",
      "4685: [D loss: 0.740090, acc: 0.529297]  [A loss: 1.022596, acc: 0.097656]\n",
      "4686: [D loss: 0.721327, acc: 0.498047]  [A loss: 0.844734, acc: 0.246094]\n",
      "4687: [D loss: 0.706152, acc: 0.533203]  [A loss: 0.809429, acc: 0.269531]\n",
      "4688: [D loss: 0.700847, acc: 0.525391]  [A loss: 0.772168, acc: 0.398438]\n",
      "4689: [D loss: 0.704420, acc: 0.505859]  [A loss: 0.891217, acc: 0.171875]\n",
      "4690: [D loss: 0.716883, acc: 0.476562]  [A loss: 0.791493, acc: 0.332031]\n",
      "4691: [D loss: 0.710999, acc: 0.541016]  [A loss: 0.934780, acc: 0.132812]\n",
      "4692: [D loss: 0.685140, acc: 0.544922]  [A loss: 0.715913, acc: 0.496094]\n",
      "4693: [D loss: 0.718983, acc: 0.531250]  [A loss: 0.933676, acc: 0.109375]\n",
      "4694: [D loss: 0.697190, acc: 0.537109]  [A loss: 0.695368, acc: 0.511719]\n",
      "4695: [D loss: 0.721223, acc: 0.515625]  [A loss: 1.017823, acc: 0.070312]\n",
      "4696: [D loss: 0.697885, acc: 0.513672]  [A loss: 0.733621, acc: 0.437500]\n",
      "4697: [D loss: 0.723554, acc: 0.531250]  [A loss: 0.891647, acc: 0.164062]\n",
      "4698: [D loss: 0.688570, acc: 0.527344]  [A loss: 0.754281, acc: 0.410156]\n",
      "4699: [D loss: 0.707098, acc: 0.523438]  [A loss: 0.894328, acc: 0.160156]\n",
      "4700: [D loss: 0.689976, acc: 0.544922]  [A loss: 0.803623, acc: 0.300781]\n",
      "4701: [D loss: 0.715553, acc: 0.523438]  [A loss: 0.867728, acc: 0.218750]\n",
      "4702: [D loss: 0.685079, acc: 0.544922]  [A loss: 0.750175, acc: 0.406250]\n",
      "4703: [D loss: 0.712927, acc: 0.513672]  [A loss: 0.911895, acc: 0.097656]\n",
      "4704: [D loss: 0.700429, acc: 0.509766]  [A loss: 0.740316, acc: 0.441406]\n",
      "4705: [D loss: 0.715443, acc: 0.496094]  [A loss: 1.018901, acc: 0.070312]\n",
      "4706: [D loss: 0.685789, acc: 0.546875]  [A loss: 0.699515, acc: 0.531250]\n",
      "4707: [D loss: 0.730488, acc: 0.517578]  [A loss: 0.932892, acc: 0.144531]\n",
      "4708: [D loss: 0.704383, acc: 0.507812]  [A loss: 0.716537, acc: 0.480469]\n",
      "4709: [D loss: 0.725564, acc: 0.505859]  [A loss: 0.823352, acc: 0.289062]\n",
      "4710: [D loss: 0.696242, acc: 0.511719]  [A loss: 0.793358, acc: 0.308594]\n",
      "4711: [D loss: 0.706650, acc: 0.521484]  [A loss: 0.806158, acc: 0.328125]\n",
      "4712: [D loss: 0.701223, acc: 0.537109]  [A loss: 0.923766, acc: 0.144531]\n",
      "4713: [D loss: 0.689228, acc: 0.558594]  [A loss: 0.697397, acc: 0.476562]\n",
      "4714: [D loss: 0.720435, acc: 0.509766]  [A loss: 0.930388, acc: 0.152344]\n",
      "4715: [D loss: 0.685302, acc: 0.541016]  [A loss: 0.787782, acc: 0.347656]\n",
      "4716: [D loss: 0.708594, acc: 0.507812]  [A loss: 0.852187, acc: 0.222656]\n",
      "4717: [D loss: 0.708510, acc: 0.509766]  [A loss: 0.780598, acc: 0.316406]\n",
      "4718: [D loss: 0.702403, acc: 0.529297]  [A loss: 0.851094, acc: 0.210938]\n",
      "4719: [D loss: 0.695924, acc: 0.519531]  [A loss: 0.829635, acc: 0.257812]\n",
      "4720: [D loss: 0.700680, acc: 0.511719]  [A loss: 0.815683, acc: 0.312500]\n",
      "4721: [D loss: 0.691463, acc: 0.537109]  [A loss: 0.850486, acc: 0.203125]\n",
      "4722: [D loss: 0.684777, acc: 0.570312]  [A loss: 0.825657, acc: 0.273438]\n",
      "4723: [D loss: 0.696355, acc: 0.556641]  [A loss: 0.876824, acc: 0.160156]\n",
      "4724: [D loss: 0.693487, acc: 0.527344]  [A loss: 0.769364, acc: 0.371094]\n",
      "4725: [D loss: 0.708187, acc: 0.529297]  [A loss: 0.952366, acc: 0.132812]\n",
      "4726: [D loss: 0.697285, acc: 0.548828]  [A loss: 0.760838, acc: 0.367188]\n",
      "4727: [D loss: 0.709292, acc: 0.513672]  [A loss: 0.833564, acc: 0.257812]\n",
      "4728: [D loss: 0.703653, acc: 0.527344]  [A loss: 0.771082, acc: 0.386719]\n",
      "4729: [D loss: 0.707240, acc: 0.535156]  [A loss: 0.944741, acc: 0.136719]\n",
      "4730: [D loss: 0.676219, acc: 0.591797]  [A loss: 0.714973, acc: 0.457031]\n",
      "4731: [D loss: 0.740569, acc: 0.496094]  [A loss: 1.020107, acc: 0.085938]\n",
      "4732: [D loss: 0.716610, acc: 0.509766]  [A loss: 0.757808, acc: 0.433594]\n",
      "4733: [D loss: 0.710461, acc: 0.541016]  [A loss: 0.805992, acc: 0.316406]\n",
      "4734: [D loss: 0.713041, acc: 0.472656]  [A loss: 0.775506, acc: 0.371094]\n",
      "4735: [D loss: 0.689196, acc: 0.542969]  [A loss: 0.879793, acc: 0.187500]\n",
      "4736: [D loss: 0.698825, acc: 0.533203]  [A loss: 0.822680, acc: 0.308594]\n",
      "4737: [D loss: 0.689280, acc: 0.539062]  [A loss: 0.825534, acc: 0.289062]\n",
      "4738: [D loss: 0.724215, acc: 0.457031]  [A loss: 0.945550, acc: 0.136719]\n",
      "4739: [D loss: 0.708837, acc: 0.500000]  [A loss: 0.732165, acc: 0.449219]\n",
      "4740: [D loss: 0.734104, acc: 0.505859]  [A loss: 1.100980, acc: 0.050781]\n",
      "4741: [D loss: 0.707466, acc: 0.537109]  [A loss: 0.721382, acc: 0.457031]\n",
      "4742: [D loss: 0.717423, acc: 0.517578]  [A loss: 0.813882, acc: 0.300781]\n",
      "4743: [D loss: 0.709228, acc: 0.501953]  [A loss: 0.755248, acc: 0.382812]\n",
      "4744: [D loss: 0.707383, acc: 0.544922]  [A loss: 0.865728, acc: 0.187500]\n",
      "4745: [D loss: 0.703807, acc: 0.519531]  [A loss: 0.839631, acc: 0.261719]\n",
      "4746: [D loss: 0.733483, acc: 0.513672]  [A loss: 0.994569, acc: 0.093750]\n",
      "4747: [D loss: 0.708699, acc: 0.494141]  [A loss: 0.711916, acc: 0.480469]\n",
      "4748: [D loss: 0.722277, acc: 0.519531]  [A loss: 0.887579, acc: 0.191406]\n",
      "4749: [D loss: 0.697344, acc: 0.560547]  [A loss: 0.809317, acc: 0.312500]\n",
      "4750: [D loss: 0.692610, acc: 0.537109]  [A loss: 0.834321, acc: 0.242188]\n",
      "4751: [D loss: 0.696752, acc: 0.525391]  [A loss: 0.923494, acc: 0.152344]\n",
      "4752: [D loss: 0.695192, acc: 0.519531]  [A loss: 0.700134, acc: 0.515625]\n",
      "4753: [D loss: 0.721858, acc: 0.513672]  [A loss: 0.965940, acc: 0.125000]\n",
      "4754: [D loss: 0.706599, acc: 0.535156]  [A loss: 0.734497, acc: 0.425781]\n",
      "4755: [D loss: 0.711463, acc: 0.539062]  [A loss: 0.926844, acc: 0.136719]\n",
      "4756: [D loss: 0.715161, acc: 0.503906]  [A loss: 0.745266, acc: 0.414062]\n",
      "4757: [D loss: 0.704743, acc: 0.531250]  [A loss: 0.850791, acc: 0.218750]\n",
      "4758: [D loss: 0.686695, acc: 0.566406]  [A loss: 0.847227, acc: 0.238281]\n",
      "4759: [D loss: 0.695416, acc: 0.537109]  [A loss: 0.843241, acc: 0.250000]\n",
      "4760: [D loss: 0.687862, acc: 0.546875]  [A loss: 0.844011, acc: 0.222656]\n",
      "4761: [D loss: 0.707402, acc: 0.517578]  [A loss: 0.966450, acc: 0.117188]\n",
      "4762: [D loss: 0.705405, acc: 0.533203]  [A loss: 0.705295, acc: 0.457031]\n",
      "4763: [D loss: 0.751224, acc: 0.494141]  [A loss: 1.074230, acc: 0.062500]\n",
      "4764: [D loss: 0.720369, acc: 0.501953]  [A loss: 0.802168, acc: 0.355469]\n",
      "4765: [D loss: 0.718446, acc: 0.529297]  [A loss: 0.861538, acc: 0.210938]\n",
      "4766: [D loss: 0.696924, acc: 0.523438]  [A loss: 0.789526, acc: 0.324219]\n",
      "4767: [D loss: 0.717819, acc: 0.496094]  [A loss: 0.821388, acc: 0.261719]\n",
      "4768: [D loss: 0.677197, acc: 0.587891]  [A loss: 0.806098, acc: 0.312500]\n",
      "4769: [D loss: 0.709765, acc: 0.517578]  [A loss: 0.840389, acc: 0.230469]\n",
      "4770: [D loss: 0.693581, acc: 0.537109]  [A loss: 0.823470, acc: 0.273438]\n",
      "4771: [D loss: 0.687422, acc: 0.550781]  [A loss: 0.884218, acc: 0.179688]\n",
      "4772: [D loss: 0.697020, acc: 0.517578]  [A loss: 0.747282, acc: 0.425781]\n",
      "4773: [D loss: 0.716628, acc: 0.539062]  [A loss: 0.957661, acc: 0.121094]\n",
      "4774: [D loss: 0.710523, acc: 0.488281]  [A loss: 0.772480, acc: 0.351562]\n",
      "4775: [D loss: 0.713031, acc: 0.511719]  [A loss: 0.894457, acc: 0.171875]\n",
      "4776: [D loss: 0.709836, acc: 0.492188]  [A loss: 0.781616, acc: 0.292969]\n",
      "4777: [D loss: 0.708147, acc: 0.507812]  [A loss: 0.922253, acc: 0.125000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4778: [D loss: 0.690451, acc: 0.560547]  [A loss: 0.722611, acc: 0.500000]\n",
      "4779: [D loss: 0.732265, acc: 0.500000]  [A loss: 0.995128, acc: 0.097656]\n",
      "4780: [D loss: 0.704379, acc: 0.507812]  [A loss: 0.706288, acc: 0.511719]\n",
      "4781: [D loss: 0.733225, acc: 0.486328]  [A loss: 0.947319, acc: 0.078125]\n",
      "4782: [D loss: 0.705245, acc: 0.505859]  [A loss: 0.727916, acc: 0.421875]\n",
      "4783: [D loss: 0.721112, acc: 0.505859]  [A loss: 0.935664, acc: 0.125000]\n",
      "4784: [D loss: 0.689551, acc: 0.511719]  [A loss: 0.700995, acc: 0.496094]\n",
      "4785: [D loss: 0.712578, acc: 0.513672]  [A loss: 0.899392, acc: 0.152344]\n",
      "4786: [D loss: 0.699620, acc: 0.515625]  [A loss: 0.747190, acc: 0.414062]\n",
      "4787: [D loss: 0.723363, acc: 0.533203]  [A loss: 0.952809, acc: 0.101562]\n",
      "4788: [D loss: 0.699149, acc: 0.513672]  [A loss: 0.750278, acc: 0.390625]\n",
      "4789: [D loss: 0.728418, acc: 0.509766]  [A loss: 0.896702, acc: 0.164062]\n",
      "4790: [D loss: 0.716908, acc: 0.466797]  [A loss: 0.761898, acc: 0.371094]\n",
      "4791: [D loss: 0.714801, acc: 0.511719]  [A loss: 0.793161, acc: 0.324219]\n",
      "4792: [D loss: 0.725846, acc: 0.498047]  [A loss: 0.858592, acc: 0.214844]\n",
      "4793: [D loss: 0.704674, acc: 0.537109]  [A loss: 0.757485, acc: 0.363281]\n",
      "4794: [D loss: 0.712234, acc: 0.525391]  [A loss: 0.917192, acc: 0.152344]\n",
      "4795: [D loss: 0.694508, acc: 0.523438]  [A loss: 0.698622, acc: 0.542969]\n",
      "4796: [D loss: 0.720537, acc: 0.507812]  [A loss: 0.996153, acc: 0.066406]\n",
      "4797: [D loss: 0.691873, acc: 0.541016]  [A loss: 0.768234, acc: 0.355469]\n",
      "4798: [D loss: 0.729720, acc: 0.486328]  [A loss: 0.851085, acc: 0.207031]\n",
      "4799: [D loss: 0.705211, acc: 0.511719]  [A loss: 0.783211, acc: 0.332031]\n",
      "4800: [D loss: 0.696705, acc: 0.531250]  [A loss: 0.864224, acc: 0.195312]\n",
      "4801: [D loss: 0.693667, acc: 0.527344]  [A loss: 0.799616, acc: 0.296875]\n",
      "4802: [D loss: 0.706337, acc: 0.519531]  [A loss: 0.899409, acc: 0.167969]\n",
      "4803: [D loss: 0.698134, acc: 0.531250]  [A loss: 0.757374, acc: 0.390625]\n",
      "4804: [D loss: 0.726536, acc: 0.501953]  [A loss: 0.957081, acc: 0.113281]\n",
      "4805: [D loss: 0.708913, acc: 0.509766]  [A loss: 0.723870, acc: 0.437500]\n",
      "4806: [D loss: 0.729809, acc: 0.507812]  [A loss: 0.905615, acc: 0.156250]\n",
      "4807: [D loss: 0.704206, acc: 0.492188]  [A loss: 0.771925, acc: 0.371094]\n",
      "4808: [D loss: 0.706214, acc: 0.527344]  [A loss: 0.839374, acc: 0.230469]\n",
      "4809: [D loss: 0.713767, acc: 0.521484]  [A loss: 0.821330, acc: 0.289062]\n",
      "4810: [D loss: 0.707833, acc: 0.517578]  [A loss: 0.913062, acc: 0.148438]\n",
      "4811: [D loss: 0.692266, acc: 0.523438]  [A loss: 0.759181, acc: 0.398438]\n",
      "4812: [D loss: 0.697141, acc: 0.525391]  [A loss: 0.867098, acc: 0.222656]\n",
      "4813: [D loss: 0.695781, acc: 0.531250]  [A loss: 0.800964, acc: 0.328125]\n",
      "4814: [D loss: 0.698659, acc: 0.533203]  [A loss: 0.841227, acc: 0.242188]\n",
      "4815: [D loss: 0.696597, acc: 0.513672]  [A loss: 0.801937, acc: 0.328125]\n",
      "4816: [D loss: 0.708364, acc: 0.505859]  [A loss: 0.864157, acc: 0.230469]\n",
      "4817: [D loss: 0.700175, acc: 0.498047]  [A loss: 0.773858, acc: 0.363281]\n",
      "4818: [D loss: 0.713049, acc: 0.486328]  [A loss: 0.892775, acc: 0.218750]\n",
      "4819: [D loss: 0.717369, acc: 0.503906]  [A loss: 0.771027, acc: 0.347656]\n",
      "4820: [D loss: 0.715458, acc: 0.501953]  [A loss: 0.940264, acc: 0.132812]\n",
      "4821: [D loss: 0.706809, acc: 0.521484]  [A loss: 0.746144, acc: 0.421875]\n",
      "4822: [D loss: 0.715336, acc: 0.521484]  [A loss: 0.956225, acc: 0.117188]\n",
      "4823: [D loss: 0.701038, acc: 0.515625]  [A loss: 0.731160, acc: 0.460938]\n",
      "4824: [D loss: 0.710066, acc: 0.505859]  [A loss: 0.835810, acc: 0.250000]\n",
      "4825: [D loss: 0.705366, acc: 0.523438]  [A loss: 0.763169, acc: 0.375000]\n",
      "4826: [D loss: 0.720906, acc: 0.498047]  [A loss: 0.950541, acc: 0.117188]\n",
      "4827: [D loss: 0.685752, acc: 0.556641]  [A loss: 0.693127, acc: 0.531250]\n",
      "4828: [D loss: 0.730813, acc: 0.503906]  [A loss: 1.048126, acc: 0.085938]\n",
      "4829: [D loss: 0.698171, acc: 0.564453]  [A loss: 0.699908, acc: 0.535156]\n",
      "4830: [D loss: 0.775770, acc: 0.498047]  [A loss: 0.855440, acc: 0.191406]\n",
      "4831: [D loss: 0.693585, acc: 0.542969]  [A loss: 0.773088, acc: 0.339844]\n",
      "4832: [D loss: 0.711696, acc: 0.531250]  [A loss: 0.991011, acc: 0.097656]\n",
      "4833: [D loss: 0.707136, acc: 0.507812]  [A loss: 0.690858, acc: 0.519531]\n",
      "4834: [D loss: 0.710783, acc: 0.531250]  [A loss: 0.872089, acc: 0.222656]\n",
      "4835: [D loss: 0.703036, acc: 0.521484]  [A loss: 0.793101, acc: 0.347656]\n",
      "4836: [D loss: 0.699180, acc: 0.519531]  [A loss: 0.822478, acc: 0.265625]\n",
      "4837: [D loss: 0.706203, acc: 0.533203]  [A loss: 0.827720, acc: 0.269531]\n",
      "4838: [D loss: 0.693214, acc: 0.539062]  [A loss: 0.813101, acc: 0.242188]\n",
      "4839: [D loss: 0.718075, acc: 0.500000]  [A loss: 0.862955, acc: 0.218750]\n",
      "4840: [D loss: 0.709441, acc: 0.500000]  [A loss: 0.801518, acc: 0.296875]\n",
      "4841: [D loss: 0.719003, acc: 0.492188]  [A loss: 0.852898, acc: 0.250000]\n",
      "4842: [D loss: 0.699390, acc: 0.541016]  [A loss: 0.760604, acc: 0.363281]\n",
      "4843: [D loss: 0.718835, acc: 0.515625]  [A loss: 0.988189, acc: 0.101562]\n",
      "4844: [D loss: 0.712995, acc: 0.486328]  [A loss: 0.727380, acc: 0.472656]\n",
      "4845: [D loss: 0.710456, acc: 0.537109]  [A loss: 0.871964, acc: 0.183594]\n",
      "4846: [D loss: 0.695300, acc: 0.527344]  [A loss: 0.763321, acc: 0.351562]\n",
      "4847: [D loss: 0.724992, acc: 0.492188]  [A loss: 0.899518, acc: 0.171875]\n",
      "4848: [D loss: 0.697979, acc: 0.542969]  [A loss: 0.757151, acc: 0.410156]\n",
      "4849: [D loss: 0.724707, acc: 0.496094]  [A loss: 0.929959, acc: 0.148438]\n",
      "4850: [D loss: 0.698735, acc: 0.533203]  [A loss: 0.703619, acc: 0.484375]\n",
      "4851: [D loss: 0.718453, acc: 0.515625]  [A loss: 1.005018, acc: 0.085938]\n",
      "4852: [D loss: 0.690235, acc: 0.546875]  [A loss: 0.748326, acc: 0.402344]\n",
      "4853: [D loss: 0.725534, acc: 0.498047]  [A loss: 0.879498, acc: 0.199219]\n",
      "4854: [D loss: 0.703790, acc: 0.525391]  [A loss: 0.758068, acc: 0.378906]\n",
      "4855: [D loss: 0.699772, acc: 0.531250]  [A loss: 0.799352, acc: 0.312500]\n",
      "4856: [D loss: 0.707020, acc: 0.527344]  [A loss: 0.901716, acc: 0.203125]\n",
      "4857: [D loss: 0.688551, acc: 0.533203]  [A loss: 0.779971, acc: 0.316406]\n",
      "4858: [D loss: 0.715357, acc: 0.509766]  [A loss: 0.883441, acc: 0.191406]\n",
      "4859: [D loss: 0.673016, acc: 0.580078]  [A loss: 0.718684, acc: 0.460938]\n",
      "4860: [D loss: 0.744878, acc: 0.496094]  [A loss: 0.972492, acc: 0.140625]\n",
      "4861: [D loss: 0.700680, acc: 0.556641]  [A loss: 0.721399, acc: 0.468750]\n",
      "4862: [D loss: 0.701819, acc: 0.550781]  [A loss: 0.871518, acc: 0.226562]\n",
      "4863: [D loss: 0.713782, acc: 0.488281]  [A loss: 0.703854, acc: 0.531250]\n",
      "4864: [D loss: 0.698297, acc: 0.521484]  [A loss: 0.913227, acc: 0.191406]\n",
      "4865: [D loss: 0.693716, acc: 0.531250]  [A loss: 0.766130, acc: 0.406250]\n",
      "4866: [D loss: 0.704950, acc: 0.527344]  [A loss: 0.826553, acc: 0.285156]\n",
      "4867: [D loss: 0.690855, acc: 0.521484]  [A loss: 0.806461, acc: 0.308594]\n",
      "4868: [D loss: 0.693750, acc: 0.541016]  [A loss: 0.853101, acc: 0.289062]\n",
      "4869: [D loss: 0.714192, acc: 0.490234]  [A loss: 0.784366, acc: 0.371094]\n",
      "4870: [D loss: 0.722184, acc: 0.519531]  [A loss: 1.021649, acc: 0.074219]\n",
      "4871: [D loss: 0.718313, acc: 0.500000]  [A loss: 0.713809, acc: 0.496094]\n",
      "4872: [D loss: 0.692860, acc: 0.529297]  [A loss: 0.854304, acc: 0.214844]\n",
      "4873: [D loss: 0.692133, acc: 0.544922]  [A loss: 0.743553, acc: 0.402344]\n",
      "4874: [D loss: 0.702990, acc: 0.527344]  [A loss: 0.856953, acc: 0.175781]\n",
      "4875: [D loss: 0.697788, acc: 0.548828]  [A loss: 0.747887, acc: 0.410156]\n",
      "4876: [D loss: 0.719116, acc: 0.494141]  [A loss: 0.924415, acc: 0.132812]\n",
      "4877: [D loss: 0.714864, acc: 0.490234]  [A loss: 0.727813, acc: 0.460938]\n",
      "4878: [D loss: 0.718228, acc: 0.494141]  [A loss: 0.927682, acc: 0.121094]\n",
      "4879: [D loss: 0.693813, acc: 0.541016]  [A loss: 0.717933, acc: 0.507812]\n",
      "4880: [D loss: 0.708499, acc: 0.517578]  [A loss: 0.921714, acc: 0.187500]\n",
      "4881: [D loss: 0.709910, acc: 0.531250]  [A loss: 0.717217, acc: 0.453125]\n",
      "4882: [D loss: 0.721095, acc: 0.511719]  [A loss: 1.002851, acc: 0.152344]\n",
      "4883: [D loss: 0.708903, acc: 0.525391]  [A loss: 0.726737, acc: 0.472656]\n",
      "4884: [D loss: 0.708472, acc: 0.498047]  [A loss: 0.819806, acc: 0.289062]\n",
      "4885: [D loss: 0.700901, acc: 0.541016]  [A loss: 0.896299, acc: 0.164062]\n",
      "4886: [D loss: 0.703919, acc: 0.523438]  [A loss: 0.751132, acc: 0.414062]\n",
      "4887: [D loss: 0.711625, acc: 0.535156]  [A loss: 0.896409, acc: 0.187500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4888: [D loss: 0.706524, acc: 0.509766]  [A loss: 0.732744, acc: 0.441406]\n",
      "4889: [D loss: 0.719153, acc: 0.496094]  [A loss: 0.927120, acc: 0.132812]\n",
      "4890: [D loss: 0.707329, acc: 0.509766]  [A loss: 0.775643, acc: 0.347656]\n",
      "4891: [D loss: 0.701695, acc: 0.515625]  [A loss: 0.847207, acc: 0.250000]\n",
      "4892: [D loss: 0.706587, acc: 0.503906]  [A loss: 0.806316, acc: 0.300781]\n",
      "4893: [D loss: 0.694721, acc: 0.562500]  [A loss: 0.838320, acc: 0.250000]\n",
      "4894: [D loss: 0.701903, acc: 0.544922]  [A loss: 0.833021, acc: 0.269531]\n",
      "4895: [D loss: 0.705863, acc: 0.511719]  [A loss: 0.785439, acc: 0.343750]\n",
      "4896: [D loss: 0.693882, acc: 0.539062]  [A loss: 0.842985, acc: 0.246094]\n",
      "4897: [D loss: 0.708280, acc: 0.501953]  [A loss: 0.799394, acc: 0.332031]\n",
      "4898: [D loss: 0.711041, acc: 0.505859]  [A loss: 0.839324, acc: 0.230469]\n",
      "4899: [D loss: 0.703068, acc: 0.548828]  [A loss: 0.794135, acc: 0.359375]\n",
      "4900: [D loss: 0.711162, acc: 0.523438]  [A loss: 0.881914, acc: 0.203125]\n",
      "4901: [D loss: 0.697399, acc: 0.519531]  [A loss: 0.723243, acc: 0.445312]\n",
      "4902: [D loss: 0.710849, acc: 0.523438]  [A loss: 1.062648, acc: 0.046875]\n",
      "4903: [D loss: 0.702815, acc: 0.527344]  [A loss: 0.710792, acc: 0.472656]\n",
      "4904: [D loss: 0.722611, acc: 0.496094]  [A loss: 0.875598, acc: 0.171875]\n",
      "4905: [D loss: 0.690303, acc: 0.564453]  [A loss: 0.751011, acc: 0.421875]\n",
      "4906: [D loss: 0.713536, acc: 0.496094]  [A loss: 0.823556, acc: 0.285156]\n",
      "4907: [D loss: 0.678866, acc: 0.574219]  [A loss: 0.810855, acc: 0.312500]\n",
      "4908: [D loss: 0.720341, acc: 0.529297]  [A loss: 1.030340, acc: 0.046875]\n",
      "4909: [D loss: 0.711044, acc: 0.507812]  [A loss: 0.731875, acc: 0.457031]\n",
      "4910: [D loss: 0.709189, acc: 0.519531]  [A loss: 0.866355, acc: 0.199219]\n",
      "4911: [D loss: 0.707223, acc: 0.515625]  [A loss: 0.707581, acc: 0.484375]\n",
      "4912: [D loss: 0.709084, acc: 0.513672]  [A loss: 0.915645, acc: 0.144531]\n",
      "4913: [D loss: 0.703404, acc: 0.490234]  [A loss: 0.728736, acc: 0.441406]\n",
      "4914: [D loss: 0.706305, acc: 0.525391]  [A loss: 0.861338, acc: 0.234375]\n",
      "4915: [D loss: 0.697433, acc: 0.523438]  [A loss: 0.765618, acc: 0.355469]\n",
      "4916: [D loss: 0.703179, acc: 0.541016]  [A loss: 0.943382, acc: 0.136719]\n",
      "4917: [D loss: 0.697944, acc: 0.542969]  [A loss: 0.690347, acc: 0.546875]\n",
      "4918: [D loss: 0.745176, acc: 0.509766]  [A loss: 0.966576, acc: 0.125000]\n",
      "4919: [D loss: 0.718860, acc: 0.482422]  [A loss: 0.770111, acc: 0.359375]\n",
      "4920: [D loss: 0.716328, acc: 0.521484]  [A loss: 0.790635, acc: 0.308594]\n",
      "4921: [D loss: 0.704925, acc: 0.535156]  [A loss: 0.815589, acc: 0.304688]\n",
      "4922: [D loss: 0.705759, acc: 0.500000]  [A loss: 0.831018, acc: 0.222656]\n",
      "4923: [D loss: 0.710080, acc: 0.509766]  [A loss: 0.755543, acc: 0.417969]\n",
      "4924: [D loss: 0.716436, acc: 0.500000]  [A loss: 0.952670, acc: 0.097656]\n",
      "4925: [D loss: 0.707679, acc: 0.521484]  [A loss: 0.758147, acc: 0.390625]\n",
      "4926: [D loss: 0.727917, acc: 0.500000]  [A loss: 0.946197, acc: 0.152344]\n",
      "4927: [D loss: 0.697159, acc: 0.544922]  [A loss: 0.720716, acc: 0.468750]\n",
      "4928: [D loss: 0.725362, acc: 0.533203]  [A loss: 0.902369, acc: 0.152344]\n",
      "4929: [D loss: 0.693301, acc: 0.521484]  [A loss: 0.676172, acc: 0.582031]\n",
      "4930: [D loss: 0.770865, acc: 0.492188]  [A loss: 1.058535, acc: 0.058594]\n",
      "4931: [D loss: 0.717092, acc: 0.513672]  [A loss: 0.742432, acc: 0.390625]\n",
      "4932: [D loss: 0.734747, acc: 0.505859]  [A loss: 0.921689, acc: 0.148438]\n",
      "4933: [D loss: 0.708565, acc: 0.503906]  [A loss: 0.749755, acc: 0.371094]\n",
      "4934: [D loss: 0.726392, acc: 0.507812]  [A loss: 0.787546, acc: 0.312500]\n",
      "4935: [D loss: 0.720580, acc: 0.513672]  [A loss: 0.782294, acc: 0.300781]\n",
      "4936: [D loss: 0.690836, acc: 0.550781]  [A loss: 0.767118, acc: 0.359375]\n",
      "4937: [D loss: 0.708578, acc: 0.513672]  [A loss: 0.925508, acc: 0.109375]\n",
      "4938: [D loss: 0.691768, acc: 0.552734]  [A loss: 0.704418, acc: 0.464844]\n",
      "4939: [D loss: 0.716316, acc: 0.527344]  [A loss: 0.995486, acc: 0.109375]\n",
      "4940: [D loss: 0.702075, acc: 0.548828]  [A loss: 0.715902, acc: 0.492188]\n",
      "4941: [D loss: 0.712925, acc: 0.515625]  [A loss: 0.765925, acc: 0.375000]\n",
      "4942: [D loss: 0.705745, acc: 0.531250]  [A loss: 0.793649, acc: 0.359375]\n",
      "4943: [D loss: 0.704989, acc: 0.550781]  [A loss: 0.810955, acc: 0.246094]\n",
      "4944: [D loss: 0.701622, acc: 0.513672]  [A loss: 0.802142, acc: 0.269531]\n",
      "4945: [D loss: 0.703131, acc: 0.501953]  [A loss: 0.866194, acc: 0.210938]\n",
      "4946: [D loss: 0.700614, acc: 0.507812]  [A loss: 0.778083, acc: 0.312500]\n",
      "4947: [D loss: 0.704247, acc: 0.527344]  [A loss: 0.865781, acc: 0.230469]\n",
      "4948: [D loss: 0.705883, acc: 0.498047]  [A loss: 0.763104, acc: 0.386719]\n",
      "4949: [D loss: 0.708755, acc: 0.505859]  [A loss: 0.948977, acc: 0.109375]\n",
      "4950: [D loss: 0.702406, acc: 0.486328]  [A loss: 0.704288, acc: 0.492188]\n",
      "4951: [D loss: 0.721567, acc: 0.525391]  [A loss: 0.966077, acc: 0.109375]\n",
      "4952: [D loss: 0.730242, acc: 0.474609]  [A loss: 0.787884, acc: 0.363281]\n",
      "4953: [D loss: 0.706994, acc: 0.519531]  [A loss: 0.766935, acc: 0.343750]\n",
      "4954: [D loss: 0.699980, acc: 0.525391]  [A loss: 0.805433, acc: 0.281250]\n",
      "4955: [D loss: 0.698675, acc: 0.531250]  [A loss: 0.768129, acc: 0.363281]\n",
      "4956: [D loss: 0.696189, acc: 0.507812]  [A loss: 0.798250, acc: 0.320312]\n",
      "4957: [D loss: 0.715105, acc: 0.472656]  [A loss: 0.780149, acc: 0.347656]\n",
      "4958: [D loss: 0.706562, acc: 0.513672]  [A loss: 0.842828, acc: 0.226562]\n",
      "4959: [D loss: 0.699988, acc: 0.541016]  [A loss: 0.802801, acc: 0.292969]\n",
      "4960: [D loss: 0.710874, acc: 0.519531]  [A loss: 0.909790, acc: 0.128906]\n",
      "4961: [D loss: 0.683170, acc: 0.568359]  [A loss: 0.738831, acc: 0.414062]\n",
      "4962: [D loss: 0.713165, acc: 0.503906]  [A loss: 0.876274, acc: 0.183594]\n",
      "4963: [D loss: 0.696667, acc: 0.539062]  [A loss: 0.713987, acc: 0.453125]\n",
      "4964: [D loss: 0.703947, acc: 0.537109]  [A loss: 0.892384, acc: 0.175781]\n",
      "4965: [D loss: 0.702550, acc: 0.539062]  [A loss: 0.779935, acc: 0.335938]\n",
      "4966: [D loss: 0.708135, acc: 0.494141]  [A loss: 0.836740, acc: 0.250000]\n",
      "4967: [D loss: 0.701480, acc: 0.529297]  [A loss: 0.797633, acc: 0.300781]\n",
      "4968: [D loss: 0.714497, acc: 0.509766]  [A loss: 0.942514, acc: 0.144531]\n",
      "4969: [D loss: 0.714581, acc: 0.490234]  [A loss: 0.690511, acc: 0.527344]\n",
      "4970: [D loss: 0.713204, acc: 0.505859]  [A loss: 0.947914, acc: 0.171875]\n",
      "4971: [D loss: 0.693953, acc: 0.515625]  [A loss: 0.725196, acc: 0.453125]\n",
      "4972: [D loss: 0.706802, acc: 0.523438]  [A loss: 0.778926, acc: 0.343750]\n",
      "4973: [D loss: 0.715759, acc: 0.517578]  [A loss: 0.798388, acc: 0.300781]\n",
      "4974: [D loss: 0.707002, acc: 0.511719]  [A loss: 0.919696, acc: 0.125000]\n",
      "4975: [D loss: 0.691304, acc: 0.554688]  [A loss: 0.715873, acc: 0.441406]\n",
      "4976: [D loss: 0.722879, acc: 0.525391]  [A loss: 0.931998, acc: 0.164062]\n",
      "4977: [D loss: 0.708679, acc: 0.509766]  [A loss: 0.741790, acc: 0.398438]\n",
      "4978: [D loss: 0.714234, acc: 0.515625]  [A loss: 0.889687, acc: 0.187500]\n",
      "4979: [D loss: 0.696939, acc: 0.509766]  [A loss: 0.740767, acc: 0.410156]\n",
      "4980: [D loss: 0.711133, acc: 0.505859]  [A loss: 0.855864, acc: 0.238281]\n",
      "4981: [D loss: 0.689302, acc: 0.537109]  [A loss: 0.804339, acc: 0.308594]\n",
      "4982: [D loss: 0.695527, acc: 0.523438]  [A loss: 0.775718, acc: 0.347656]\n",
      "4983: [D loss: 0.711640, acc: 0.505859]  [A loss: 0.782042, acc: 0.335938]\n",
      "4984: [D loss: 0.699993, acc: 0.541016]  [A loss: 0.913828, acc: 0.148438]\n",
      "4985: [D loss: 0.688580, acc: 0.517578]  [A loss: 0.738899, acc: 0.433594]\n",
      "4986: [D loss: 0.717256, acc: 0.490234]  [A loss: 0.906149, acc: 0.218750]\n",
      "4987: [D loss: 0.702123, acc: 0.511719]  [A loss: 0.788585, acc: 0.304688]\n",
      "4988: [D loss: 0.714387, acc: 0.501953]  [A loss: 0.788903, acc: 0.320312]\n",
      "4989: [D loss: 0.708161, acc: 0.529297]  [A loss: 0.772496, acc: 0.339844]\n",
      "4990: [D loss: 0.703406, acc: 0.529297]  [A loss: 0.885805, acc: 0.183594]\n",
      "4991: [D loss: 0.693456, acc: 0.537109]  [A loss: 0.787599, acc: 0.332031]\n",
      "4992: [D loss: 0.695190, acc: 0.531250]  [A loss: 0.952851, acc: 0.117188]\n",
      "4993: [D loss: 0.699425, acc: 0.511719]  [A loss: 0.707255, acc: 0.480469]\n",
      "4994: [D loss: 0.711622, acc: 0.527344]  [A loss: 0.917518, acc: 0.179688]\n",
      "4995: [D loss: 0.704429, acc: 0.550781]  [A loss: 0.717802, acc: 0.453125]\n",
      "4996: [D loss: 0.729601, acc: 0.496094]  [A loss: 0.917189, acc: 0.144531]\n",
      "4997: [D loss: 0.711956, acc: 0.492188]  [A loss: 0.760189, acc: 0.382812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4998: [D loss: 0.730165, acc: 0.494141]  [A loss: 0.948670, acc: 0.140625]\n",
      "4999: [D loss: 0.705492, acc: 0.525391]  [A loss: 0.728893, acc: 0.445312]\n",
      "5000: [D loss: 0.724210, acc: 0.523438]  [A loss: 0.906220, acc: 0.160156]\n",
      "5001: [D loss: 0.701326, acc: 0.498047]  [A loss: 0.737491, acc: 0.402344]\n",
      "5002: [D loss: 0.736570, acc: 0.498047]  [A loss: 1.053423, acc: 0.074219]\n",
      "5003: [D loss: 0.708079, acc: 0.519531]  [A loss: 0.730882, acc: 0.410156]\n",
      "5004: [D loss: 0.724187, acc: 0.472656]  [A loss: 0.804143, acc: 0.304688]\n",
      "5005: [D loss: 0.714247, acc: 0.494141]  [A loss: 0.772789, acc: 0.371094]\n",
      "5006: [D loss: 0.713340, acc: 0.521484]  [A loss: 0.885586, acc: 0.167969]\n",
      "5007: [D loss: 0.716703, acc: 0.500000]  [A loss: 0.759693, acc: 0.394531]\n",
      "5008: [D loss: 0.710930, acc: 0.525391]  [A loss: 0.865090, acc: 0.210938]\n",
      "5009: [D loss: 0.699928, acc: 0.541016]  [A loss: 0.773738, acc: 0.398438]\n",
      "5010: [D loss: 0.711650, acc: 0.531250]  [A loss: 0.983227, acc: 0.089844]\n",
      "5011: [D loss: 0.719101, acc: 0.480469]  [A loss: 0.689215, acc: 0.554688]\n",
      "5012: [D loss: 0.711093, acc: 0.511719]  [A loss: 0.815921, acc: 0.242188]\n",
      "5013: [D loss: 0.689582, acc: 0.562500]  [A loss: 0.793173, acc: 0.328125]\n",
      "5014: [D loss: 0.713157, acc: 0.480469]  [A loss: 0.770140, acc: 0.339844]\n",
      "5015: [D loss: 0.694718, acc: 0.550781]  [A loss: 0.894217, acc: 0.195312]\n",
      "5016: [D loss: 0.698580, acc: 0.544922]  [A loss: 0.729740, acc: 0.460938]\n",
      "5017: [D loss: 0.714469, acc: 0.509766]  [A loss: 0.923258, acc: 0.140625]\n",
      "5018: [D loss: 0.703145, acc: 0.517578]  [A loss: 0.715964, acc: 0.511719]\n",
      "5019: [D loss: 0.716188, acc: 0.527344]  [A loss: 0.875578, acc: 0.218750]\n",
      "5020: [D loss: 0.695453, acc: 0.525391]  [A loss: 0.752504, acc: 0.437500]\n",
      "5021: [D loss: 0.714960, acc: 0.503906]  [A loss: 0.859569, acc: 0.183594]\n",
      "5022: [D loss: 0.696725, acc: 0.509766]  [A loss: 0.836454, acc: 0.207031]\n",
      "5023: [D loss: 0.704160, acc: 0.509766]  [A loss: 0.832668, acc: 0.238281]\n",
      "5024: [D loss: 0.701024, acc: 0.546875]  [A loss: 0.880742, acc: 0.187500]\n",
      "5025: [D loss: 0.691786, acc: 0.513672]  [A loss: 0.790763, acc: 0.320312]\n",
      "5026: [D loss: 0.736026, acc: 0.478516]  [A loss: 1.026372, acc: 0.050781]\n",
      "5027: [D loss: 0.694924, acc: 0.533203]  [A loss: 0.679864, acc: 0.535156]\n",
      "5028: [D loss: 0.748901, acc: 0.500000]  [A loss: 0.980200, acc: 0.082031]\n",
      "5029: [D loss: 0.702923, acc: 0.513672]  [A loss: 0.717015, acc: 0.480469]\n",
      "5030: [D loss: 0.725391, acc: 0.486328]  [A loss: 0.860252, acc: 0.195312]\n",
      "5031: [D loss: 0.684816, acc: 0.552734]  [A loss: 0.748894, acc: 0.382812]\n",
      "5032: [D loss: 0.726090, acc: 0.500000]  [A loss: 0.939298, acc: 0.121094]\n",
      "5033: [D loss: 0.701727, acc: 0.503906]  [A loss: 0.717285, acc: 0.464844]\n",
      "5034: [D loss: 0.719505, acc: 0.494141]  [A loss: 0.837670, acc: 0.226562]\n",
      "5035: [D loss: 0.704488, acc: 0.511719]  [A loss: 0.800030, acc: 0.234375]\n",
      "5036: [D loss: 0.702290, acc: 0.535156]  [A loss: 0.896521, acc: 0.175781]\n",
      "5037: [D loss: 0.697189, acc: 0.521484]  [A loss: 0.743248, acc: 0.402344]\n",
      "5038: [D loss: 0.706551, acc: 0.523438]  [A loss: 0.922569, acc: 0.117188]\n",
      "5039: [D loss: 0.691568, acc: 0.546875]  [A loss: 0.762044, acc: 0.386719]\n",
      "5040: [D loss: 0.698146, acc: 0.539062]  [A loss: 0.857751, acc: 0.191406]\n",
      "5041: [D loss: 0.707502, acc: 0.529297]  [A loss: 0.766608, acc: 0.347656]\n",
      "5042: [D loss: 0.724437, acc: 0.498047]  [A loss: 0.847413, acc: 0.222656]\n",
      "5043: [D loss: 0.690248, acc: 0.535156]  [A loss: 0.772533, acc: 0.406250]\n",
      "5044: [D loss: 0.703653, acc: 0.525391]  [A loss: 0.874418, acc: 0.214844]\n",
      "5045: [D loss: 0.688744, acc: 0.580078]  [A loss: 0.793745, acc: 0.335938]\n",
      "5046: [D loss: 0.694658, acc: 0.548828]  [A loss: 0.892561, acc: 0.148438]\n",
      "5047: [D loss: 0.697001, acc: 0.525391]  [A loss: 0.770988, acc: 0.386719]\n",
      "5048: [D loss: 0.705192, acc: 0.541016]  [A loss: 1.003026, acc: 0.082031]\n",
      "5049: [D loss: 0.694934, acc: 0.533203]  [A loss: 0.735001, acc: 0.441406]\n",
      "5050: [D loss: 0.714114, acc: 0.509766]  [A loss: 0.952260, acc: 0.105469]\n",
      "5051: [D loss: 0.714729, acc: 0.496094]  [A loss: 0.660697, acc: 0.617188]\n",
      "5052: [D loss: 0.706806, acc: 0.531250]  [A loss: 0.967909, acc: 0.113281]\n",
      "5053: [D loss: 0.695450, acc: 0.533203]  [A loss: 0.791260, acc: 0.332031]\n",
      "5054: [D loss: 0.697784, acc: 0.548828]  [A loss: 0.856155, acc: 0.214844]\n",
      "5055: [D loss: 0.705365, acc: 0.525391]  [A loss: 0.786876, acc: 0.343750]\n",
      "5056: [D loss: 0.727108, acc: 0.462891]  [A loss: 0.858960, acc: 0.195312]\n",
      "5057: [D loss: 0.712754, acc: 0.519531]  [A loss: 0.773696, acc: 0.339844]\n",
      "5058: [D loss: 0.697357, acc: 0.523438]  [A loss: 0.921950, acc: 0.156250]\n",
      "5059: [D loss: 0.698371, acc: 0.517578]  [A loss: 0.675391, acc: 0.539062]\n",
      "5060: [D loss: 0.722003, acc: 0.511719]  [A loss: 1.072640, acc: 0.050781]\n",
      "5061: [D loss: 0.709973, acc: 0.507812]  [A loss: 0.746424, acc: 0.378906]\n",
      "5062: [D loss: 0.731530, acc: 0.498047]  [A loss: 0.837644, acc: 0.250000]\n",
      "5063: [D loss: 0.693731, acc: 0.544922]  [A loss: 0.768602, acc: 0.386719]\n",
      "5064: [D loss: 0.731185, acc: 0.486328]  [A loss: 0.921429, acc: 0.148438]\n",
      "5065: [D loss: 0.686948, acc: 0.558594]  [A loss: 0.722801, acc: 0.453125]\n",
      "5066: [D loss: 0.710095, acc: 0.529297]  [A loss: 0.953014, acc: 0.113281]\n",
      "5067: [D loss: 0.701092, acc: 0.521484]  [A loss: 0.758559, acc: 0.394531]\n",
      "5068: [D loss: 0.721964, acc: 0.521484]  [A loss: 0.820981, acc: 0.261719]\n",
      "5069: [D loss: 0.695190, acc: 0.523438]  [A loss: 0.788809, acc: 0.300781]\n",
      "5070: [D loss: 0.709002, acc: 0.515625]  [A loss: 0.855632, acc: 0.253906]\n",
      "5071: [D loss: 0.691748, acc: 0.546875]  [A loss: 0.752977, acc: 0.410156]\n",
      "5072: [D loss: 0.714420, acc: 0.494141]  [A loss: 0.940328, acc: 0.125000]\n",
      "5073: [D loss: 0.702949, acc: 0.521484]  [A loss: 0.727718, acc: 0.488281]\n",
      "5074: [D loss: 0.721377, acc: 0.515625]  [A loss: 0.947855, acc: 0.156250]\n",
      "5075: [D loss: 0.700083, acc: 0.507812]  [A loss: 0.746207, acc: 0.417969]\n",
      "5076: [D loss: 0.712882, acc: 0.513672]  [A loss: 0.843685, acc: 0.226562]\n",
      "5077: [D loss: 0.705910, acc: 0.521484]  [A loss: 0.749916, acc: 0.386719]\n",
      "5078: [D loss: 0.703628, acc: 0.517578]  [A loss: 0.849209, acc: 0.265625]\n",
      "5079: [D loss: 0.713601, acc: 0.500000]  [A loss: 0.738961, acc: 0.410156]\n",
      "5080: [D loss: 0.713490, acc: 0.515625]  [A loss: 0.957968, acc: 0.093750]\n",
      "5081: [D loss: 0.703793, acc: 0.503906]  [A loss: 0.757198, acc: 0.378906]\n",
      "5082: [D loss: 0.703368, acc: 0.513672]  [A loss: 0.884899, acc: 0.179688]\n",
      "5083: [D loss: 0.694204, acc: 0.503906]  [A loss: 0.756754, acc: 0.398438]\n",
      "5084: [D loss: 0.705316, acc: 0.505859]  [A loss: 0.814172, acc: 0.277344]\n",
      "5085: [D loss: 0.712665, acc: 0.498047]  [A loss: 0.794544, acc: 0.335938]\n",
      "5086: [D loss: 0.705785, acc: 0.535156]  [A loss: 0.811151, acc: 0.273438]\n",
      "5087: [D loss: 0.686920, acc: 0.529297]  [A loss: 0.919990, acc: 0.128906]\n",
      "5088: [D loss: 0.698367, acc: 0.523438]  [A loss: 0.730565, acc: 0.421875]\n",
      "5089: [D loss: 0.717204, acc: 0.507812]  [A loss: 0.965869, acc: 0.113281]\n",
      "5090: [D loss: 0.707453, acc: 0.507812]  [A loss: 0.697192, acc: 0.527344]\n",
      "5091: [D loss: 0.712348, acc: 0.511719]  [A loss: 0.887026, acc: 0.183594]\n",
      "5092: [D loss: 0.709045, acc: 0.486328]  [A loss: 0.719133, acc: 0.472656]\n",
      "5093: [D loss: 0.711483, acc: 0.492188]  [A loss: 0.863366, acc: 0.214844]\n",
      "5094: [D loss: 0.696719, acc: 0.509766]  [A loss: 0.759974, acc: 0.425781]\n",
      "5095: [D loss: 0.709370, acc: 0.523438]  [A loss: 0.846248, acc: 0.253906]\n",
      "5096: [D loss: 0.705996, acc: 0.527344]  [A loss: 0.769260, acc: 0.351562]\n",
      "5097: [D loss: 0.708966, acc: 0.505859]  [A loss: 0.902850, acc: 0.156250]\n",
      "5098: [D loss: 0.702122, acc: 0.501953]  [A loss: 0.741877, acc: 0.433594]\n",
      "5099: [D loss: 0.703408, acc: 0.544922]  [A loss: 0.861537, acc: 0.210938]\n",
      "5100: [D loss: 0.707905, acc: 0.498047]  [A loss: 0.841546, acc: 0.222656]\n",
      "5101: [D loss: 0.704908, acc: 0.519531]  [A loss: 0.872265, acc: 0.207031]\n",
      "5102: [D loss: 0.687942, acc: 0.542969]  [A loss: 0.641947, acc: 0.644531]\n",
      "5103: [D loss: 0.770064, acc: 0.505859]  [A loss: 1.106186, acc: 0.062500]\n",
      "5104: [D loss: 0.702072, acc: 0.537109]  [A loss: 0.782979, acc: 0.351562]\n",
      "5105: [D loss: 0.728908, acc: 0.513672]  [A loss: 0.848352, acc: 0.246094]\n",
      "5106: [D loss: 0.683284, acc: 0.562500]  [A loss: 0.734914, acc: 0.480469]\n",
      "5107: [D loss: 0.697712, acc: 0.566406]  [A loss: 0.772801, acc: 0.375000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5108: [D loss: 0.697078, acc: 0.541016]  [A loss: 0.773083, acc: 0.382812]\n",
      "5109: [D loss: 0.715489, acc: 0.511719]  [A loss: 0.861382, acc: 0.222656]\n",
      "5110: [D loss: 0.711260, acc: 0.521484]  [A loss: 0.741900, acc: 0.375000]\n",
      "5111: [D loss: 0.712996, acc: 0.515625]  [A loss: 0.974405, acc: 0.085938]\n",
      "5112: [D loss: 0.680639, acc: 0.589844]  [A loss: 0.716265, acc: 0.492188]\n",
      "5113: [D loss: 0.722368, acc: 0.519531]  [A loss: 0.904281, acc: 0.156250]\n",
      "5114: [D loss: 0.691239, acc: 0.546875]  [A loss: 0.735065, acc: 0.421875]\n",
      "5115: [D loss: 0.721464, acc: 0.507812]  [A loss: 0.831378, acc: 0.238281]\n",
      "5116: [D loss: 0.691711, acc: 0.513672]  [A loss: 0.776260, acc: 0.359375]\n",
      "5117: [D loss: 0.716093, acc: 0.521484]  [A loss: 0.860890, acc: 0.203125]\n",
      "5118: [D loss: 0.694990, acc: 0.529297]  [A loss: 0.791810, acc: 0.308594]\n",
      "5119: [D loss: 0.707287, acc: 0.519531]  [A loss: 0.821022, acc: 0.277344]\n",
      "5120: [D loss: 0.707828, acc: 0.501953]  [A loss: 0.812406, acc: 0.265625]\n",
      "5121: [D loss: 0.696471, acc: 0.552734]  [A loss: 0.871808, acc: 0.199219]\n",
      "5122: [D loss: 0.686672, acc: 0.548828]  [A loss: 0.783556, acc: 0.382812]\n",
      "5123: [D loss: 0.707324, acc: 0.531250]  [A loss: 0.836045, acc: 0.257812]\n",
      "5124: [D loss: 0.703178, acc: 0.533203]  [A loss: 0.884247, acc: 0.183594]\n",
      "5125: [D loss: 0.699618, acc: 0.507812]  [A loss: 0.748222, acc: 0.421875]\n",
      "5126: [D loss: 0.733771, acc: 0.486328]  [A loss: 0.995549, acc: 0.101562]\n",
      "5127: [D loss: 0.699478, acc: 0.531250]  [A loss: 0.718259, acc: 0.480469]\n",
      "5128: [D loss: 0.727215, acc: 0.505859]  [A loss: 0.924051, acc: 0.160156]\n",
      "5129: [D loss: 0.708859, acc: 0.529297]  [A loss: 0.765618, acc: 0.367188]\n",
      "5130: [D loss: 0.724045, acc: 0.503906]  [A loss: 0.890545, acc: 0.199219]\n",
      "5131: [D loss: 0.693276, acc: 0.544922]  [A loss: 0.778537, acc: 0.355469]\n",
      "5132: [D loss: 0.713787, acc: 0.511719]  [A loss: 0.933567, acc: 0.140625]\n",
      "5133: [D loss: 0.699018, acc: 0.542969]  [A loss: 0.791387, acc: 0.367188]\n",
      "5134: [D loss: 0.727948, acc: 0.482422]  [A loss: 0.911911, acc: 0.156250]\n",
      "5135: [D loss: 0.688792, acc: 0.544922]  [A loss: 0.710629, acc: 0.441406]\n",
      "5136: [D loss: 0.727053, acc: 0.517578]  [A loss: 0.932170, acc: 0.144531]\n",
      "5137: [D loss: 0.699768, acc: 0.531250]  [A loss: 0.747651, acc: 0.429688]\n",
      "5138: [D loss: 0.739353, acc: 0.515625]  [A loss: 1.036668, acc: 0.054688]\n",
      "5139: [D loss: 0.697202, acc: 0.505859]  [A loss: 0.731479, acc: 0.429688]\n",
      "5140: [D loss: 0.707320, acc: 0.513672]  [A loss: 0.810731, acc: 0.304688]\n",
      "5141: [D loss: 0.695519, acc: 0.519531]  [A loss: 0.764223, acc: 0.378906]\n",
      "5142: [D loss: 0.699783, acc: 0.544922]  [A loss: 0.846912, acc: 0.242188]\n",
      "5143: [D loss: 0.694587, acc: 0.523438]  [A loss: 0.772460, acc: 0.343750]\n",
      "5144: [D loss: 0.702187, acc: 0.488281]  [A loss: 0.821252, acc: 0.281250]\n",
      "5145: [D loss: 0.705791, acc: 0.523438]  [A loss: 0.764306, acc: 0.398438]\n",
      "5146: [D loss: 0.713112, acc: 0.537109]  [A loss: 0.781654, acc: 0.328125]\n",
      "5147: [D loss: 0.709577, acc: 0.513672]  [A loss: 0.945629, acc: 0.117188]\n",
      "5148: [D loss: 0.689832, acc: 0.544922]  [A loss: 0.751562, acc: 0.433594]\n",
      "5149: [D loss: 0.706156, acc: 0.517578]  [A loss: 0.901861, acc: 0.187500]\n",
      "5150: [D loss: 0.711528, acc: 0.507812]  [A loss: 0.727208, acc: 0.460938]\n",
      "5151: [D loss: 0.726257, acc: 0.509766]  [A loss: 1.016022, acc: 0.121094]\n",
      "5152: [D loss: 0.702197, acc: 0.541016]  [A loss: 0.758972, acc: 0.394531]\n",
      "5153: [D loss: 0.710077, acc: 0.513672]  [A loss: 0.777053, acc: 0.394531]\n",
      "5154: [D loss: 0.707124, acc: 0.515625]  [A loss: 0.798644, acc: 0.332031]\n",
      "5155: [D loss: 0.713041, acc: 0.539062]  [A loss: 0.824446, acc: 0.281250]\n",
      "5156: [D loss: 0.706755, acc: 0.523438]  [A loss: 0.871820, acc: 0.222656]\n",
      "5157: [D loss: 0.700689, acc: 0.531250]  [A loss: 0.848978, acc: 0.218750]\n",
      "5158: [D loss: 0.699261, acc: 0.541016]  [A loss: 0.930315, acc: 0.148438]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6b34902d81ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmnist_dcgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST_DCGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElapsedTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmnist_dcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmnist_dcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7e286200b405>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_steps, batch_size, save_interval)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 self.x_train.shape[0], size=batch_size), :, :, :]\n\u001b[1;32m     22\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mimages_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1594\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    mnist_dcgan = MNIST_DCGAN()\n",
    "    timer = ElapsedTimer()\n",
    "    mnist_dcgan.train(train_steps=10000, batch_size=256, save_interval=500)\n",
    "    timer.elapsed_time()\n",
    "    mnist_dcgan.plot_images(fake=True)\n",
    "    mnist_dcgan.plot_images(fake=False, save2file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
